(Files content cropped to 300k characters, download full ingest to see more)
================================================
FILE: README.md
================================================
<div align="center">
    <br/>
    <p>
        <img src="resources/branding/app_icon/raw.png"
            title="Helium" alt="Helium logo" width="120" />
        <h1>Helium</h1>
    </p>
    <p width="120">
        The Chromium-based web browser made for people, with love.
        <br>
        Best privacy by default, unbiased ad-blocking, no bloat and no noise.
    </p>
    <a href="https://helium.computer/">
        helium.computer
    </a>
    <br/>
</div>

## Downloads
> [!NOTE]
> Helium is still in beta, so unexpected issues may occur. We are not responsible
for any damage caused by usage of beta software.

Best way to download Helium is to open [helium.computer](https://helium.computer/) on your computer.
It'll pick the right build for your OS and architecture automatically.

If you wish to download builds "straight from the tap" with all options in one place,
you can do it on GitHub in the Releases section in each platform's repo:
- [macOS](https://github.com/imputnet/helium-macos/releases/latest)
- [Linux](https://github.com/imputnet/helium-linux/releases/latest) (AppImage)
- [Windows](https://github.com/imputnet/helium-windows/releases/latest) (no auto-updates yet)

## Platform packaging
Helium is available on all major desktop platforms, with entirety of source code
for all of them published here:
- [Helium for macOS](https://github.com/imputnet/helium-macos)
- [Helium for Linux](https://github.com/imputnet/helium-linux)
- [Helium for Windows](https://github.com/imputnet/helium-windows)

## Other Helium repos
Along with the main repo and platform packaging, these projects are also a part of Helium:
- [Helium services](https://github.com/imputnet/helium-services)
- [Helium onboarding](https://github.com/imputnet/helium-onboarding) (the onboarding page seen in Helium at `helium://setup`)
- [uBlock Origin packaging](https://github.com/imputnet/ublock-origin-crx)

## Credits
### ungoogled-chromium
Helium is proudly based on [ungoogled-chromium](https://github.com/ungoogled-software/ungoogled-chromium).
It wouldn't be possible for us to get rid of Google's bloat and get a development+building pipeline this fast without it.
Huge shout-out to everyone behind this amazing project!
(and we intend to contribute even more stuff upstream in the future)

### The Chromium project
[The Chromium Project](https://www.chromium.org/) is obviously at the core of Helium,
making it possible to exist in the first place.

### ungoogled-chromium's dependencies
- [Inox patchset](https://github.com/gcarq/inox-patchset)
- [Debian](https://tracker.debian.org/pkg/chromium-browser)
- [Bromite](https://github.com/bromite/bromite)
- [Iridium Browser](https://iridiumbrowser.de/)

## License
All code, patches, modified portions of imported code or patches, and
any other content that is unique to Helium and not imported from other
repositories is licensed under GPL-3.0. See [LICENSE](LICENSE).

Any content imported from other projects retains its original license (for
example, any original unmodified code imported from ungoogled-chromium remains
licensed under their [BSD 3-Clause license](LICENSE.ungoogled_chromium)).

## More documentation (soon)
> [!NOTE]
> We will add more documentation along with design and motivation guidelines in the future.
All docs will be linked here along with other related content.



================================================
FILE: chromium_version.txt
================================================
143.0.7499.169



================================================
FILE: domain_regex.list
================================================
fonts(\\*?)\.googleapis(\\*?)\.com#f0ntz\g<1>.9oo91e8p1\g<2>.qjz9zk
google([A-Za-z\-]*?\\*?)\.com(?!mon)#9oo91e\g<1>.qjz9zk
gstatic([A-Za-z\-]*?\\*?)\.com#95tat1c\g<1>.qjz9zk
chrome([A-Za-z\-]*?\\*?)\.com(?!ponent)#ch40me\g<1>.qjz9zk
chromium([A-Za-z\-]*?\\*?)\.org#ch40m1um\g<1>.qjz9zk
mozilla([A-Za-z\-]*?\\*?)\.org#m0z111a\g<1>.qjz9zk
facebook([A-Za-z\-]*?\\*?)\.com#f8c3b00k\g<1>.qjz9zk
appspot([A-Za-z\-]*?\\*?)\.com#8pp2p8t\g<1>.qjz9zk
youtube([A-Za-z\-]*?\\*?)\.com#y0u1ub3\g<1>.qjz9zk
ytimg([A-Za-z\-]*?\\*?)\.com#yt1mg\g<1>.qjz9zk
gmail([A-Za-z\-]*?\\*?)\.com#9ma1l\g<1>.qjz9zk
doubleclick([A-Za-z\-]*?\\*?)\.net#60u613cl1c4\g<1>.n3t.qjz9zk
doubleclick([A-Za-z\-]*?\\*?)\.com#60u613cl1c4\g<1>.c0m.qjz9zk
googlezip(\\*?)\.net#9oo91e21p\g<1>.qjz9zk
beacons([1-9]?\\*?)\.gvt([1-9]?\\*?)\.com#b3ac0n2\g<1>.9vt\g<2>.qjz9zk
ggpht(\\*?)\.com#99pht\g<1>.qjz9zk
microsoft(\\*?)\.com#m1cr050ft\g<1>.qjz9zk
1e100(\\*?)\.net#l3lOO\g<1>.qjz9zk
(?<!http://schemas.)android(\\*?)\.com#8n6r01d\g<1>.qjz9zk
goo\.gl(e?)#goo.gl\g<1>.qjz9zk
privacysandbox([A-Za-z\-]*?\\*?)\.com#pr1v4cy54ndb0x\g<1>.qjz9zk



================================================
FILE: downloads.ini
================================================
# Official Chromium source code archive
# NOTE: Substitutions beginning with underscore are provided by utils
[chromium]
url = https://commondatastorage.googleapis.com/chromium-browser-official/chromium-%(_chromium_version)s-lite.tar.xz
download_filename = chromium-%(_chromium_version)s-lite.tar.xz
hash_url = chromium|chromium-%(_chromium_version)s-lite.tar.xz.hashes|https://commondatastorage.googleapis.com/chromium-browser-official/chromium-%(_chromium_version)s-lite.tar.xz.hashes
output_path = ./
strip_leading_dirs = chromium-%(_chromium_version)s



================================================
FILE: extras.ini
================================================
# Everything that's downloaded after cloning Chromium goes here.
# It will not work from main downloads.ini
[search_engines_data]
url = https://gist.githubusercontent.com/wukko/2a591364dda346e10219e4adabd568b1/raw/e75ae3c4a1ce940ef7627916a48bc40882d24d40/nonfree-search-engines-data.tar.gz
download_filename = nonfree-search-engines-data.tar.gz
sha256 = 00a87050fa3f941d04d67fb5763991e0b8ea399a88b505ab0e56dd263f06864c
output_path = ./third_party/search_engines_data/resources_internal

[onboarding]
version = 202512121537
url = https://github.com/imputnet/helium-onboarding/releases/download/%(version)s/helium-onboarding-%(version)s.tar.gz
download_filename = onboarding-page-%(version)s.tar.gz
sha256 = d9729e4d160a2425d8bce36ab2e77588ec85e0f7ce6f5bdb8325997f1b5315fa
output_path = ./components/helium_onboarding

# If you are bumping this, you *NEED* to re-strip the assets.json
# file *every time* by using `devutils/clear-ublock-assets.js`.
[ublock_origin]
version = 1.67.0
url = https://github.com/imputnet/ublock-origin-crx/releases/download/%(version)s/uBlock0_%(version)s.crx
sha256 = 969eaaa4e0b1893a35e1c5767c33bcfcc62737667644c97f644ff3c84677aff7
download_filename = ublock-origin-%(version)s.zip
output_path = third_party/ublock



================================================
FILE: flags.gn
================================================
build_with_tflite_lib=false
chrome_pgo_phase=0
clang_use_chrome_plugins=false
disable_fieldtrial_testing_config=true
enable_hangout_services_extension=false
enable_mdns=false
enable_remoting=false
enable_reporting=false
enable_service_discovery=false
enable_widevine=true
exclude_unwind_tables=true
google_api_key=""
google_default_client_id=""
google_default_client_secret=""
safe_browsing_mode=0
treat_warnings_as_errors=false
use_official_google_api_keys=false
use_unofficial_version_number=false



================================================
FILE: LICENSE
================================================
                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    Copyright (C) 2025 The Helium Authors

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.



================================================
FILE: LICENSE.ungoogled_chromium
================================================
BSD 3-Clause License

Copyright (c) 2015-2023, The ungoogled-chromium Authors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its
   contributors may be used to endorse or promote products derived from
   this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.



================================================
FILE: revision.txt
================================================
7



================================================
FILE: shell.nix
================================================
{ pkgs ? import <nixpkgs> {} }: pkgs.mkShell {
  nativeBuildInputs = with pkgs; [
    quilt

    (python3.withPackages (ps: with ps; [
      httplib2
      six
    ]))
  ];
}



================================================
FILE: version.txt
================================================
0



================================================
FILE: .cirrus.yml
================================================
env:
    CIRRUS_CLONE_DEPTH: 1

container:
    dockerfile: .cirrus_Dockerfile
    cpu: 8
    memory: 32G
    use_in_memory_disk: true

code_check_task:
    pip_cache:
        folder: /usr/local/lib/python3.10/site-packages
        fingerprint_script: cat .cirrus_requirements.txt
        populate_script: python3 -m ensurepip && pip install -r .cirrus_requirements.txt
    utils_script:
        - python3 -m yapf --style '.style.yapf' -e '*/third_party/*' -rpd utils
        - ./devutils/run_utils_pylint.py --hide-fixme
        - ./devutils/run_utils_tests.sh
    devutils_script:
        - python3 -m yapf --style '.style.yapf' -e '*/third_party/*' -rpd devutils
        - ./devutils/run_devutils_pylint.py --hide-fixme
        - ./devutils/run_devutils_tests.sh

validate_config_task:
    validate_config_script: ./devutils/validate_config.py

validate_with_source_task:
    pip_cache:
        folder: /usr/local/lib/python3.10/site-packages
        fingerprint_script: cat .cirrus_requirements.txt
        populate_script: python3 -m ensurepip && pip install -r .cirrus_requirements.txt
    chromium_download_script: |
        # These directories will not exist when this is called, unless cache retrieval
        # fails and leaves partially-complete files around.
        rm -rf chromium_src
        rm -rf chromium_download_cache
        mkdir chromium_download_cache
        # Attempt to download tarball
        ./utils/downloads.py retrieve -i extras.ini -c chromium_download_cache &
        if ! ./utils/downloads.py retrieve -i downloads.ini -c chromium_download_cache ; then
          # If tarball is not available, attempt a clone
          ./utils/clone.py -o chromium_src
          rm -rf chromium_src/uc_staging
          find chromium_src -type d -name '.git' -exec rm -rf "{}" \; -prune
          tar cf chromium_download_cache/chromium-$(cat chromium_version.txt)-lite.tar.xz \
            --transform s/chromium_src/chromium-$(cat chromium_version.txt)/ chromium_src
        fi
        wait
    unpack_source_script: |
        if [ ! -d chromium_src ]; then
          for file in downloads extras; do
            ./utils/downloads.py unpack -i $file.ini -c chromium_download_cache chromium_src
          done
        fi
    validate_patches_script:
        - ./devutils/validate_patches.py -l chromium_src -v
    validate_lists_script:
        # NOTE: This check is prone to false positives, but not false negatives.
        - ./devutils/check_files_exist.py chromium_src pruning.list domain_substitution.list

# vim: set expandtab shiftwidth=4 softtabstop=4:



================================================
FILE: .cirrus_Dockerfile
================================================
# Dockerfile for Python 3 with xz-utils (for tar.xz unpacking)

FROM python:3.10-slim-bookworm

RUN apt update && apt install -y xz-utils patch axel curl git



================================================
FILE: .cirrus_requirements.txt
================================================
# Based on Python package versions in Debian bookworm
# https://packages.debian.org/bookworm/python/
astroid==2.14.2 # via pylint
pylint==2.16.2
pytest-cov==4.0.0
pytest==7.2.1
httplib2==0.20.4
requests==2.28.1
pillow==11.3.0
yapf==0.32.0



================================================
FILE: .style.yapf
================================================
[style]
based_on_style = pep8
allow_split_before_dict_value = false
coalesce_brackets = true
column_limit = 100
indent_width = 4
join_multiple_lines = true
spaces_before_comment = 1



================================================
FILE: devutils/README.md
================================================
# Developer utilities for ungoogled-chromium

This is a collection of scripts written for developing on ungoogled-chromium. See the descriptions at the top of each script for more information.



================================================
FILE: devutils/__init__.py
================================================
[Empty file]


================================================
FILE: devutils/_lint_tests.py
================================================
# pylint: disable=missing-function-docstring,invalid-name,global-statement,missing-module-docstring
# Copyright 2025 The Helium Authors
# You can use, redistribute, and/or modify this source code under
# the terms of the GPL-3.0 license that can be found in the LICENSE file.

from third_party import unidiff

LICENSE_HEADER_IGNORES = ["html", "license", "readme"]

patches_dir = None
series = None


def _read_text(path):
    with open(patches_dir / path, "r", encoding="utf-8") as f:
        return filter(str, f.read().splitlines())


def _read_patch(path):
    return unidiff.PatchSet('\n'.join(_read_text(path)))


def _init(root):
    global patches_dir
    global series
    patches_dir = root / "patches"
    series = set(_read_text("series"))


def a_all_patches_in_series_exist():
    for patch in series:
        assert (patches_dir / patch).is_file(), \
               f"{patch} is in series, but does not exist in the source tree"


def a_all_patches_in_tree_are_in_series():
    for patch in patches_dir.rglob('*'):
        if not patch.is_file() or patch == patches_dir / "series":
            continue

        assert str(patch.relative_to(patches_dir)) in series, \
               f"{patch} exists in source tree, but is not included in the series"


def b_all_patches_have_meaningful_contents():
    for patch in series:
        assert any(l.startswith('+++ ') for l in _read_text(patch)), \
               f"{patch} does not have any meaningful content"


def b_all_patches_have_no_trailing_whitespace():
    for patch in series:
        for i, line in enumerate(_read_text(patch)):
            if not line.startswith('+ '):
                continue

            assert not line.endswith(' '), \
                   f"{patch} contains trailing whitespace on line {i + 1}"


def c_all_new_files_have_license_header():
    for patch in series:
        if 'helium' not in patch:
            continue

        added_files = filter(lambda f: f.is_added_file, _read_patch(patch))

        for file in added_files:
            if any(p in file.path.lower() for p in LICENSE_HEADER_IGNORES):
                continue

            assert any('terms of the GPL-3.0 license' in str(hunk) for hunk in file), \
                   f"File {file.path} was added in {patch}, but contains no Helium license header"


def c_all_new_headers_have_correct_guard():
    for patch in series:
        if 'helium' not in patch:
            continue

        added_files = filter(lambda f: f.is_added_file and f.path.endswith('.h'),
                             _read_patch(patch))

        for file in added_files:
            expected_macro_name = file.path.upper() \
                                  .replace('.', '_') \
                                  .replace('/', '_') + '_'

            assert len(file) == 1

            expected = {
                "ifndef": f'#ifndef {expected_macro_name}',
                "define": f'#define {expected_macro_name}'
            }

            found = {
                "ifndef": None,
                "define": None,
            }

            for _line in file[0]:
                line = str(_line)

                if expected["ifndef"] in line:
                    assert found["define"] is None
                    assert found["ifndef"] is None
                    found["ifndef"] = line
                elif expected["define"] in line:
                    assert found["ifndef"] is not None
                    assert found["define"] is None
                    found["define"] = line

            for macro_type, value in found.items():
                value_print = (value or '(none)').rstrip()
                assert value == f"+{expected[macro_type]}\n", \
                       f"Patch {patch} has unexpected {macro_type} in {file.path}:" \
                       f"{value_print}, expecting: {expected[macro_type]}"


def d_no_whitespace_only_changes():
    for patch in series:
        if 'helium' not in patch:
            continue

        for file in _read_patch(patch):
            for hunk in file:
                seen_nonws = False
                for line in hunk:
                    line = str(line)

                    if line.startswith('+') or line.startswith('-'):
                        seen_nonws = seen_nonws or len(line.rstrip()) > 1

                assert seen_nonws, \
                    f"Patch {patch} contains hunk consisting of "\
                    f"only whitespace characters in {file.path}: {hunk}"



================================================
FILE: devutils/check_all_code.sh
================================================
#!/bin/bash

# Wrapper for devutils and utils formatter, linter, and tester

set -eu

_root_dir=$(dirname $(dirname $(readlink -f $0)))
cd ${_root_dir}/devutils

printf '###### utils yapf ######\n'
./run_utils_yapf.sh
printf '###### utils pylint ######\n'
./run_utils_pylint.py || ./run_utils_pylint.py --hide-fixme
printf '###### utils tests ######\n'
./run_utils_tests.sh

printf '### devutils yapf ######\n'
./run_devutils_yapf.sh
printf '###### devutils pylint ######\n'
./run_devutils_pylint.py || ./run_devutils_pylint.py --hide-fixme
printf '###### devutils tests ######\n'
./run_devutils_tests.sh



================================================
FILE: devutils/check_downloads_ini.py
================================================
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run sanity checking algorithms over downloads.ini files

It checks the following:

    * downloads.ini has the correct format (i.e. conforms to its schema)

Exit codes:
    * 0 if no problems detected
    * 1 if warnings or errors occur
"""

import argparse
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from downloads import DownloadInfo, schema

sys.path.pop(0)


def check_downloads_ini(downloads_ini_iter):
    """
    Combines and checks if the the downloads.ini files provided are valid.

    downloads_ini_iter must be an iterable of strings to downloads.ini files.

    Returns True if errors occured, False otherwise.
    """
    try:
        DownloadInfo(downloads_ini_iter)
    except schema.SchemaError:
        return True
    return False


def main():
    """CLI entrypoint"""

    root_dir = Path(__file__).resolve().parent.parent
    default_downloads_ini = [str(root_dir / 'downloads.ini')]

    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-d',
                        '--downloads-ini',
                        type=Path,
                        nargs='*',
                        default=default_downloads_ini,
                        help='List of downloads.ini files to check. Default: %(default)s')
    args = parser.parse_args()

    if check_downloads_ini(args.downloads_ini):
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/check_files_exist.py
================================================
#!/usr/bin/env python3

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""
Checks if files in a list exist.

Used for quick validation of lists in CI checks.
"""

import argparse
import sys
from pathlib import Path


def main():
    """CLI entrypoint"""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('root_dir', type=Path, help='The directory to check from')
    parser.add_argument('input_files', type=Path, nargs='+', help='The files lists to check')
    args = parser.parse_args()

    for input_name in args.input_files:
        file_iter = filter(
            len, map(str.strip,
                     Path(input_name).read_text(encoding='UTF-8').splitlines()))
        for file_name in file_iter:
            if not Path(args.root_dir, file_name).exists():
                print(f'ERROR: Path "{file_name}" from file "{input_name}" does not exist.',
                      file=sys.stderr)
                sys.exit(1)


if __name__ == "__main__":
    main()



================================================
FILE: devutils/check_gn_flags.py
================================================
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run sanity checking algorithms over GN flags

It checks the following:

    * GN flags in flags.gn are sorted and not duplicated

Exit codes:
    * 0 if no problems detected
    * 1 if warnings or errors occur
"""

import argparse
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from _common import ENCODING, get_logger

sys.path.pop(0)


def check_gn_flags(gn_flags_path):
    """
    Checks if GN flags are sorted and not duplicated.

    gn_flags_path is a pathlib.Path to the GN flags file to check

    Returns True if warnings were logged; False otherwise
    """
    keys_seen = set()
    warnings = False
    with gn_flags_path.open(encoding=ENCODING) as file_obj:
        iterator = iter(file_obj.read().splitlines())
    try:
        previous = next(iterator)
    except StopIteration:
        return warnings
    for current in iterator:
        gn_key = current.split('=')[0]
        if gn_key in keys_seen:
            get_logger().warning('In GN flags %s, "%s" appears at least twice', gn_flags_path,
                                 gn_key)
            warnings = True
        else:
            keys_seen.add(gn_key)
        if current < previous:
            get_logger().warning('In GN flags %s, "%s" should be sorted before "%s"', gn_flags_path,
                                 current, previous)
            warnings = True
        previous = current
    return warnings


def main():
    """CLI entrypoint"""

    root_dir = Path(__file__).resolve().parent.parent
    default_flags_gn = root_dir / 'flags.gn'

    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-f',
                        '--flags-gn',
                        type=Path,
                        default=default_flags_gn,
                        help='Path to the GN flags to use. Default: %(default)s')
    args = parser.parse_args()

    if check_gn_flags(args.flags_gn):
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/check_patch_files.py
================================================
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run sanity checking algorithms over ungoogled-chromium's patch files

It checks the following:

    * All patches exist
    * All patches are referenced by the patch order

Exit codes:
    * 0 if no problems detected
    * 1 if warnings or errors occur
"""

import argparse
import sys
from pathlib import Path

from third_party import unidiff

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from _common import ENCODING, get_logger, parse_series # pylint: disable=wrong-import-order

sys.path.pop(0)

# File suffixes to ignore for checking unused patches
_PATCHES_IGNORE_SUFFIXES = {'.md'}


def _read_series_file(patches_dir, series_file, join_dir=False):
    """
    Returns a generator over the entries in the series file

    patches_dir is a pathlib.Path to the directory of patches
    series_file is a pathlib.Path relative to patches_dir

    join_dir indicates if the patches_dir should be joined with the series entries
    """
    for entry in parse_series(patches_dir / series_file):
        if join_dir:
            yield patches_dir / entry
        else:
            yield entry


def check_patch_readability(patches_dir, series_path=Path('series')):
    """
    Check if the patches from iterable patch_path_iter are readable.
        Patches that are not are logged to stdout.

    Returns True if warnings occured, False otherwise.
    """
    warnings = False
    for patch_path in _read_series_file(patches_dir, series_path, join_dir=True):
        if patch_path.exists():
            with patch_path.open(encoding=ENCODING) as file_obj:
                try:
                    unidiff.PatchSet(file_obj.read())
                except unidiff.errors.UnidiffParseError:
                    get_logger().exception('Could not parse patch: %s', patch_path)
                    warnings = True
                    continue
        else:
            get_logger().warning('Patch not found: %s', patch_path)
            warnings = True
    return warnings


def check_unused_patches(patches_dir, series_path=Path('series')):
    """
    Checks if there are unused patches in patch_dir from series file series_path.
        Unused patches are logged to stdout.

    patches_dir is a pathlib.Path to the directory of patches
    series_path is a pathlib.Path to the series file relative to the patches_dir

    Returns True if there are unused patches; False otherwise.
    """
    unused_patches = set()
    for path in patches_dir.rglob('*'):
        if path.is_dir():
            continue
        if path.suffix in _PATCHES_IGNORE_SUFFIXES:
            continue
        unused_patches.add(str(path.relative_to(patches_dir)))
    unused_patches -= set(_read_series_file(patches_dir, series_path))
    unused_patches.remove(str(series_path))
    logger = get_logger()
    for entry in sorted(unused_patches):
        logger.warning('Unused patch: %s', entry)
    return bool(unused_patches)


def check_series_duplicates(patches_dir, series_path=Path('series')):
    """
    Checks if there are duplicate entries in the series file

    series_path is a pathlib.Path to the series file relative to the patches_dir

    returns True if there are duplicate entries; False otherwise.
    """
    entries_seen = set()
    for entry in _read_series_file(patches_dir, series_path):
        if entry in entries_seen:
            get_logger().warning('Patch appears more than once in series: %s', entry)
            return True
        entries_seen.add(entry)
    return False


def main():
    """CLI entrypoint"""

    root_dir = Path(__file__).resolve().parent.parent
    default_patches_dir = root_dir / 'patches'

    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-p',
                        '--patches',
                        type=Path,
                        default=default_patches_dir,
                        help='Path to the patches directory to use. Default: %(default)s')
    args = parser.parse_args()

    warnings = False
    warnings |= check_patch_readability(args.patches)
    warnings |= check_series_duplicates(args.patches)
    warnings |= check_unused_patches(args.patches)

    if warnings:
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/clear-ublock-assets.js
================================================
// Copyright 2025 The Helium Authors
// You can use, redistribute, and/or modify this source code under
// the terms of the GPL-3.0 license that can be found in the LICENSE file.

// Program for updating the assets.json file in uB0 to disable all
// outgoing connections before the user is able to consent to them.

const fs = require('fs');

const err = () => {
  console.error('usage: node clear-ublock-assets <path to uB0 assets.json');
  process.exit(1);
}

const assets_path = process.argv[2] || err();

const stripURLs = (c) =>
  [c].flat().filter(s => !URL.canParse(s));

const breakKey = (obj, key_) => {
  const keys = Object.keys(obj);
  const idx = keys.indexOf(key_);

  if (idx === -1) {
    return;
  }

  for (let key of keys.splice(idx)) {
    const val = obj[key];
    delete obj[key];

    if (key === key_) {
      key = `^${key}`;
    }

    obj[key] = val;
  }
}

const clear = obj => {
  for (const filter of Object.values(obj)) {
    if (filter.off) {
      continue;
    }

    filter.contentURL = stripURLs(filter.contentURL);
    breakKey(filter, 'cdnURLs');
    breakKey(filter, 'patchURLs');
  }

  return obj;
}

fs.writeFileSync(
  assets_path,
  JSON.stringify(clear(
    JSON.parse(fs.readFileSync(
      assets_path
    ))
  ), null, '\t') + '\n'
);



================================================
FILE: devutils/lint.py
================================================
#!/usr/bin/env python3

# Copyright 2025 The Helium Authors
# You can use, redistribute, and/or modify this source code under
# the terms of the GPL-3.0 license that can be found in the LICENSE file.
"""Script to run sanity checks against the Helium patchset."""

import sys
import inspect
import argparse
from pathlib import Path

import _lint_tests


def parse_args():
    """Parses the CLI arguments."""
    parser = argparse.ArgumentParser()
    parser.add_argument('-t', '--tree', help='root of the source tree to check')
    return parser.parse_args()


def main():
    """CLI entrypoint for executing tests"""
    args = parse_args()
    root_dir = (Path(__file__).parent / "..").resolve()

    if args.tree:
        root_dir = Path(args.tree).resolve()

    _lint_tests._init(root_dir) # pylint: disable=protected-access

    for name, func in inspect.getmembers(_lint_tests, inspect.isfunction):
        if name.startswith("_"):
            continue

        try:
            func()
            print(f"[OK] {name}")
        except Exception:
            print(f"[ERR] {name}:", file=sys.stderr)
            raise


if __name__ == '__main__':
    main()



================================================
FILE: devutils/print_tag_version.sh
================================================
_root_dir=$(dirname $(dirname $(readlink -f $0)))
printf '%s-%s' $(cat $_root_dir/chromium_version.txt) $(cat $_root_dir/revision.txt)



================================================
FILE: devutils/pytest.ini
================================================
[pytest]
testpaths = tests
#filterwarnings =
#	error
#	ignore::DeprecationWarning
#addopts = --cov-report term-missing --hypothesis-show-statistics -p no:warnings
# Live logging
#log_cli=true
#log_level=DEBUG
addopts = -capture=all --cov=. --cov-config=.coveragerc --cov-report term-missing -p no:warnings



================================================
FILE: devutils/run_devutils_pylint.py
================================================
#!/usr/bin/env python3

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run Pylint over devutils"""

import argparse
import sys
from pathlib import Path

from run_other_pylint import ChangeDir, run_pylint


def main():
    """CLI entrypoint"""
    parser = argparse.ArgumentParser(description='Run Pylint over devutils')
    parser.add_argument('--hide-fixme', action='store_true', help='Hide "fixme" Pylint warnings.')
    parser.add_argument('--show-locally-disabled',
                        action='store_true',
                        help='Show "locally-disabled" Pylint warnings.')
    args = parser.parse_args()

    disables = [
        'wrong-import-position',
        'duplicate-code',
    ]

    if args.hide_fixme:
        disables.append('fixme')
    if not args.show_locally_disabled:
        disables.append('locally-disabled')

    pylint_options = [
        f"--disable={','.join(disables)}",
        '--jobs=4',
        '--score=n',
        '--persistent=n',
    ]

    ignore_prefixes = [
        ('third_party', ),
    ]

    sys.path.insert(1, str(Path(__file__).resolve().parent.parent / 'utils'))
    sys.path.insert(2, str(Path(__file__).resolve().parent.parent / 'devutils' / 'third_party'))
    with ChangeDir(Path(__file__).parent):
        result = run_pylint(
            Path(),
            pylint_options,
            ignore_prefixes=ignore_prefixes,
        )
    sys.path.pop(2)
    sys.path.pop(1)
    if not result:
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/run_devutils_tests.sh
================================================
#!/bin/bash

set -eu

_root_dir=$(dirname $(dirname $(readlink -f $0)))
cd ${_root_dir}/devutils
python3 -m pytest -c ${_root_dir}/devutils/pytest.ini



================================================
FILE: devutils/run_devutils_yapf.sh
================================================
#!/bin/bash

set -eu

_current_dir=$(dirname $(readlink -f $0))
_root_dir=$(dirname $_current_dir)
python3 -m yapf --style "$_root_dir/.style.yapf" -e '*/third_party/*' -rpi "$_current_dir"



================================================
FILE: devutils/run_other_pylint.py
================================================
#!/usr/bin/env python3

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run Pylint over any module"""

import argparse
import os
import shutil
import sys
from pathlib import Path

from pylint import lint


class ChangeDir:
    """
    Changes directory to path in with statement
    """

    def __init__(self, path):
        self._path = path
        self._orig_path = os.getcwd()

    def __enter__(self):
        os.chdir(str(self._path))

    def __exit__(self, *_):
        os.chdir(self._orig_path)


def run_pylint(module_path, pylint_options, ignore_prefixes=tuple()):
    """Runs Pylint. Returns a boolean indicating success"""
    pylint_stats = Path(f'/run/user/{os.getuid()}/pylint_stats')
    if not pylint_stats.parent.is_dir(): #pylint: disable=no-member
        pylint_stats = Path('/run/shm/pylint_stats')
    os.environ['PYLINTHOME'] = str(pylint_stats)

    input_paths = []
    if not module_path.exists():
        print('ERROR: Cannot find', module_path)
        sys.exit(1)
    if module_path.is_dir():
        for path in module_path.rglob('*.py'):
            ignore_matched = False
            for prefix in ignore_prefixes:
                if path.parts[:len(prefix)] == prefix:
                    ignore_matched = True
                    break
            if ignore_matched:
                continue
            input_paths.append(str(path))
    else:
        input_paths.append(str(module_path))
    runner = lint.Run((*input_paths, *pylint_options), do_exit=False)

    if pylint_stats.is_dir():
        shutil.rmtree(str(pylint_stats))

    if runner.linter.msg_status != 0:
        print('WARNING: Non-zero exit status:', runner.linter.msg_status)
        return False
    return True


def main():
    """CLI entrypoint"""

    parser = argparse.ArgumentParser(description='Run Pylint over arbitrary module')
    parser.add_argument('--hide-fixme', action='store_true', help='Hide "fixme" Pylint warnings.')
    parser.add_argument('--show-locally-disabled',
                        action='store_true',
                        help='Show "locally-disabled" Pylint warnings.')
    parser.add_argument('module_path', type=Path, help='Path to the module to check')
    args = parser.parse_args()

    if not args.module_path.exists():
        print(f'ERROR: Module path "{args.module_path}" does not exist')
        sys.exit(1)

    disables = [
        'wrong-import-position',
    ]

    if args.hide_fixme:
        disables.append('fixme')
    if not args.show_locally_disabled:
        disables.append('locally-disabled')

    pylint_options = [
        f"--disable={','.join(disables)}",
        '--jobs=4',
        '--score=n',
        '--persistent=n',
    ]

    if not run_pylint(args.module_path, pylint_options):
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/run_other_yapf.sh
================================================
#!/bin/bash

set -eu

python3 -m yapf --style "$(dirname $(readlink -f $0))/.style.yapf" -rpi $@



================================================
FILE: devutils/run_utils_pylint.py
================================================
#!/usr/bin/env python3

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run Pylint over utils"""

import argparse
import sys
from pathlib import Path

from run_other_pylint import ChangeDir, run_pylint


def main():
    """CLI entrypoint"""
    parser = argparse.ArgumentParser(description='Run Pylint over utils')
    parser.add_argument('--hide-fixme', action='store_true', help='Hide "fixme" Pylint warnings.')
    parser.add_argument('--show-locally-disabled',
                        action='store_true',
                        help='Show "locally-disabled" Pylint warnings.')
    args = parser.parse_args()

    pylint_options = [
        '--jobs=4',
        '--max-args=7',
        '--score=n',
        '--persistent=n',
    ]

    if args.hide_fixme:
        pylint_options.append('--disable=fixme')
    if not args.show_locally_disabled:
        pylint_options.append('--disable=locally-disabled')

    ignore_prefixes = [
        ('third_party', ),
        ('tests', ),
    ]

    sys.path.insert(1, str(Path(__file__).resolve().parent.parent / 'utils' / 'third_party'))
    sys.path.append(Path(__file__).resolve().parent.parent / 'utils')
    with ChangeDir(Path(__file__).resolve().parent.parent / 'utils'):
        result = run_pylint(
            Path(),
            pylint_options,
            ignore_prefixes=ignore_prefixes,
        )
    sys.path.pop(1)
    if not result:
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    main()



================================================
FILE: devutils/run_utils_tests.sh
================================================
#!/bin/bash

set -eu

_root_dir=$(dirname $(dirname $(readlink -f $0)))
cd ${_root_dir}/utils
python3 -m pytest -c ${_root_dir}/utils/pytest.ini



================================================
FILE: devutils/run_utils_yapf.sh
================================================
#!/bin/bash

set -eu

_root_dir=$(dirname $(dirname $(readlink -f $0)))
python3 -m yapf --style "$_root_dir/.style.yapf" -e '*/third_party/*' -rpi "$_root_dir/utils"



================================================
FILE: devutils/set_quilt_vars.fish
================================================
#!/bin/fish

# Fish variant of set_quilt_vars.sh

alias quilt='quilt --quiltrc -'

set REPO_ROOT (dirname (dirname (readlink -f (status current-filename))))

set -gx QUILT_PATCHES "$REPO_ROOT/patches"

set -gx QUILT_PUSH_ARGS "--color=auto"
set -gx QUILT_DIFF_OPTS "--show-c-function"
set -gx QUILT_PATCH_OPTS "--unified --reject-format=unified"
set -gx QUILT_DIFF_ARGS "-p ab --no-timestamps --no-index --color=auto"
set -gx QUILT_REFRESH_ARGS "-p ab --no-timestamps --no-index --strip-trailing-whitespace"
set -gx QUILT_COLORS "diff_hdr=1;32:diff_add=1;34:diff_rem=1;31:diff_hunk=1;33:diff_ctx=35:diff_cctx=33"
set -gx QUILT_SERIES_ARGS "--color=auto"
set -gx QUILT_PATCHES_ARGS "--color=auto"

set -gx LC_ALL C



================================================
FILE: devutils/set_quilt_vars.sh
================================================
# Sets quilt variables for updating the patches
# Make sure to run this with the shell command "source" in order to inherit the variables into the interactive environment

# There is some problem with the absolute paths in QUILT_PATCHES and QUILT_SERIES breaking quilt
# (refresh and diff don't read QUILT_*_ARGS, and series displays absolute paths instead of relative)
# Specifying a quiltrc file fixes this, so "--quiltrc -" fixes this too.
# One side effect of '--quiltrc -' is that we lose default settings from /etc/quilt.quiltrc, so they are redefined below.
alias quilt='quilt --quiltrc -'

# Assume this script lives within the repository
REPO_ROOT=$(dirname "$(dirname "$(readlink -f "${BASH_SOURCE[0]:-${(%):-%x}}")")")

export QUILT_PATCHES="$REPO_ROOT/patches"
#export QUILT_SERIES=$(readlink -f "$REPO_ROOT/patches/series")

# Options below borrowed from Debian and default quilt options (from /etc/quilt.quiltrc on Debian)
export QUILT_PUSH_ARGS="--color=auto"
export QUILT_DIFF_OPTS="--show-c-function"
export QUILT_PATCH_OPTS="--unified --reject-format=unified"
export QUILT_DIFF_ARGS="-p ab --no-timestamps --no-index --color=auto"
export QUILT_REFRESH_ARGS="-p ab --no-timestamps --no-index --strip-trailing-whitespace"
export QUILT_COLORS="diff_hdr=1;32:diff_add=1;34:diff_rem=1;31:diff_hunk=1;33:diff_ctx=35:diff_cctx=33"
export QUILT_SERIES_ARGS="--color=auto"
export QUILT_PATCHES_ARGS="--color=auto"

export LC_ALL=C
# When non-default less options are used, add the -R option so that less outputs
# ANSI color escape codes "raw".
if [ -n "${LESS-}" -a -z "${QUILT_PAGER+x}" ]; then
    export QUILT_PAGER="less -FRX"
fi



================================================
FILE: devutils/update_lists.py
================================================
#!/usr/bin/env python3

# Copyright 2025 The Helium Authors
# You can use, redistribute, and/or modify this source code under
# the terms of the GPL-3.0 license that can be found in the LICENSE file.

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""
Update binary pruning and domain substitution lists automatically.

It will download and unpack into the source tree as necessary.
No binary pruning or domain substitution will be applied to the source tree after
the process has finished.
"""

import argparse
import os
import sys

from itertools import repeat
from multiprocessing import Pool
from pathlib import Path, PurePosixPath

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from _common import get_logger
from domain_substitution import DomainRegexList, TREE_ENCODINGS
from prune_binaries import CONTINGENT_PATHS

sys.path.pop(0)

# Encoding for output files
_ENCODING = 'UTF-8'

# pylint: disable=line-too-long

# NOTE: Include patterns have precedence over exclude patterns
# pathlib.Path.match() paths to include in binary pruning
PRUNING_INCLUDE_PATTERNS = [
    'components/domain_reliability/baked_in_configs/*',
    # Removals for patches/core/ungoogled-chromium/remove-unused-preferences-fields.patch
    'components/safe_browsing/core/common/safe_browsing_prefs.cc',
    'components/safe_browsing/core/common/safe_browsing_prefs.h',
    'components/signin/public/base/signin_pref_names.cc',
    'components/signin/public/base/signin_pref_names.h',
]

# pathlib.Path.match() paths to exclude from binary pruning
PRUNING_EXCLUDE_PATTERNS = [
    'chrome/common/win/eventlog_messages.mc', # TODO: False positive textfile
    # Exclusions for DOM distiller (contains model data only)
    'components/dom_distiller/core/data/distillable_page_model_new.bin',
    'components/dom_distiller/core/data/long_page_model.bin',
    # Exclusions for GeoLanguage data
    # Details: https://docs.google.com/document/d/18WqVHz5F9vaUiE32E8Ge6QHmku2QSJKvlqB9JjnIM-g/edit
    # Introduced with: https://chromium.googlesource.com/chromium/src/+/6647da61
    'components/language/content/browser/ulp_language_code_locator/geolanguage-data_rank0.bin',
    'components/language/content/browser/ulp_language_code_locator/geolanguage-data_rank1.bin',
    'components/language/content/browser/ulp_language_code_locator/geolanguage-data_rank2.bin',
    # Exclusion for required prebuilt object for Windows arm64 builds
    'third_party/crashpad/crashpad/util/misc/capture_context_win_arm64.obj',
    'third_party/icu/common/icudtl.dat', # Exclusion for ICU data
    # Exclusion for Android
    'build/android/chromium-debug.keystore',
    'third_party/icu/android/icudtl.dat',
    'third_party/icu/common/icudtb.dat',
    # Exclusion for rollup v4.0+
    'third_party/devtools-frontend/src/node_modules/@rollup/wasm-node/dist/wasm-node/bindings_wasm_bg.wasm',
    'third_party/node/node_modules/@rollup/wasm-node/dist/wasm-node/bindings_wasm_bg.wasm',
    # Exclusion for performance tracing
    'third_party/perfetto/src/trace_processor/importers/proto/atoms.descriptor',
    # Exclusion for zoneinfo64
    'third_party/rust/chromium_crates_io/vendor/zoneinfo64-v0_2/src/data/zoneinfo64.res',
    # Exclusions for safe file extensions
    '*.avif',
    '*.ttf',
    '*.png',
    '*.jpg',
    '*.webp',
    '*.gif',
    '*.ico',
    '*.mp3',
    '*.wav',
    '*.flac',
    '*.car',
    '*.icns',
    '*.woff',
    '*.woff2',
    '*makefile',
    '*.profdata',
    '*.xcf',
    '*.cur',
    '*.pdf',
    '*.ai',
    '*.h',
    '*.c',
    '*.cpp',
    '*.cc',
    '*.mk',
    '*.bmp',
    '*.py',
    '*.xml',
    '*.html',
    '*.js',
    '*.json',
    '*.txt',
    '*.xtb'
]

# NOTE: Domain substitution path prefix exclusion has precedence over inclusion patterns
# Paths to exclude by prefixes of the POSIX representation for domain substitution
DOMAIN_EXCLUDE_PREFIXES = [
    'components/test/',
    'net/http/transport_security_state_static.json',
    'net/http/transport_security_state_static_pins.json',
    # Exclusions for Visual Studio Project generation with GN (PR #445)
    'tools/gn/',
    # Exclusions for files covered with other patches/unnecessary
    'third_party/search_engines_data/resources/definitions/prepopulated_engines.json',
    'third_party/blink/renderer/core/dom/document.cc',
    # Exclusion to allow download of sysroots
    'build/linux/sysroot_scripts/sysroots.json',
    # Licenses and credits
    'tools/licenses/licenses.py',
    # Google Web Store extension stuff
    'extensions/common/api/_api_features.json',
    'chrome/common/extensions/api/_api_features.json',
    'extensions/common/extension_urls.cc',
    'extensions/browser/updater/safe_manifest_parser.cc',
]

# pylint: enable=line-too-long

# pathlib.Path.match() patterns to include in domain substitution
DOMAIN_INCLUDE_PATTERNS = [
    '*.h', '*.hh', '*.hpp', '*.hxx', '*.cc', '*.cpp', '*.cxx', '*.c', '*.h', '*.json', '*.js',
    '*.html', '*.htm', '*.css', '*.py*', '*.grd*', '*.sql', '*.idl', '*.mk', '*.gyp*', 'makefile',
    '*.ts', '*.txt', '*.xml', '*.mm', '*.jinja*', '*.gn', '*.gni'
]

# Binary-detection constant
_TEXTCHARS = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7f})


class UnusedPatterns: #pylint: disable=too-few-public-methods
    """Tracks unused prefixes and patterns"""

    _all_names = ('pruning_include_patterns', 'pruning_exclude_patterns', 'domain_include_patterns',
                  'domain_exclude_prefixes')

    def __init__(self):
        # Initialize all tracked patterns and prefixes in sets
        # Users will discard elements that are used
        for name in self._all_names:
            setattr(self, name, set(globals()[name.upper()]))

    def log_unused(self, error=True):
        """
        Logs unused patterns and prefixes

        Returns True if there are unused patterns or prefixes; False otherwise
        """
        have_unused = False
        log = get_logger().error if error else get_logger().info
        for name in self._all_names:
            current_set = getattr(self, name, None)
            if current_set:
                log('Unused from %s: %s', name.upper(), current_set)
                have_unused = True
        return have_unused


def _is_binary(bytes_data):
    """
    Returns True if the data seems to be binary data (i.e. not human readable); False otherwise
    """
    # From: https://stackoverflow.com/a/7392391
    return bool(bytes_data.translate(None, _TEXTCHARS))


def _dir_empty(path):
    """
    Returns True if the directory is empty; False otherwise

    path is a pathlib.Path or string to a directory to test.
    """
    try:
        next(os.scandir(str(path)))
    except StopIteration:
        return True
    return False


def should_prune(path, relative_path, used_pep_set, used_pip_set):
    """
    Returns True if a path should be pruned from the source tree; False otherwise

    path is the pathlib.Path to the file from the current working directory.
    relative_path is the pathlib.Path to the file from the source tree
    used_pep_set is a list of PRUNING_EXCLUDE_PATTERNS that have been matched
    used_pip_set is a list of PRUNING_INCLUDE_PATTERNS that have been matched
    """
    # Match against include patterns
    for pattern in filter(relative_path.match, PRUNING_INCLUDE_PATTERNS):
        used_pip_set.add(pattern)
        return True

    # Match against exclude patterns
    for pattern in filter(Path(str(relative_path).lower()).match, PRUNING_EXCLUDE_PATTERNS):
        used_pep_set.add(pattern)
        return False

    # Do binary data detection
    with path.open('rb') as file_obj:
        if _is_binary(file_obj.read()):
            return True

    # Passed all filtering; do not prune
    return False


def _check_regex_match(file_path, search_regex):
    """
    Returns True if a regex pattern matches a file; False otherwise

    file_path is a pathlib.Path to the file to test
    search_regex is a compiled regex object to search for domain names
    """
    with file_path.open("rb") as file_obj:
        file_bytes = file_obj.read()
        content = None
        for encoding in TREE_ENCODINGS:
            try:
                content = file_bytes.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        if not search_regex.search(content) is None:
            return True
    return False


def should_domain_substitute(path, relative_path, search_regex, used_dep_set, used_dip_set):
    """
    Returns True if a path should be domain substituted in the source tree; False otherwise

    path is the pathlib.Path to the file from the current working directory.
    relative_path is the pathlib.Path to the file from the source tree.
    used_dep_set is a list of DOMAIN_EXCLUDE_PREFIXES that have been matched
    used_dip_set is a list of DOMAIN_INCLUDE_PATTERNS that have been matched
    """
    relative_path_posix = relative_path.as_posix().lower()
    for include_pattern in DOMAIN_INCLUDE_PATTERNS:
        if PurePosixPath(relative_path_posix).match(include_pattern):
            used_dip_set.add(include_pattern)
            for exclude_prefix in DOMAIN_EXCLUDE_PREFIXES:
                if relative_path_posix.startswith(exclude_prefix):
                    used_dep_set.add(exclude_prefix)
                    return False
            # Skip LICENSE.* files so that they remain untouched.
            for license_path in ['license', 'license.txt', 'license.html']:
                if relative_path_posix.endswith('/' + license_path):
                    return False
            return _check_regex_match(path, search_regex)
    return False


def compute_lists_proc(path, source_tree, search_regex):
    """
    Adds the path to appropriate lists to be used by compute_lists.

    path is the pathlib.Path to the file from the current working directory.
    source_tree is a pathlib.Path to the source tree
    search_regex is a compiled regex object to search for domain names
    """
    used_pep_set = set() # PRUNING_EXCLUDE_PATTERNS
    used_pip_set = set() # PRUNING_INCLUDE_PATTERNS
    used_dep_set = set() # DOMAIN_EXCLUDE_PREFIXES
    used_dip_set = set() # DOMAIN_INCLUDE_PATTERNS
    pruning_set = set()
    domain_substitution_set = set()
    symlink_set = set()
    if path.is_file():
        relative_path = path.relative_to(source_tree)
        if not any(str(relative_path.as_posix()).startswith(cpath) for cpath in CONTINGENT_PATHS):
            if path.is_symlink():
                try:
                    resolved_relative_posix = path.resolve().relative_to(source_tree).as_posix()
                    symlink_set.add((resolved_relative_posix, relative_path.as_posix()))
                except ValueError:
                    # Symlink leads out of the source tree
                    pass
            elif not any(skip in ('.git', '__pycache__', 'uc_staging') for skip in path.parts):
                try:
                    if should_prune(path, relative_path, used_pep_set, used_pip_set):
                        pruning_set.add(relative_path.as_posix())
                    elif should_domain_substitute(path, relative_path, search_regex, used_dep_set,
                                                  used_dip_set):
                        domain_substitution_set.add(relative_path.as_posix())
                except: #pylint: disable=bare-except
                    get_logger().exception('Unhandled exception while processing %s', relative_path)
    return (used_pep_set, used_pip_set, used_dep_set, used_dip_set, pruning_set,
            domain_substitution_set, symlink_set)


def compute_lists(source_tree, search_regex, processes): # pylint: disable=too-many-locals
    """
    Compute the binary pruning and domain substitution lists of the source tree.
    Returns a tuple of three items in the following order:
    1. The sorted binary pruning list
    2. The sorted domain substitution list
    3. An UnusedPatterns object

    source_tree is a pathlib.Path to the source tree
    search_regex is a compiled regex object to search for domain names
    processes is the maximum number of worker processes to create
    """
    pruning_set = set()
    domain_substitution_set = set()
    symlink_set = set() # POSIX resolved path -> set of POSIX symlink paths
    source_tree = source_tree.resolve()
    unused_patterns = UnusedPatterns()

    # Launch multiple processes iterating over the source tree
    with Pool(processes) as procpool:
        returned_data = procpool.starmap(
            compute_lists_proc,
            zip(source_tree.rglob('*'), repeat(source_tree), repeat(search_regex)))

    # Handle the returned data
    for (used_pep_set, used_pip_set, used_dep_set, used_dip_set, returned_pruning_set,
         returned_domain_sub_set, returned_symlink_set) in returned_data:
        # pragma pylint: disable=no-member
        unused_patterns.pruning_exclude_patterns.difference_update(used_pep_set)
        unused_patterns.pruning_include_patterns.difference_update(used_pip_set)
        unused_patterns.domain_exclude_prefixes.difference_update(used_dep_set)
        unused_patterns.domain_include_patterns.difference_update(used_dip_set)
        # pragma pylint: enable=no-member
        pruning_set.update(returned_pruning_set)
        domain_substitution_set.update(returned_domain_sub_set)
        symlink_set.update(returned_symlink_set)

    # Prune symlinks for pruned files
    for (resolved, symlink) in symlink_set:
        if resolved in pruning_set:
            pruning_set.add(symlink)

    return sorted(pruning_set), sorted(domain_substitution_set), unused_patterns


def main(args_list=None):
    """CLI entrypoint"""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('--pruning',
                        metavar='PATH',
                        type=Path,
                        default='pruning.list',
                        help='The path to store pruning.list. Default: %(default)s')
    parser.add_argument('--domain-substitution',
                        metavar='PATH',
                        type=Path,
                        default='domain_substitution.list',
                        help='The path to store domain_substitution.list. Default: %(default)s')
    parser.add_argument('--domain-regex',
                        metavar='PATH',
                        type=Path,
                        default='domain_regex.list',
                        help='The path to domain_regex.list. Default: %(default)s')
    parser.add_argument('-t',
                        '--tree',
                        metavar='PATH',
                        type=Path,
                        required=True,
                        help='The path to the source tree to use.')
    parser.add_argument(
        '--processes',
        metavar='NUM',
        type=int,
        default=None,
        help=
        'The maximum number of worker processes to create. Defaults to the number of system CPUs.')
    parser.add_argument('--domain-exclude-prefix',
                        metavar='PREFIX',
                        type=str,
                        action='append',
                        help='Additional exclusion for domain_substitution.list.')
    parser.add_argument('--no-error-unused',
                        action='store_false',
                        dest='error_unused',
                        help='Do not treat unused patterns/prefixes as an error.')
    args = parser.parse_args(args_list)
    if args.domain_exclude_prefix is not None:
        DOMAIN_EXCLUDE_PREFIXES.extend(args.domain_exclude_prefix)
    if args.tree.exists() and not _dir_empty(args.tree):
        get_logger().info('Using existing source tree at %s', args.tree)
    else:
        get_logger().error('No source tree found. Aborting.')
        sys.exit(1)
    get_logger().info('Computing lists...')
    pruning_set, domain_substitution_set, unused_patterns = compute_lists(
        args.tree,
        DomainRegexList(args.domain_regex).search_regex, args.processes)
    with args.pruning.open('w', encoding=_ENCODING) as file_obj:
        file_obj.writelines(f'{line}\n' for line in pruning_set)
    with args.domain_substitution.open('w', encoding=_ENCODING) as file_obj:
        file_obj.writelines(f'{line}\n' for line in domain_substitution_set)
    if unused_patterns.log_unused(args.error_unused) and args.error_unused:
        get_logger().error('Please update or remove unused patterns and/or prefixes. '
                           'The lists have still been updated with the remaining valid entries.')
        sys.exit(1)


if __name__ == "__main__":
    main()



================================================
FILE: devutils/update_platform_patches.py
================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""
Utility to ease the updating of platform patches against ungoogled-chromium's patches
"""

import argparse
import os
import shutil
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from _common import ENCODING, get_logger
from patches import merge_patches

sys.path.pop(0)

_SERIES = 'series'
_SERIES_ORIG = 'series.orig'
_SERIES_PREPEND = 'series.prepend'
_SERIES_MERGED = 'series.merged'


def merge_platform_patches(platform_patches_dir, prepend_patches_dir):
    '''
    Prepends prepend_patches_dir into platform_patches_dir

    Returns True if successful, False otherwise
    '''
    if not (platform_patches_dir / _SERIES).exists():
        get_logger().error('Unable to find platform series file: %s',
                           platform_patches_dir / _SERIES)
        return False

    # Make series.orig file
    shutil.copyfile(str(platform_patches_dir / _SERIES), str(platform_patches_dir / _SERIES_ORIG))

    # Make series.prepend
    shutil.copyfile(str(prepend_patches_dir / _SERIES), str(platform_patches_dir / _SERIES_PREPEND))

    # Merge patches
    merge_patches([prepend_patches_dir], platform_patches_dir, prepend=True)
    (platform_patches_dir / _SERIES).replace(platform_patches_dir / _SERIES_MERGED)

    return True


def _dir_empty(path):
    '''
    Returns True if the directory exists and is empty; False otherwise
    '''
    try:
        next(os.scandir(str(path)))
    except StopIteration:
        return True
    except FileNotFoundError:
        pass
    return False


def _rename_files_with_dirs(root_dir, source_dir, sorted_file_iter):
    '''
    Moves a list of sorted files back to their original location,
    removing empty directories along the way
    '''
    past_parent = None
    for partial_path in sorted_file_iter:
        complete_path = Path(root_dir, partial_path)
        complete_source_path = Path(source_dir, partial_path)
        try:
            complete_path.rename(complete_source_path)
        except FileNotFoundError:
            get_logger().warning('Could not move prepended patch: %s', complete_path)
        if past_parent != complete_path.parent:
            while past_parent and _dir_empty(past_parent):
                past_parent.rmdir()
                past_parent = past_parent.parent
            past_parent = complete_path.parent
    # Handle last path's directory
    while _dir_empty(complete_path.parent):
        complete_path.parent.rmdir()
        complete_path = complete_path.parent


def unmerge_platform_patches(platform_patches_dir, prepend_patches_dir):
    '''
    Undo merge_platform_patches(), adding any new patches from series.merged as necessary

    Returns True if successful, False otherwise
    '''
    if not (platform_patches_dir / _SERIES_PREPEND).exists():
        get_logger().error('Unable to find series.prepend at: %s',
                           platform_patches_dir / _SERIES_PREPEND)
        return False
    prepend_series = set(
        filter(len,
               (platform_patches_dir / _SERIES_PREPEND).read_text(encoding=ENCODING).splitlines()))

    # Move prepended files back to original location, preserving changes
    _rename_files_with_dirs(platform_patches_dir, prepend_patches_dir, sorted(prepend_series))

    # Determine positions of blank spaces in series.orig
    if not (platform_patches_dir / _SERIES_ORIG).exists():
        get_logger().error('Unable to find series.orig at: %s', platform_patches_dir / _SERIES_ORIG)
        return False
    orig_series = (platform_patches_dir / _SERIES_ORIG).read_text(encoding=ENCODING).splitlines()
    # patch path -> list of lines after patch path and before next patch path
    path_comments = {}
    # patch path -> inline comment for patch
    path_inline_comments = {}
    previous_path = None
    for partial_path in orig_series:
        if not partial_path or partial_path.startswith('#'):
            if partial_path not in path_comments:
                path_comments[previous_path] = []
            path_comments[previous_path].append(partial_path)
        else:
            path_parts = partial_path.split(' #', maxsplit=1)
            previous_path = path_parts[0]
            if len(path_parts) == 2:
                path_inline_comments[path_parts[0]] = path_parts[1]

    # Apply changes on series.merged into a modified version of series.orig
    if not (platform_patches_dir / _SERIES_MERGED).exists():
        get_logger().error('Unable to find series.merged at: %s',
                           platform_patches_dir / _SERIES_MERGED)
        return False
    new_series = filter(len, (platform_patches_dir /
                              _SERIES_MERGED).read_text(encoding=ENCODING).splitlines())
    new_series = filter((lambda x: x not in prepend_series), new_series)
    new_series = list(new_series)
    series_index = 0
    while series_index < len(new_series):
        current_path = new_series[series_index]
        if current_path in path_inline_comments:
            new_series[series_index] = current_path + ' #' + path_inline_comments[current_path]
        if current_path in path_comments:
            new_series.insert(series_index + 1, '\n'.join(path_comments[current_path]))
            series_index += 1
        series_index += 1

    # Write series file
    with (platform_patches_dir / _SERIES).open('w', encoding=ENCODING) as series_file:
        series_file.write('\n'.join(new_series))
        series_file.write('\n')

    # All other operations are successful; remove merging intermediates
    (platform_patches_dir / _SERIES_MERGED).unlink()
    (platform_patches_dir / _SERIES_ORIG).unlink()
    (platform_patches_dir / _SERIES_PREPEND).unlink()

    return True


def main():
    """CLI Entrypoint"""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('command',
                        choices=('merge', 'unmerge'),
                        help='Merge or unmerge ungoogled-chromium patches with platform patches')
    parser.add_argument('platform_patches',
                        type=Path,
                        help='The path to the platform patches in GNU Quilt format to merge into')
    args = parser.parse_args()

    repo_dir = Path(__file__).resolve().parent.parent

    success = False
    prepend_patches_dir = repo_dir / 'patches'
    if args.command == 'merge':
        success = merge_platform_patches(args.platform_patches, prepend_patches_dir)
    elif args.command == 'unmerge':
        success = unmerge_platform_patches(args.platform_patches, prepend_patches_dir)
    else:
        raise NotImplementedError(args.command)

    if success:
        return 0
    return 1


if __name__ == '__main__':
    sys.exit(main())



================================================
FILE: devutils/validate_config.py
================================================
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright (c) 2019 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Run sanity checking algorithms over ungoogled-chromium's config files

NOTE: This script is hardcoded to run over ungoogled-chromium's config files only.
To check other files, use the other scripts imported by this script.

It checks the following:

    * All patches exist
    * All patches are referenced by the patch order
    * Each patch is used only once
    * GN flags in flags.gn are sorted and not duplicated
    * downloads.ini has the correct format (i.e. conforms to its schema)

Exit codes:
    * 0 if no problems detected
    * 1 if warnings or errors occur
"""

import sys
from pathlib import Path

from check_downloads_ini import check_downloads_ini
from check_gn_flags import check_gn_flags
from check_patch_files import (check_patch_readability, check_series_duplicates,
                               check_unused_patches)


def main():
    """CLI entrypoint"""

    warnings = False
    root_dir = Path(__file__).resolve().parent.parent
    patches_dir = root_dir / 'patches'

    # Check patches
    warnings |= check_patch_readability(patches_dir)
    warnings |= check_series_duplicates(patches_dir)
    warnings |= check_unused_patches(patches_dir)

    # Check GN flags
    warnings |= check_gn_flags(root_dir / 'flags.gn')

    # Check downloads.ini
    warnings |= check_downloads_ini([root_dir / 'downloads.ini'])

    if warnings:
        sys.exit(1)
    sys.exit(0)


if __name__ == '__main__':
    if sys.argv[1:]:
        print(__doc__)
    else:
        main()



================================================
FILE: devutils/validate_patches.py
================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright (c) 2020 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""
Validates that all patches apply cleanly against the source tree.

The required source tree files can be retrieved from Google directly.
"""

import argparse
import ast
import base64
import email.utils
import json
import logging
import sys
import tempfile
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent / 'third_party'))
import unidiff
from unidiff.constants import LINE_TYPE_EMPTY, LINE_TYPE_NO_NEWLINE

sys.path.pop(0)

sys.path.insert(0, str(Path(__file__).resolve().parent.parent / 'utils'))
from domain_substitution import TREE_ENCODINGS
from _common import ENCODING, get_logger, get_chromium_version, parse_series, add_common_params
from patches import dry_run_check

sys.path.pop(0)

try:
    import requests
    import requests.adapters
    import urllib3.util

    class _VerboseRetry(urllib3.util.Retry):
        """A more verbose version of HTTP Adatper about retries"""

        def sleep_for_retry(self, response=None):
            """Sleeps for Retry-After, and logs the sleep time"""
            if response:
                retry_after = self.get_retry_after(response)
                if retry_after:
                    get_logger().info(
                        'Got HTTP status %s with Retry-After header. Retrying after %s seconds...',
                        response.status, retry_after)
                else:
                    get_logger().info(
                        'Could not find Retry-After header for HTTP response %s. Status reason: %s',
                        response.status, response.reason)
            return super().sleep_for_retry(response)

        def _sleep_backoff(self):
            """Log info about backoff sleep"""
            get_logger().info('Running HTTP request sleep backoff')
            super()._sleep_backoff()

    def _get_requests_session():
        session = requests.Session()
        http_adapter = requests.adapters.HTTPAdapter(
            max_retries=_VerboseRetry(total=10,
                                      read=10,
                                      connect=10,
                                      backoff_factor=8,
                                      status_forcelist=urllib3.Retry.RETRY_AFTER_STATUS_CODES,
                                      raise_on_status=False))
        session.mount('http://', http_adapter)
        session.mount('https://', http_adapter)
        return session
except ImportError:

    def _get_requests_session():
        raise RuntimeError('The Python module "requests" is required for remote'
                           'file downloading. It can be installed from PyPI.')


_ROOT_DIR = Path(__file__).resolve().parent.parent
_SRC_PATH = Path('src')


class _PatchValidationError(Exception):
    """Raised when patch validation fails"""


class _UnexpectedSyntaxError(RuntimeError):
    """Raised when unexpected syntax is used in DEPS"""


class _NotInRepoError(RuntimeError):
    """Raised when the remote file is not present in the given repo"""


class _DepsNodeVisitor(ast.NodeVisitor):
    _valid_syntax_types = (ast.mod, ast.expr_context, ast.boolop, ast.Assign, ast.Add, ast.Name,
                           ast.Dict, ast.Str, ast.NameConstant, ast.List, ast.BinOp)
    _allowed_callables = ('Var', )

    def visit_Call(self, node): #pylint: disable=invalid-name
        """Override Call syntax handling"""
        if node.func.id not in self._allowed_callables:
            raise _UnexpectedSyntaxError(f'Unexpected call of "{node.func.id}" '
                                         f'at line {node.lineno}, column {node.col_offset}')

    def generic_visit(self, node):
        for ast_type in self._valid_syntax_types:
            if isinstance(node, ast_type):
                super().generic_visit(node)
                return
        raise _UnexpectedSyntaxError(f'Unexpected {type(node).__name__} '
                                     f'at line {node.lineno}, column {node.col_offset}')


def _validate_deps(deps_text):
    """Returns True if the DEPS file passes validation; False otherwise"""
    try:
        _DepsNodeVisitor().visit(ast.parse(deps_text))
    except _UnexpectedSyntaxError as exc:
        get_logger().error('%s', exc)
        return False
    return True


def _deps_var(deps_globals):
    """Return a function that implements DEPS's Var() function"""

    def _var_impl(var_name):
        """Implementation of Var() in DEPS"""
        return deps_globals['vars'][var_name]

    return _var_impl


def _parse_deps(deps_text):
    """Returns a dict of parsed DEPS data"""
    deps_globals = {'__builtins__': None}
    deps_globals['Var'] = _deps_var(deps_globals)
    exec(deps_text, deps_globals) #pylint: disable=exec-used
    return deps_globals


def _download_googlesource_file(download_session, repo_url, version, relative_path):
    """
    Returns the contents of the text file with path within the given
    googlesource.com repo as a string.
    """
    if 'googlesource.com' not in repo_url:
        raise ValueError(f'Repository URL is not a googlesource.com URL: {repo_url}')
    full_url = repo_url + f'/+/{version}/{str(relative_path)}?format=TEXT'
    get_logger().debug('Downloading: %s', full_url)
    response = download_session.get(full_url)
    if response.status_code == 404:
        raise _NotInRepoError()
    response.raise_for_status()
    # Assume all files that need patching are compatible with UTF-8
    return base64.b64decode(response.text, validate=True).decode('UTF-8')


def _get_dep_value_url(deps_globals, dep_value):
    """Helper for _process_deps_entries"""
    if isinstance(dep_value, str):
        url = dep_value
    elif isinstance(dep_value, dict):
        if 'url' not in dep_value:
            # Ignore other types like CIPD since
            # it probably isn't necessary
            return None
        url = dep_value['url']
    else:
        raise NotImplementedError()
    if '{' in url:
        # Probably a Python format string
        url = url.format(**deps_globals['vars'])
    if url.count('@') != 1:
        raise _PatchValidationError(f'Invalid number of @ symbols in URL: {url}')
    return url


def _process_deps_entries(deps_globals, child_deps_tree, child_path, deps_use_relative_paths):
    """Helper for _get_child_deps_tree"""
    for dep_path_str, dep_value in deps_globals.get('deps', {}).items():
        url = _get_dep_value_url(deps_globals, dep_value)
        if url is None:
            continue
        dep_path = Path(dep_path_str)
        if not deps_use_relative_paths:
            try:
                dep_path = Path(dep_path_str).relative_to(child_path)
            except ValueError:
                # Not applicable to the current DEPS tree path
                continue
        grandchild_deps_tree = None # Delaying creation of dict() until it's needed
        for recursedeps_item in deps_globals.get('recursedeps', tuple()):
            if isinstance(recursedeps_item, str):
                if recursedeps_item == str(dep_path):
                    grandchild_deps_tree = 'DEPS'
            else: # Some sort of iterable
                recursedeps_item_path, recursedeps_item_depsfile = recursedeps_item
                if recursedeps_item_path == str(dep_path):
                    grandchild_deps_tree = recursedeps_item_depsfile
        if grandchild_deps_tree is None:
            # This dep is not recursive; i.e. it is fully loaded
            grandchild_deps_tree = {}
        child_deps_tree[dep_path] = (*url.split('@'), grandchild_deps_tree)


def _get_child_deps_tree(download_session, current_deps_tree, child_path, deps_use_relative_paths):
    """Helper for _download_source_file"""
    repo_url, version, child_deps_tree = current_deps_tree[child_path]
    if isinstance(child_deps_tree, str):
        # Load unloaded DEPS
        deps_globals = _parse_deps(
            _download_googlesource_file(download_session, repo_url, version, child_deps_tree))
        child_deps_tree = {}
        current_deps_tree[child_path] = (repo_url, version, child_deps_tree)
        deps_use_relative_paths = deps_globals.get('use_relative_paths', False)
        _process_deps_entries(deps_globals, child_deps_tree, child_path, deps_use_relative_paths)
    return child_deps_tree, deps_use_relative_paths


def _get_last_chromium_modification():
    """Returns the last modification date of the chromium-browser-official tar file"""
    with _get_requests_session() as session:
        response = session.head('https://storage.googleapis.com/chromium-browser-official/'
                                f'chromium-{get_chromium_version()}.tar.xz')
        response.raise_for_status()
        return email.utils.parsedate_to_datetime(response.headers['Last-Modified'])


def _get_gitiles_git_log_date(log_entry):
    """Helper for _get_gitiles_git_log_date"""
    return email.utils.parsedate_to_datetime(log_entry['committer']['time'])


def _get_gitiles_commit_before_date(repo_url, target_branch, target_datetime):
    """Returns the hexadecimal hash of the closest commit before target_datetime"""
    json_log_url = f'{repo_url}/+log/{target_branch}?format=JSON'
    with _get_requests_session() as session:
        response = session.get(json_log_url)
        response.raise_for_status()
        git_log = json.loads(response.text[5:]) # Trim closing delimiters for various structures
    assert len(git_log) == 2 # 'log' and 'next' entries
    assert 'log' in git_log
    assert git_log['log']
    git_log = git_log['log']
    # Check boundary conditions
    if _get_gitiles_git_log_date(git_log[0]) < target_datetime:
        # Newest commit is older than target datetime
        return git_log[0]['commit']
    if _get_gitiles_git_log_date(git_log[-1]) > target_datetime:
        # Oldest commit is newer than the target datetime; assume oldest is close enough.
        get_logger().warning('Oldest entry in gitiles log for repo "%s" is newer than target; '
                             'continuing with oldest entry...')
        return git_log[-1]['commit']
    # Do binary search
    low_index = 0
    high_index = len(git_log) - 1
    mid_index = high_index
    while low_index != high_index:
        mid_index = low_index + (high_index - low_index) // 2
        if _get_gitiles_git_log_date(git_log[mid_index]) > target_datetime:
            low_index = mid_index + 1
        else:
            high_index = mid_index
    return git_log[mid_index]['commit']


class _FallbackRepoManager:
    """Retrieves fallback repos and caches data needed for determining repos"""

    _GN_REPO_URL = 'https://gn.googlesource.com/gn.git'

    def __init__(self):
        self._cache_gn_version = None

    @property
    def gn_version(self):
        """
        Returns the version of the GN repo for the Chromium version used by this code
        """
        if not self._cache_gn_version:
            # Because there seems to be no reference to the logic for generating the
            # chromium-browser-official tar file, it's possible that it is being generated
            # by an internal script that manually injects the GN repository files.
            # Therefore, assume that the GN version used in the chromium-browser-official tar
            # files correspond to the latest commit in the master branch of the GN repository
            # at the time of the tar file's generation. We can get an approximation for the
            # generation time by using the last modification date of the tar file on
            # Google's file server.
            self._cache_gn_version = _get_gitiles_commit_before_date(
                self._GN_REPO_URL, 'master', _get_last_chromium_modification())
        return self._cache_gn_version

    def get_fallback(self, current_relative_path, current_node, root_deps_tree):
        """
        Helper for _download_source_file

        It returns a new (repo_url, version, new_relative_path) to attempt a file download with
        """
        assert len(current_node) == 3
        # GN special processing
        try:
            new_relative_path = current_relative_path.relative_to('tools/gn')
        except ValueError:
            pass
        else:
            if current_node is root_deps_tree[_SRC_PATH]:
                get_logger().info('Redirecting to GN repo version %s for path: %s', self.gn_version,
                                  current_relative_path)
                return (self._GN_REPO_URL, self.gn_version, new_relative_path)
        return None, None, None


def _get_target_file_deps_node(download_session, root_deps_tree, target_file):
    """
    Helper for _download_source_file

    Returns the corresponding repo containing target_file based on the DEPS tree
    """
    # The "deps" from the current DEPS file
    current_deps_tree = root_deps_tree
    current_node = None
    # Path relative to the current node (i.e. DEPS file)
    current_relative_path = Path('src', target_file)
    previous_relative_path = None
    deps_use_relative_paths = False
    child_path = None
    while current_relative_path != previous_relative_path:
        previous_relative_path = current_relative_path
        for child_path in current_deps_tree:
            try:
                current_relative_path = previous_relative_path.relative_to(child_path)
            except ValueError:
                # previous_relative_path does not start with child_path
                continue
            current_node = current_deps_tree[child_path]
            # current_node will match with current_deps_tree after the following statement
            current_deps_tree, deps_use_relative_paths = _get_child_deps_tree(
                download_session, current_deps_tree, child_path, deps_use_relative_paths)
            break
    assert not current_node is None
    return current_node, current_relative_path


def _download_source_file(download_session, root_deps_tree, fallback_repo_manager, target_file):
    """
    Downloads the source tree file from googlesource.com

    download_session is an active requests.Session() object
    deps_dir is a pathlib.Path to the directory containing a DEPS file.
    """
    current_node, current_relative_path = _get_target_file_deps_node(download_session,
                                                                     root_deps_tree, target_file)
    # Attempt download with potential fallback logic
    repo_url, version, _ = current_node
    try:
        # Download with DEPS-provided repo
        return _download_googlesource_file(download_session, repo_url, version,
                                           current_relative_path)
    except _NotInRepoError:
        pass
    get_logger().debug(
        'Path "%s" (relative: "%s") not found using DEPS tree; finding fallback repo...',
        target_file, current_relative_path)
    repo_url, version, current_relative_path = fallback_repo_manager.get_fallback(
        current_relative_path, current_node, root_deps_tree)
    if not repo_url:
        get_logger().error('No fallback repo found for "%s" (relative: "%s")', target_file,
                           current_relative_path)
        raise _NotInRepoError()
    try:
        # Download with fallback repo
        return _download_googlesource_file(download_session, repo_url, version,
                                           current_relative_path)
    except _NotInRepoError:
        pass
    get_logger().error('File "%s" (relative: "%s") not found in fallback repo "%s", version "%s"',
                       target_file, current_relative_path, repo_url, version)
    raise _NotInRepoError()


def _initialize_deps_tree():
    """
    Initializes and returns a dependency tree for DEPS files

    The DEPS tree is a dict has the following format:
    key - pathlib.Path relative to the DEPS file's path
    value - tuple(repo_url, version, recursive dict here)
        repo_url is the URL to the dependency's repository root
        If the recursive dict is a string, then it is a string to the DEPS file to load
            if needed

    download_session is an active requests.Session() object
    """
    root_deps_tree = {
        _SRC_PATH: ('https://chromium.googlesource.com/chromium/src.git', get_chromium_version(),
                    'DEPS')
    }
    return root_deps_tree


def _retrieve_remote_files(file_iter):
    """
    Retrieves all file paths in file_iter from Google

    file_iter is an iterable of strings that are relative UNIX paths to
        files in the Chromium source.

    Returns a dict of relative UNIX path strings to a list of lines in the file as strings
    """

    files = {}

    root_deps_tree = _initialize_deps_tree()

    try:
        total_files = len(file_iter)
    except TypeError:
        total_files = None

    logger = get_logger()
    if total_files is None:
        logger.info('Downloading remote files...')
    else:
        logger.info('Downloading %d remote files...', total_files)
    last_progress = 0
    file_count = 0
    fallback_repo_manager = _FallbackRepoManager()
    with _get_requests_session() as download_session:
        download_session.stream = False # To ensure connection to Google can be reused
        for file_path in file_iter:
            if total_files:
                file_count += 1
                current_progress = file_count * 100 // total_files // 5 * 5
                if current_progress != last_progress:
                    last_progress = current_progress
                    logger.info('%d%% downloaded', current_progress)
            else:
                current_progress = file_count // 20 * 20
                if current_progress != last_progress:
                    last_progress = current_progress
                    logger.info('%d files downloaded', current_progress)
            try:
                files[file_path] = _download_source_file(download_session, root_deps_tree,
                                                         fallback_repo_manager,
                                                         file_path).split('\n')
            except _NotInRepoError:
                get_logger().warning('Could not find "%s" remotely. Skipping...', file_path)
    return files


def _retrieve_local_files(file_iter, source_dir):
    """
    Retrieves all file paths in file_iter from the local source tree

    file_iter is an iterable of strings that are relative UNIX paths to
        files in the Chromium source.

    Returns a dict of relative UNIX path strings to a list of lines in the file as strings
    """
    files = {}
    for file_path in file_iter:
        try:
            raw_content = (source_dir / file_path).read_bytes()
        except FileNotFoundError:
            get_logger().warning('Missing file from patches: %s', file_path)
            continue
        for encoding in TREE_ENCODINGS:
            try:
                content = raw_content.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        if not content:
            raise UnicodeDecodeError(f'Unable to decode with any encoding: {file_path}')
        files[file_path] = content.split('\n')
    if not files:
        get_logger().error('All files used by patches are missing!')
    return files


def _modify_file_lines(patched_file, file_lines):
    """Helper for _apply_file_unidiff"""
    # Cursor for keeping track of the current line during hunk application
    # NOTE: The cursor is based on the line list index, not the line number!
    line_cursor = None
    for hunk in patched_file:
        # Validate hunk will match
        if not hunk.is_valid():
            raise _PatchValidationError(f'Hunk is not valid: {repr(hunk)}')
        line_cursor = hunk.target_start - 1
        for line in hunk:
            normalized_line = line.value.rstrip('\n')
            if line.is_added:
                file_lines[line_cursor:line_cursor] = (normalized_line, )
                line_cursor += 1
            elif line.is_removed:
                if normalized_line != file_lines[line_cursor]:
                    raise _PatchValidationError(f"Line '{file_lines[line_cursor]}' does not match "
                                                f"removal line '{normalized_line}' from patch")
                del file_lines[line_cursor]
            elif line.is_context:
                if not normalized_line and line_cursor == len(file_lines):
                    # We reached the end of the file
                    break
                if normalized_line != file_lines[line_cursor]:
                    raise _PatchValidationError(f"Line '{file_lines[line_cursor]}' does not match "
                                                f"context line '{normalized_line}' from patch")
                line_cursor += 1
            else:
                assert line.line_type in (LINE_TYPE_EMPTY, LINE_TYPE_NO_NEWLINE)


def _apply_file_unidiff(patched_file, files_under_test):
    """Applies the unidiff.PatchedFile to the source files under testing"""
    patched_file_path = Path(patched_file.path)
    if patched_file.is_added_file:
        if patched_file_path in files_under_test:
            assert files_under_test[patched_file_path] is None
        assert len(patched_file) == 1 # Should be only one hunk
        assert patched_file[0].removed == 0
        assert patched_file[0].target_start == 1
        files_under_test[patched_file_path] = [x.value.rstrip('\n') for x in patched_file[0]]
    elif patched_file.is_removed_file:
        # Remove lines to see if file to be removed matches patch
        _modify_file_lines(patched_file, files_under_test[patched_file_path])
        files_under_test[patched_file_path] = None
    else: # Patching an existing file
        assert patched_file.is_modified_file
        _modify_file_lines(patched_file, files_under_test[patched_file_path])


def _dry_check_patched_file(patched_file, orig_file_content):
    """Run "patch --dry-check" on a unidiff.PatchedFile for diagnostics"""
    with tempfile.TemporaryDirectory() as tmpdirname:
        tmp_dir = Path(tmpdirname)
        # Write file to patch
        patched_file_path = tmp_dir / patched_file.path
        patched_file_path.parent.mkdir(parents=True, exist_ok=True)
        patched_file_path.write_text(orig_file_content)
        # Write patch
        patch_path = tmp_dir / 'broken_file.patch'
        patch_path.write_text(str(patched_file))
        # Dry run
        _, dry_stdout, _ = dry_run_check(patch_path, tmp_dir)
        return dry_stdout


def _test_patches(series_iter, patch_cache, files_under_test):
    """
    Tests the patches specified in the iterable series_iter

    Returns a boolean indicating if any of the patches have failed
    """
    for patch_path_str in series_iter:
        for patched_file in patch_cache[patch_path_str]:
            orig_file_content = None
            if get_logger().isEnabledFor(logging.DEBUG):
                orig_file_content = files_under_test.get(Path(patched_file.path))
                if orig_file_content:
                    orig_file_content = ' '.join(orig_file_content)
            try:
                _apply_file_unidiff(patched_file, files_under_test)
            except _PatchValidationError as exc:
                get_logger().warning('Patch failed validation: %s', patch_path_str)
                get_logger().debug('Specifically, file "%s" failed validation: %s',
                                   patched_file.path, exc)
                if get_logger().isEnabledFor(logging.DEBUG):
                    # _PatchValidationError cannot be thrown when a file is added
                    assert patched_file.is_modified_file or patched_file.is_removed_file
                    assert orig_file_content is not None
                    get_logger().debug(
                        'Output of "patch --dry-run" for this patch on this file:\n%s',
                        _dry_check_patched_file(patched_file, orig_file_content))
                return True
            except: #pylint: disable=bare-except
                get_logger().warning('Patch failed validation: %s', patch_path_str)
                get_logger().debug('Specifically, file "%s" caused exception while applying:',
                                   patched_file.path,
                                   exc_info=True)
                return True
    return False


def _load_all_patches(series_iter, patches_dir):
    """
    Returns a tuple of the following:
    - boolean indicating success or failure of reading files
    - dict of relative UNIX path strings to unidiff.PatchSet
    """
    had_failure = False
    unidiff_dict = {}
    for relative_path in series_iter:
        if relative_path in unidiff_dict:
            continue
        unidiff_dict[relative_path] = unidiff.PatchSet.from_filename(str(patches_dir /
                                                                         relative_path),
                                                                     encoding=ENCODING)
        if not (patches_dir / relative_path).read_text(encoding=ENCODING).endswith('\n'):
            had_failure = True
            get_logger().warning('Patch file does not end with newline: %s',
                                 str(patches_dir / relative_path))
    return had_failure, unidiff_dict


def _get_required_files(patch_cache):
    """Returns an iterable of pathlib.Path files needed from the source tree for patching"""
    new_files = set() # Files introduced by patches
    file_set = set()
    for patch_set in patch_cache.values():
        for patched_file in patch_set:
            if patched_file.is_added_file:
                new_files.add(patched_file.path)
            elif patched_file.path not in new_files:
                file_set.add(Path(patched_file.path))
    return file_set


def _get_files_under_test(args, required_files, parser):
    """
    Helper for main to get files_under_test

    Exits the program if --cache-remote debugging option is used
    """
    if args.local:
        files_under_test = _retrieve_local_files(required_files, args.local)
    else: # --remote and --cache-remote
        files_under_test = _retrieve_remote_files(required_files)
        if args.cache_remote:
            for file_path, file_content in files_under_test.items():
                if not (args.cache_remote / file_path).parent.exists():
                    (args.cache_remote / file_path).parent.mkdir(parents=True)
                with (args.cache_remote / file_path).open('w', encoding=ENCODING) as cache_file:
                    cache_file.write('\n'.join(file_content))
            parser.exit()
    return files_under_test


def main():
    """CLI Entrypoint"""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-s',
                        '--series',
                        type=Path,
                        metavar='FILE',
                        default=str(Path('patches', 'series')),
                        help='The series file listing patches to apply. Default: %(default)s')
    parser.add_argument('-p',
                        '--patches',
                        type=Path,
                        metavar='DIRECTORY',
                        default='patches',
                        help='The patches directory to read from. Default: %(default)s')
    add_common_params(parser)

    file_source_group = parser.add_mutually_exclusive_group(required=True)
    file_source_group.add_argument(
        '-l',
        '--local',
        type=Path,
        metavar='DIRECTORY',
        help=
        'Use a local source tree. It must be UNMODIFIED, otherwise the results will not be valid.')
    file_source_group.add_argument(
        '-r',
        '--remote',
        action='store_true',
        help=('Download the required source tree files from Google. '
              'This feature requires the Python module "requests". If you do not want to '
              'install this, consider using --local instead.'))
    file_source_group.add_argument(
        '-c',
        '--cache-remote',
        type=Path,
        metavar='DIRECTORY',
        help='(For debugging) Store the required remote files in an empty local directory')
    args = parser.parse_args()
    if args.cache_remote and not args.cache_remote.exists():
        if args.cache_remote.parent.exists():
            args.cache_remote.mkdir()
        else:
            parser.error(f'Parent of cache path {args.cache_remote} does not exist')

    if not args.series.is_file():
        parser.error(f'--series path is not a file or not found: {args.series}')
    if not args.patches.is_dir():
        parser.error(f'--patches path is not a directory or not found: {args.patches}')

    series_iterable = tuple(parse_series(args.series))
    had_failure, patch_cache = _load_all_patches(series_iterable, args.patches)
    required_files = _get_required_files(patch_cache)
    files_under_test = _get_files_under_test(args, required_files, parser)
    had_failure |= _test_patches(series_iterable, patch_cache, files_under_test)
    if had_failure:
        get_logger().error('***FAILED VALIDATION; SEE ABOVE***')
        if not args.verbose:
            get_logger().info('(For more error details, re-run with the "-v" flag)')
        parser.exit(status=1)
    else:
        get_logger().info('Passed validation (%d patches total)', len(series_iterable))


if __name__ == '__main__':
    main()



================================================
FILE: devutils/.coveragerc
================================================
[run]
branch = True
parallel = True
omit = tests/*

[report]
# Regexes for lines to exclude from consideration
exclude_lines =
    # Have to re-enable the standard pragma
    pragma: no cover

    # Don't complain about missing debug-only code:
    def __repr__
    if self\.debug

    # Don't complain if tests don't hit defensive assertion code:
    raise AssertionError
    raise NotImplementedError

    # Don't complain if non-runnable code isn't run:
    if 0:
    if __name__ == .__main__.:



================================================
FILE: devutils/tests/__init__.py
================================================
[Empty file]


================================================
FILE: devutils/tests/test_check_patch_files.py
================================================
# -*- coding: UTF-8 -*-

# Copyright (c) 2020 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Test check_patch_files.py"""

import logging
import tempfile
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent / 'utils'))
from _common import ENCODING, get_logger, set_logging_level

sys.path.pop(0)

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from check_patch_files import check_series_duplicates

sys.path.pop(0)


def test_check_series_duplicates():
    """Test check_series_duplicates"""

    set_logging_level(logging.DEBUG)

    with tempfile.TemporaryDirectory() as tmpdirname:
        patches_dir = Path(tmpdirname)
        series_path = Path(tmpdirname, 'series')

        get_logger().info('Check no duplicates')
        series_path.write_text('\n'.join([
            'a.patch',
            'b.patch',
            'c.patch',
        ]), encoding=ENCODING)
        assert not check_series_duplicates(patches_dir)

        get_logger().info('Check duplicates')
        series_path.write_text('\n'.join([
            'a.patch',
            'b.patch',
            'c.patch',
            'a.patch',
        ]),
                               encoding=ENCODING)
        assert check_series_duplicates(patches_dir)


if __name__ == '__main__':
    test_check_series_duplicates()



================================================
FILE: devutils/tests/test_validate_patches.py
================================================
# -*- coding: UTF-8 -*-

# Copyright (c) 2020 The ungoogled-chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE.ungoogled_chromium file.
"""Test validate_patches.py"""

import logging
import tempfile
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent / 'utils'))
from _common import ENCODING, get_logger, set_logging_level

sys.path.pop(0)

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
import validate_patches

sys.path.pop(0)


def test_test_patches():
    """Test _dry_check_patched_file"""

    #pylint: disable=protected-access
    set_logging_level(logging.DEBUG)

    orig_file_content = """bye world"""
    series_iter = ['test.patch']

    def _run_test_patches(patch_content):
        with tempfile.TemporaryDirectory() as tmpdirname:
            Path(tmpdirname, 'foobar.txt').write_text(orig_file_content, encoding=ENCODING)
            Path(tmpdirname, 'test.patch').write_text(patch_content, encoding=ENCODING)
            _, patch_cache = validate_patches._load_all_patches(series_iter, Path(tmpdirname))
            required_files = validate_patches._get_required_files(patch_cache)
            files_under_test = validate_patches._retrieve_local_files(required_files,
                                                                      Path(tmpdirname))
            return validate_patches._test_patches(series_iter, patch_cache, files_under_test)

    get_logger().info('Check valid modification')
    patch_content = """--- a/foobar.txt
+++ b/foobar.txt
@@ -1 +1 @@
-bye world
+hello world
"""
    assert not _run_test_patches(patch_content)

    get_logger().info('Check invalid modification')
    patch_content = """--- a/foobar.txt
+++ b/foobar.txt
@@ -1 +1 @@
-hello world
+olleh world
"""
    assert _run_test_patches(patch_content)

    get_logger().info('Check correct removal')
    patch_content = """--- a/foobar.txt
+++ /dev/null
@@ -1 +0,0 @@
-bye world
"""
    assert not _run_test_patches(patch_content)

    get_logger().info('Check incorrect removal')
    patch_content = """--- a/foobar.txt
+++ /dev/null
@@ -1 +0,0 @@
-this line does not exist in foobar
"""
    assert _run_test_patches(patch_content)


if __name__ == '__main__':
    test_test_patches()



================================================
FILE: devutils/third_party/README.md
================================================
This directory contains third-party libraries used by devutils.

Contents:

* [python-unidiff](https://github.com/matiasb/python-unidiff)
    * For parsing and modifying unified diffs.



================================================
FILE: devutils/third_party/__init__.py
================================================
[Empty file]


================================================
FILE: devutils/third_party/unidiff/__init__.py
================================================
# -*- coding: utf-8 -*-

# The MIT License (MIT)
# Copyright (c) 2014-2017 Matias Bordese
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.


"""Unidiff parsing library."""

from __future__ import unicode_literals

from . import __version__
from .patch import (
    DEFAULT_ENCODING,
    LINE_TYPE_ADDED,
    LINE_TYPE_CONTEXT,
    LINE_TYPE_REMOVED,
    Hunk,
    PatchedFile,
    PatchSet,
    UnidiffParseError,
)

VERSION = __version__.__version__



================================================
FILE: devutils/third_party/unidiff/__version__.py
================================================
# -*- coding: utf-8 -*-

# The MIT License (MIT)
# Copyright (c) 2014-2017 Matias Bordese
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.

__version__ = '0.5.5'



================================================
FILE: devutils/third_party/unidiff/constants.py
================================================
# -*- coding: utf-8 -*-

# The MIT License (MIT)
# Copyright (c) 2014-2017 Matias Bordese
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.


"""Useful constants and regexes used by the package."""

from __future__ import unicode_literals

import re


RE_SOURCE_FILENAME = re.compile(
    r'^--- (?P<filename>[^\t\n]+)(?:\t(?P<timestamp>[^\n]+))?')
RE_TARGET_FILENAME = re.compile(
    r'^\+\+\+ (?P<filename>[^\t\n]+)(?:\t(?P<timestamp>[^\n]+))?')

# @@ (source offset, length) (target offset, length) @@ (section header)
RE_HUNK_HEADER = re.compile(
    r"^@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))?\ @@[ ]?(.*)")

#    kept line (context)
# \n empty line (treat like context)
# +  added line
# -  deleted line
# \  No newline case
RE_HUNK_BODY_LINE = re.compile(
    r'^(?P<line_type>[- \+\\])(?P<value>.*)', re.DOTALL)
RE_HUNK_EMPTY_BODY_LINE = re.compile(
    r'^(?P<line_type>[- \+\\]?)(?P<value>[\r\n]{1,2})', re.DOTALL)

RE_NO_NEWLINE_MARKER = re.compile(r'^\\ No newline at end of file')

DEFAULT_ENCODING = 'UTF-8'

LINE_TYPE_ADDED = '+'
LINE_TYPE_REMOVED = '-'
LINE_TYPE_CONTEXT = ' '
LINE_TYPE_EMPTY = ''
LINE_TYPE_NO_NEWLINE = '\\'
LINE_VALUE_NO_NEWLINE = ' No newline at end of file'



================================================
FILE: devutils/third_party/unidiff/errors.py
================================================
# -*- coding: utf-8 -*-

# The MIT License (MIT)
# Copyright (c) 2014-2017 Matias Bordese
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.


"""Errors and exceptions raised by the package."""

from __future__ import unicode_literals


class UnidiffParseError(Exception):
    """Exception when parsing the unified diff data."""



================================================
FILE: devutils/third_party/unidiff/patch.py
================================================
# -*- coding: utf-8 -*-

# The MIT License (MIT)
# Copyright (c) 2014-2017 Matias Bordese
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
# OR OTHER DEALINGS IN THE SOFTWARE.


"""Classes used by the unified diff parser to keep the diff data."""

from __future__ import unicode_literals

import codecs
import sys

from .constants import (
    DEFAULT_ENCODING,
    LINE_TYPE_ADDED,
    LINE_TYPE_CONTEXT,
    LINE_TYPE_EMPTY,
    LINE_TYPE_REMOVED,
    LINE_TYPE_NO_NEWLINE,
    LINE_VALUE_NO_NEWLINE,
    RE_HUNK_BODY_LINE,
    RE_HUNK_EMPTY_BODY_LINE,
    RE_HUNK_HEADER,
    RE_SOURCE_FILENAME,
    RE_TARGET_FILENAME,
    RE_NO_NEWLINE_MARKER,
)
from .errors import UnidiffParseError


PY2 = sys.version_info[0] == 2
if PY2:
    from StringIO import StringIO
    open_file = codecs.open
    make_str = lambda x: x.encode(DEFAULT_ENCODING)

    def implements_to_string(cls):
        cls.__unicode__ = cls.__str__
        cls.__str__ = lambda x: x.__unicode__().encode(DEFAULT_ENCODING)
        return cls
else:
    from io import StringIO
    open_file = open
    make_str = str
    implements_to_string = lambda x: x
    unicode = str
    basestring = str


@implements_to_string
class Line(object):
    """A diff line."""

    def __init__(self, value, line_type,
                 source_line_no=None, target_line_no=None, diff_line_no=None):
        super(Line, self).__init__()
        self.source_line_no = source_line_no
        self.target_line_no = target_line_no
        self.diff_line_no = diff_line_no
        self.line_type = line_type
        self.value = value

    def __repr__(self):
        return make_str("<Line: %s%s>") % (self.line_type, self.value)

    def __str__(self):
        return "%s%s" % (self.line_type, self.value)

    def __eq__(self, other):
        return (self.source_line_no == other.source_line_no and
                self.target_line_no == other.target_line_no and
                self.diff_line_no == other.diff_line_no and
                self.line_type == other.line_type and
                self.value == other.value)

    @property
    def is_added(self):
        return self.line_type == LINE_TYPE_ADDED

    @property
    def is_removed(self):
        return self.line_type == LINE_TYPE_REMOVED

    @property
    def is_context(self):
        return self.line_type == LINE_TYPE_CONTEXT


@implements_to_string
class PatchInfo(list):
    """Lines with extended patch info.

    Format of this info is not documented and it very much depends on
    patch producer.

    """

    def __repr__(self):
        value = "<PatchInfo: %s>" % self[0].strip()
        return make_str(value)

    def __str__(self):
        return ''.join(unicode(line) for line in self)


@implements_to_string
class Hunk(list):
    """Each of the modified blocks of a file."""

    def __init__(self, src_start=0, src_len=0, tgt_start=0, tgt_len=0,
                 section_header=''):
        if src_len is None:
            src_len = 1
        if tgt_len is None:
            tgt_len = 1
        self.added = 0  # number of added lines
        self.removed = 0  # number of removed lines
        self.source = []
        self.source_start = int(src_start)
        self.source_length = int(src_len)
        self.target = []
        self.target_start = int(tgt_start)
        self.target_length = int(tgt_len)
        self.section_header = section_header

    def __repr__(self):
        value = "<Hunk: @@ %d,%d %d,%d @@ %s>" % (self.source_start,
                                                  self.source_length,
                                                  self.target_start,
                                                  self.target_length,
                                                  self.section_header)
        return make_str(value)

    def __str__(self):
        # section header is optional and thus we output it only if it's present
        head = "@@ -%d,%d +%d,%d @@%s\n" % (
            self.source_start, self.source_length,
            self.target_start, self.target_length,
            ' ' + self.section_header if self.section_header else '')
        content = ''.join(unicode(line) for line in self)
        return head + content

    def append(self, line):
        """Append the line to hunk, and keep track of source/target lines."""
        super(Hunk, self).append(line)
        s = str(line)
        if line.is_added:
            self.added += 1
            self.target.append(s)
        elif line.is_removed:
            self.removed += 1
            self.source.append(s)
        elif line.is_context:
            self.target.append(s)
            self.source.append(s)

    def is_valid(self):
        """Check hunk header data matches entered lines info."""
        return (len(self.source) == self.source_length and
                len(self.target) == self.target_length)

    def source_lines(self):
        """Hunk lines from source file (generator)."""
        return (l for l in self if l.is_context or l.is_removed)

    def target_lines(self):
        """Hunk lines from target file (generator)."""
        return (l for l in self if l.is_context or l.is_added)


class PatchedFile(list):
    """Patch updated file, it is a list of Hunks."""

    def __init__(self, patch_info=None, source='', target='',
                 source_timestamp=None, target_timestamp=None):
        super(PatchedFile, self).__init__()
        self.patch_info = patch_info
        self.source_file = source
        self.source_timestamp = source_timestamp
        self.target_file = target
        self.target_timestamp = target_timestamp

    def __repr__(self):
        return make_str("<PatchedFile: %s>") % make_str(self.path)

    def __str__(self):
        # patch info is optional
        info = '' if self.patch_info is None else str(self.patch_info)
        source = "--- %s%s\n" % (
            self.source_file,
            '\t' + self.source_timestamp if self.source_timestamp else '')
        target = "+++ %s%s\n" % (
            self.target_file,
            '\t' + self.target_timestamp if self.target_timestamp else '')
        hunks = ''.join(unicode(hunk) for hunk in self)
        return info + source + target + hunks

    def _parse_hunk(self, header, diff, encoding):
        """Parse hunk details."""
        header_info = RE_HUNK_HEADER.match(header)
        hunk_info = header_info.groups()
        hunk = Hunk(*hunk_info)

        source_line_no = hunk.source_start
        target_line_no = hunk.target_start
        expected_source_end = source_line_no + hunk.source_length
        expected_target_end = target_line_no + hunk.target_length

        for diff_line_no, line in diff:
            if encoding is not None:
                line = line.decode(encoding)

            valid_line = RE_HUNK_EMPTY_BODY_LINE.match(line)
            if not valid_line:
                valid_line = RE_HUNK_BODY_LINE.match(line)

            if not valid_line:
                raise UnidiffParseError('Hunk diff line expected: %s' % line)

            line_type = valid_line.group('line_type')
            if line_type == LINE_TYPE_EMPTY:
                line_type = LINE_TYPE_CONTEXT
            value = valid_line.group('value')
            original_line = Line(value, line_type=line_type)
            if line_type == LINE_TYPE_ADDED:
                original_line.target_line_no = target_line_no
                target_line_no += 1
            elif line_type == LINE_TYPE_REMOVED:
                original_line.source_line_no = source_line_no
                source_line_no += 1
            elif line_type == LINE_TYPE_CONTEXT:
                original_line.target_line_no = target_line_no
                target_line_no += 1
                original_line.source_line_no = source_line_no
                source_line_no += 1
            elif line_type == LINE_TYPE_NO_NEWLINE:
                pass
            else:
                original_line = None

            # stop parsing if we got past expected number of lines
            if (source_line_no > expected_source_end or
                    target_line_no > expected_target_end):
                raise UnidiffParseError('Hunk is longer than expected')

            if original_line:
                original_line.diff_line_no = diff_line_no
                hunk.append(original_line)

            # if hunk source/target lengths are ok, hunk is complete
            if (source_line_no == expected_source_end and
                    target_line_no == expected_target_end):
                break

        # report an error if we haven't got expected number of lines
        if (source_line_no < expected_source_end or
                target_line_no < expected_target_end):
            raise UnidiffParseError('Hunk is shorter than expected')

        self.append(hunk)

    def _add_no_newline_marker_to_last_hunk(self):
        if not self:
            raise UnidiffParseError(
                'Unexpected marker:' + LINE_VALUE_NO_NEWLINE)
        last_hunk = self[-1]
        last_hunk.append(
            Line(LINE_VALUE_NO_NEWLINE + '\n', line_type=LINE_TYPE_NO_NEWLINE))

    def _append_trailing_empty_line(self):
        if not self:
            raise UnidiffParseError('Unexpected trailing newline character')
        last_hunk = self[-1]
        last_hunk.append(Line('\n', line_type=LINE_TYPE_EMPTY))

    @property
    def path(self):
        """Return the file path abstracted from VCS."""
        if (self.source_file.startswith('a/') and
                self.target_file.startswith('b/')):
            filepath = self.source_file[2:]
        elif (self.source_file.startswith('a/') and
              self.target_file == '/dev/null'):
            filepath = self.source_file[2:]
        elif (self.target_file.startswith('b/') and
              self.source_file == '/dev/null'):
            filepath = self.target_file[2:]
        else:
            filepath = self.source_file
        return filepath

    @property
    def added(self):
        """Return the file total added lines."""
        return sum([hunk.added for hunk in self])

    @property
    def removed(self):
        """Return the file total removed lines."""
        return sum([hunk.removed for hunk in self])

    @property
    def is_added_file(self):
        """Return True if this patch adds the file."""
        return (len(self) == 1 and self[0].source_start == 0 and
                self[0].source_length == 0)

    @property
    def is_removed_file(self):
        """Return True if this patch removes the file."""
        return (len(self) == 1 and self[0].target_start == 0 and
                self[0].target_length == 0)

    @property
    def is_modified_file(self):
        """Return True if this patch modifies the file."""
        return not (self.is_added_file or self.is_removed_file)


@implements_to_string
class PatchSet(list):
    """A list of PatchedFiles."""

    def __init__(self, f, encoding=None):
        super(PatchSet, self).__init__()

        # convert string inputs to StringIO objects
        if isinstance(f, basestring):
            f = self._convert_string(f, encoding)

        # make sure we pass an iterator object to parse
        data = iter(f)
        # if encoding is None, assume we are reading unicode data
        self._parse(data, encoding=encoding)

    def __repr__(self):
        return make_str('<PatchSet: %s>') % super(PatchSet, self).__repr__()

    def __str__(self):
        return ''.join(unicode(patched_file) for patched_file in self)

    def _parse(self, diff, encoding):
        current_file = None
        patch_info = None

        diff = enumerate(diff, 1)
        for unused_diff_line_no, line in diff:
            if encoding is not None:
                line = line.decode(encoding)

            # check for source file header
            is_source_filename = RE_SOURCE_FILENAME.match(line)
            if is_source_filename:
                source_file = is_source_filename.group('filename')
                source_timestamp = is_source_filename.group('timestamp')
                # reset current file
                current_file = None
                continue

            # check for target file header
            is_target_filename = RE_TARGET_FILENAME.match(line)
            if is_target_filename:
                if current_file is not None:
                    raise UnidiffParseError('Target without source: %s' % line)
                target_file = is_target_filename.group('filename')
                target_timestamp = is_target_filename.group('timestamp')
                # add current file to PatchSet
                current_file = PatchedFile(
                    patch_info, source_file, target_file,
                    source_timestamp, target_timestamp)
                self.append(current_file)
                patch_info = None
                continue

            # check for hunk header
            is_hunk_header = RE_HUNK_HEADER.match(line)
            if is_hunk_header:
                if current_file is None:
                    raise UnidiffParseError('Unexpected hunk found: %s' % line)
                current_file._parse_hunk(line, diff, encoding)
                continue

            # check for no newline marker
            is_no_newline = RE_NO_NEWLINE_MARKER.match(line)
            if is_no_newline:
                if current_file is None:
                    raise UnidiffParseError('Unexpected marker: %s' % line)
                current_file._add_no_newline_marker_to_last_hunk()
                continue

            # sometimes hunks can be followed by empty lines
            if line == '\n' and current_file is not None:
                current_file._append_trailing_empty_line()
                continue

            # if nothing has matched above then this line is a patch info
            if patch_info is None:
                current_file = None
                patch_info = PatchInfo()
            patch_info.append(line)

    @classmethod
    def from_filename(cls, filename, encoding=DEFAULT_ENCODING, errors=None):
        """Return a PatchSet instance given a diff filename."""
        with open_file(filename, 'r', encoding=encoding, errors=errors) as f:
            instance = cls(f)
        return instance

    @staticmethod
    def _convert_string(data, encoding=None, errors='strict'):
        if encoding is not None:
            # if encoding is given, assume bytes and decode
            data = unicode(data, encoding=encoding, errors=errors)
        return StringIO(data)

    @classmethod
    def from_string(cls, data, encoding=None, errors='strict'):
        """Return a PatchSet instance given a diff string."""
        return cls(cls._convert_string(data, encoding, errors))

    @property
    def added_files(self):
        """Return patch added files as a list."""
        return [f for f in self if f.is_added_file]

    @property
    def removed_files(self):
        """Return patch removed files as a list."""
        return [f for f in self if f.is_removed_file]

    @property
    def modified_files(self):
        """Return patch modified files as a list."""
        return [f for f in self if f.is_modified_file]

    @property
    def added(self):
        """Return the patch total added lines."""
        return sum([f.added for f in self])

    @property
    def removed(self):
        """Return the patch total removed lines."""
        return sum([f.removed for f in self])



================================================
FILE: patches/series
================================================
upstream-fixes/missing-dependencies.patch
upstream-fixes/fix-crash-without-enterprise-cloud-content-analysis.patch
upstream-fixes/fix-python-codecs-deprecation.patch
upstream-fixes/fix-macos-widget-rect.patch

inox-patchset/fix-building-without-safebrowsing.patch
inox-patchset/disable-autofill-download-manager.patch
inox-patchset/disable-update-pings.patch
inox-patchset/disable-rlz.patch

iridium-browser/safe-browsing-disable-reporting.patch
iridium-browser/all-add-trk-prefixes-to-possibly-evil-connections.patch

ungoogled-chromium/disable-crash-reporter.patch
ungoogled-chromium/disable-google-host-detection.patch
ungoogled-chromium/toggle-translation-via-switch.patch
ungoogled-chromium/disable-untraceable-urls.patch
ungoogled-chromium/disable-profile-avatar-downloading.patch
ungoogled-chromium/disable-gcm.patch
ungoogled-chromium/disable-domain-reliability.patch
ungoogled-chromium/block-trk-and-subdomains.patch
ungoogled-chromium/disable-gaia.patch
ungoogled-chromium/disable-fonts-googleapis-references.patch
ungoogled-chromium/disable-webstore-urls.patch
ungoogled-chromium/fix-learn-doubleclick-hsts.patch
ungoogled-chromium/disable-webrtc-log-uploader.patch
ungoogled-chromium/fix-building-with-prunned-binaries.patch
ungoogled-chromium/disable-network-time-tracker.patch
ungoogled-chromium/disable-mei-preload.patch
ungoogled-chromium/fix-building-without-safebrowsing.patch
ungoogled-chromium/remove-unused-preferences-fields.patch
ungoogled-chromium/block-requests.patch
ungoogled-chromium/disable-privacy-sandbox.patch
ungoogled-chromium/doh-changes.patch
ungoogled-chromium/extensions-manifestv2.patch
ungoogled-chromium/remove-f1-shortcut.patch
ungoogled-chromium/move-js-optimizer-unfamiliar-sites.patch

bromite/disable-fetching-field-trials.patch

ungoogled-chromium/add-ungoogled-flag-headers.patch

inox-patchset/modify-default-prefs.patch
inox-patchset/disable-battery-status-service.patch

debian/disable-google-api-warning.patch

iridium-browser/updater-disable-auto-update.patch
iridium-browser/browser-disable-profile-auto-import-on-first-run.patch

bromite/fingerprinting-flags-client-rects-and-measuretext.patch
bromite/flag-max-connections-per-host.patch
bromite/flag-fingerprinting-canvas-image-data-noise.patch

ungoogled-chromium/add-components-ungoogled.patch
ungoogled-chromium/add-ipv6-probing-option.patch
ungoogled-chromium/disable-intranet-redirect-detector.patch
ungoogled-chromium/fix-building-without-mdns-and-service-discovery.patch
ungoogled-chromium/add-flag-to-configure-extension-downloading.patch
ungoogled-chromium/add-flag-for-search-engine-collection.patch
ungoogled-chromium/add-flag-to-disable-beforeunload.patch
ungoogled-chromium/add-flag-to-force-punycode-hostnames.patch
ungoogled-chromium/add-flag-to-show-avatar-button.patch
ungoogled-chromium/add-suggestions-url-field.patch
ungoogled-chromium/add-flag-to-hide-crashed-bubble.patch
ungoogled-chromium/add-flag-to-scroll-tabs.patch
ungoogled-chromium/enable-paste-and-go-new-tab-button.patch
ungoogled-chromium/add-flag-for-bookmark-bar-ntp.patch
ungoogled-chromium/enable-menu-on-reload-button.patch
ungoogled-chromium/add-flag-for-omnibox-autocomplete-filtering.patch
ungoogled-chromium/disable-dial-repeating-discovery.patch
ungoogled-chromium/remove-uneeded-ui.patch
ungoogled-chromium/add-flag-to-close-window-with-last-tab.patch
ungoogled-chromium/add-flag-to-convert-popups-to-tabs.patch
ungoogled-chromium/add-flag-to-disable-local-history-expiration.patch
ungoogled-chromium/prepopulated-search-engines.patch
ungoogled-chromium/add-flag-to-clear-data-on-exit.patch
ungoogled-chromium/add-flag-for-grab-handle.patch
ungoogled-chromium/add-flag-for-close-confirmation.patch
ungoogled-chromium/add-flag-for-custom-ntp.patch
ungoogled-chromium/add-flag-for-tab-hover-cards.patch
ungoogled-chromium/add-flag-to-hide-tab-close-buttons.patch
ungoogled-chromium/add-flag-to-disable-tls-grease.patch
ungoogled-chromium/add-flag-to-change-http-accept-header.patch
ungoogled-chromium/add-flag-for-disabling-link-drag.patch
ungoogled-chromium/add-flag-to-hide-extensions-menu.patch
ungoogled-chromium/add-flag-to-hide-fullscreen-exit-ui.patch
ungoogled-chromium/add-flag-for-incognito-themes.patch
ungoogled-chromium/add-flags-for-referrer-customization.patch
ungoogled-chromium/add-flags-for-existing-switches.patch
ungoogled-chromium/add-flag-to-reduce-system-info.patch
ungoogled-chromium/add-flag-to-remove-client-hints.patch
ungoogled-chromium/disable-downloads-page-referrer-url.patch
ungoogled-chromium/disable-chromelabs.patch
ungoogled-chromium/remove-pac-size-limit.patch
ungoogled-chromium/enable-certificate-transparency-and-add-flag.patch
ungoogled-chromium/add-flag-to-spoof-webgl-renderer-info.patch
ungoogled-chromium/add-flag-to-increase-incognito-storage-quota.patch
ungoogled-chromium/add-credits.patch
ungoogled-chromium/disable-ai-search-shortcuts.patch

brave/chrome-importer-files.patch
brave/custom-importer.patch
brave/fix-component-content-settings-store.patch
brave/tab-cycling-mru-impl.patch

helium/core/add-zen-importer.patch
helium/core/disable-unsupported-importers.patch
helium/core/fix-building-without-safebrowsing.patch
helium/core/services-prefs.patch
helium/core/services-schema-nag.patch
helium/core/override-chrome-protocol.patch
helium/core/onboarding-page.patch
helium/core/change-chromium-branding.patch
helium/core/scan-chrome-native-messaging-hosts.patch

helium/core/search/restore-google.patch
helium/core/search/engine-defaults.patch
helium/core/search/fix-search-engine-icons.patch
helium/core/search/force-eu-search-features.patch
helium/core/search/remove-description-snippet-deps.patch

helium/settings/setup-behavior-settings-page.patch
helium/core/keyboard-shortcuts.patch
helium/core/update-default-browser-prefs.patch
helium/core/add-default-browser-reject-button.patch
helium/core/proxy-extension-downloads.patch
helium/core/reenable-update-checks.patch
helium/core/add-native-bangs.patch
helium/core/disable-bookmarks-bar.patch
helium/core/reenable-spellcheck-downloads.patch
helium/core/prefer-https-by-default.patch
helium/core/enable-tab-hover-cards.patch
helium/core/memory-saving-by-default.patch
helium/core/disable-history-clusters.patch
helium/core/unbreak-chromium-link.patch
helium/core/update-credits.patch
helium/core/disable-user-education-nags.patch
helium/core/replace-default-profile-name.patch
helium/core/disable-live-caption-completely.patch
helium/core/spoof-extension-downloader-platform.patch
helium/core/spoof-chrome-ua-brand.patch
helium/core/add-helium-versioning.patch
helium/core/enable-tab-search-toolbar-button.patch
helium/core/clean-context-menu.patch
helium/core/split-view.patch
helium/core/fix-tab-sync-unreached-error.patch
helium/core/fix-instance-id-stuck.patch

helium/core/flags-setup.patch
helium/core/add-low-power-framerate-flag.patch
helium/core/add-update-channel-flag.patch
helium/core/add-updater-preference.patch
helium/core/add-disable-ech-flag.patch
helium/core/exclude-irrelevant-flags.patch

helium/core/disable-outdated-build-detector.patch
helium/core/remove-dead-toolbar-actions.patch
helium/core/add-component-l10n-support.patch
helium/core/add-component-managed-schema-support.patch
helium/core/fix-component-extension-reenablement.patch
helium/core/ublock-setup-sources.patch
helium/core/ublock-install-as-component.patch
helium/core/ublock-reconfigure-defaults.patch
helium/core/ublock-migrate-prefs.patch
helium/core/ublock-helium-services.patch
helium/core/clean-omnibox-suggestions.patch
helium/core/increase-incognito-storage-quota.patch
helium/core/mitigate-fingerprinting-canvas.patch
helium/core/mitigate-fingerprinting-audio-context.patch
helium/core/reduce-accept-language-headers.patch
helium/core/disable-ad-topics-and-etc.patch
helium/core/enable-parallel-downloading.patch
helium/core/infinite-tab-freezing.patch
helium/core/disable-touch-ui.patch
helium/core/open-new-tabs-next-to-active-tab-option.patch
helium/core/disable-update-toast.patch
helium/core/disable-fedcm-bubble.patch
helium/core/add-middle-click-autoscroll-flag.patch
helium/core/webrtc-default-handling-policy.patch
helium/core/browser-window-context-menu.patch
helium/core/disable-ntp-footer.patch
helium/core/tab-cycling-mru.patch
helium/core/component-updates.patch

helium/settings/settings-page-icons.patch
helium/settings/move-search-suggest.patch
helium/settings/remove-autofill.patch
helium/settings/remove-profile-page-sections.patch
helium/settings/fix-page-names.patch
helium/settings/disable-safety-hub-page.patch
helium/settings/remove-results-help-link.patch
helium/settings/about-page-tweaks.patch
helium/settings/remove-translate-section.patch
helium/settings/remove-safety-hub-entry-points.patch
helium/settings/reenable-update-status.patch
helium/settings/privacy-page-tweaks.patch
helium/settings/fix-section-separators.patch
helium/settings/fix-text-on-cookies-page.patch
helium/settings/update-search-suggest-text.patch
helium/settings/fix-appearance-page.patch
helium/settings/remove-dead-imports.patch
helium/settings/enable-quad9-doh-option.patch
helium/settings/reorder-settings-menu.patch

helium/hop/setup.patch
helium/hop/disable-password-manager.patch

helium/ui/layout-constants.patch
helium/ui/layout-provider.patch
helium/ui/update-cr-components.patch
helium/ui/always-use-better-ntp.patch
helium/ui/clean-new-tab-page.patch
helium/ui/remove-toolbar-corners.patch
helium/ui/location-bar.patch
helium/ui/location-bar-intent-chip.patch
helium/ui/tabs.patch
helium/ui/tab-strip-controls.patch
helium/ui/toolbar.patch
helium/ui/toolbar-window-frame-hit-test.patch
helium/ui/toolbar-button-prefs.patch
helium/ui/omnibox.patch
helium/ui/app-menu-style.patch
helium/ui/app-menu-model.patch
helium/ui/app-menu-button.patch
helium/ui/remove-reading-list-from-app-menu.patch
helium/ui/fix-customize-side-panel.patch
helium/ui/side-panel.patch
helium/ui/remove-dead-toolbar-actions.patch
helium/ui/remove-dead-profile-actions.patch
helium/ui/clean-up-installed-extension-bubble.patch
helium/ui/selected-keyword-view.patch
helium/ui/bookmark-button-bg-fix.patch
helium/ui/restyle-ntp-tiles.patch
helium/ui/side-panel-webui.patch
helium/ui/helium-logo-icons.patch
helium/ui/square-ntp-monograms.patch
helium/ui/set-gray-as-default-theme.patch
helium/ui/improve-toast.patch
helium/ui/square-interstitial-buttons.patch
helium/ui/center-window-on-launch.patch
helium/ui/remove-devtools-annoyances.patch
helium/ui/bookmarks-bar-padding.patch
helium/ui/profile-picker-cleanup.patch
helium/ui/disable-tab-group-editor-footer.patch
helium/ui/profile-customization-cleanup.patch
helium/ui/bangs-ui.patch
helium/ui/thinner-infobar.patch
helium/ui/reduce-text-button-height.patch
helium/ui/smaller-window-grab-handle.patch
helium/ui/pwa-toolbar.patch
helium/ui/top-container.patch
helium/ui/status-bubble.patch
helium/ui/clean-incognito-guest-ntp.patch
helium/ui/enable-fluent-scrollbar.patch
helium/ui/helium-color-scheme.patch
helium/ui/improve-flags-webui.patch
helium/ui/ublock-show-in-settings.patch
helium/ui/licenses-in-credits.patch
helium/ui/remove-autofill-link-to-password-manager.patch
helium/ui/fix-caption-button-bounds.patch
helium/ui/find-bar.patch
helium/ui/remove-zoom-action.patch
helium/ui/experiments/compact-action-toolbar.patch
helium/ui/pdf-viewer.patch



================================================
FILE: patches/brave/custom-importer.patch
================================================
This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this file,
You can obtain one at https://mozilla.org/MPL/2.0/.

Copyright (c) 2019, The Brave Authors
Copyright (c) 2025, The Helium Authors

Alternatively, the contents of this file may be used under the terms
of the GNU General Public License Version 3, as described below:

Copyright (C) 2025 The Helium Authors

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.

--- a/chrome/browser/importer/importer_list.cc
+++ b/chrome/browser/importer/importer_list.cc
@@ -27,6 +27,8 @@
 #include "chrome/common/importer/edge_importer_utils_win.h"
 #endif

+#include "chrome/browser/importer/chrome_importer_list.cc"
+
 namespace {

 #if BUILDFLAG(IS_WIN)
@@ -171,20 +173,30 @@ std::vector<user_data_importer::SourcePr
   if (shell_integration::IsFirefoxDefaultBrowser()) {
     DetectFirefoxProfiles(locale, &profiles);
     DetectBuiltinWindowsProfiles(&profiles);
+    DetectChromeProfiles(&profiles);
   } else {
     DetectBuiltinWindowsProfiles(&profiles);
     DetectFirefoxProfiles(locale, &profiles);
+    DetectChromeProfiles(&profiles);
   }
 #elif BUILDFLAG(IS_MAC)
   if (shell_integration::IsFirefoxDefaultBrowser()) {
     DetectFirefoxProfiles(locale, &profiles);
     DetectSafariProfiles(&profiles);
+    DetectChromeProfiles(&profiles);
   } else {
     DetectSafariProfiles(&profiles);
     DetectFirefoxProfiles(locale, &profiles);
+    DetectChromeProfiles(&profiles);
   }
 #else
-  DetectFirefoxProfiles(locale, &profiles);
+  if (shell_integration::IsFirefoxDefaultBrowser()) {
+    DetectFirefoxProfiles(locale, &profiles);
+    DetectChromeProfiles(&profiles);
+  } else {
+    DetectChromeProfiles(&profiles);
+    DetectFirefoxProfiles(locale, &profiles);
+  }
 #endif
   if (include_interactive_profiles) {
     user_data_importer::SourceProfile bookmarks_profile;
@@ -234,5 +246,11 @@ void ImporterList::SourceProfilesLoaded(
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);

   source_profiles_.assign(profiles.begin(), profiles.end());
+
+  for (auto& profile : source_profiles_) {
+    if (profile.services_supported & user_data_importer::PASSWORDS)
+      profile.services_supported ^= user_data_importer::PASSWORDS;
+  }
+
   std::move(profiles_loaded_callback).Run();
 }
--- a/chrome/common/importer/BUILD.gn
+++ b/chrome/common/importer/BUILD.gn
@@ -3,11 +3,15 @@
 # found in the LICENSE file.

 import("//mojo/public/tools/bindings/mojom.gni")
+import("//extensions/buildflags/buildflags.gni")

 assert(!is_fuchsia, "Fuchsia shouldn't use anything in //chrome")

 mojom("interfaces") {
-  sources = [ "profile_import.mojom" ]
+  sources = [
+    "profile_import.mojom",
+    "chrome_profile_import.mojom"
+  ]

   public_deps = [
     "//mojo/public/mojom/base",
@@ -82,19 +86,28 @@ source_set("importer") {
   sources = [
     "firefox_importer_utils.cc",
     "firefox_importer_utils.h",
+    "chrome_importer_constants.h",
+    "chrome_importer_utils.cc",
+    "chrome_importer_utils.h",
     "importer_autofill_form_data_entry.cc",
     "importer_autofill_form_data_entry.h",
     "importer_bridge.cc",
     "importer_bridge.h",
     "pstore_declarations.h",
+    "scoped_copy_file.cc",
+    "scoped_copy_file.h",
   ]
-  if (is_chromeos || is_linux) {
-    sources += [ "firefox_importer_utils_linux.cc" ]
+  if (is_linux) {
+    sources += [
+      "firefox_importer_utils_linux.cc",
+      "chrome_importer_utils_linux.cc",
+    ]
   } else if (is_mac) {
     sources += [
       "firefox_importer_utils_mac.mm",
       "safari_importer_utils.h",
       "safari_importer_utils.mm",
+      "chrome_importer_utils_mac.mm",
     ]
   } else if (is_win) {
     sources += [
@@ -105,6 +118,7 @@ source_set("importer") {
       "ie_importer_utils_win.h",
       "importer_test_registry_overrider_win.cc",
       "importer_test_registry_overrider_win.h",
+      "chrome_importer_utils_win.cc",
     ]
   }
   deps = [
@@ -113,10 +127,19 @@ source_set("importer") {
     "//chrome/common:ini_parser",
     "//components/favicon_base",
     "//components/user_data_importer/common",
+    "//components/webdata/common",
     "//content/public/common",
+    "//extensions/buildflags",
     "//ui/base",
     "//url",
+    "//sql",
   ]
+
+  if (enable_extensions) {
+    deps += [
+      "//extensions/common",
+    ]
+  }
 }

 if (!is_android) {
--- a/components/user_data_importer/common/importer_type.h
+++ b/components/user_data_importer/common/importer_type.h
@@ -28,6 +28,16 @@ enum ImporterType {
 #if BUILDFLAG(IS_WIN)
   TYPE_EDGE = 6,
 #endif
+  TYPE_CHROME = 64,
+  TYPE_EDGE_CHROMIUM = 65,
+  TYPE_VIVALDI = 66,
+  TYPE_OPERA = 67,
+  TYPE_YANDEX = 68,
+  TYPE_WHALE = 69,
+  TYPE_ARC = 70,
+  TYPE_BRAVE = 71,
+  TYPE_DIA = 72,
+  TYPE_PERPLEXITY_COMET = 73,
 };

 }  // namespace user_data_importer
--- a/tools/metrics/histograms/metadata/sql/histograms.xml
+++ b/tools/metrics/histograms/metadata/sql/histograms.xml
@@ -42,6 +42,7 @@ chromium-metrics-reviews@google.com.
   <variant name="DBSCSessions" summary="DBSCSessions"/>
   <variant name="DIPS" summary="DIPS"/>
   <variant name="DownloadRecord" summary="DownloadRecord"/>
+  <variant name="Favicons" summary="Favicons"/>
   <variant name="FileIndexService" summary="FileIndexService"/>
   <variant name="FirefoxImporter" summary="FirefoxImporter"/>
   <variant name="FirstPartySets" summary="FirstPartySets"/>
--- a/components/user_data_importer/common/importer_data_types.h
+++ b/components/user_data_importer/common/importer_data_types.h
@@ -29,7 +29,8 @@ enum ImportItem {
   SEARCH_ENGINES = 1 << 4,
   HOME_PAGE = 1 << 5,
   AUTOFILL_FORM_DATA = 1 << 6,
-  ALL = (1 << 7) - 1  // All the bits should be 1, hence the -1.
+  EXTENSIONS = 1 << 7,
+  ALL = (1 << 8) - 1  // All the bits should be 1, hence the -1.
 };

 // Information about a profile needed by an importer to do import work.
@@ -111,6 +112,7 @@ enum VisitSource {
   VISIT_SOURCE_FIREFOX_IMPORTED = 1,
   VISIT_SOURCE_IE_IMPORTED = 2,
   VISIT_SOURCE_SAFARI_IMPORTED = 3,
+  VISIT_SOURCE_CHROME_IMPORTED = 4,
 };

 }  // namespace user_data_importer
--- a/chrome/common/importer/profile_import_process_param_traits_macros.h
+++ b/chrome/common/importer/profile_import_process_param_traits_macros.h
@@ -23,11 +23,11 @@
 #if BUILDFLAG(IS_WIN)
 IPC_ENUM_TRAITS_MIN_MAX_VALUE(user_data_importer::ImporterType,
                               user_data_importer::TYPE_UNKNOWN,
-                              user_data_importer::TYPE_EDGE)
+                              user_data_importer::TYPE_PERPLEXITY_COMET)
 #else
 IPC_ENUM_TRAITS_MIN_MAX_VALUE(user_data_importer::ImporterType,
                               user_data_importer::TYPE_UNKNOWN,
-                              user_data_importer::TYPE_BOOKMARKS_FILE)
+                              user_data_importer::TYPE_PERPLEXITY_COMET)
 #endif

 IPC_ENUM_TRAITS_MIN_MAX_VALUE(user_data_importer::ImportItem,
--- a/chrome/browser/ui/webui/settings/import_data_handler.cc
+++ b/chrome/browser/ui/webui/settings/import_data_handler.cc
@@ -146,6 +146,9 @@ void ImportDataHandler::HandleImportData
   if (*type_dict.FindBool(prefs::kImportDialogSearchEngine)) {
     selected_items |= user_data_importer::SEARCH_ENGINES;
   }
+  if (*type_dict.FindBool(prefs::kImportDialogExtensions)) {
+    selected_items |= user_data_importer::EXTENSIONS;
+  }

   const user_data_importer::SourceProfile& source_profile =
       importer_list_->GetSourceProfileAt(browser_index);
@@ -225,6 +228,8 @@ void ImportDataHandler::SendBrowserProfi
     browser_profile.Set(
         "autofillFormData",
         (browser_services & user_data_importer::AUTOFILL_FORM_DATA) != 0);
+    browser_profile.Set("extensions",
+                        (browser_services & user_data_importer::EXTENSIONS) != 0);

     browser_profiles.Append(std::move(browser_profile));
   }
--- a/chrome/common/pref_names.h
+++ b/chrome/common/pref_names.h
@@ -4281,6 +4281,9 @@ inline constexpr char kServiceWorkerToCo
 inline constexpr char kSharedWorkerBlobURLFixEnabled[] =
     "worker.shared_worker_blob_url_fix_enabled";

+inline constexpr char kImportDialogExtensions[] =
+    "import_dialog_extensions";
+
 // Boolean indicating whether clearing window.name when the navigation is
 // top-level, cross-site and swaps BrowsingContextGroup is allowed or not.
 inline constexpr char kClearWindowNameForNewBrowsingContextGroup[] =
--- a/chrome/browser/extensions/api/settings_private/prefs_util.cc
+++ b/chrome/browser/extensions/api/settings_private/prefs_util.cc
@@ -1147,6 +1147,8 @@ const PrefsUtil::TypedPrefMap& PrefsUtil
       settings_api::PrefType::kBoolean;
   (*s_allowlist)[::prefs::kImportDialogSearchEngine] =
       settings_api::PrefType::kBoolean;
+  (*s_allowlist)[::prefs::kImportDialogExtensions] =
+      settings_api::PrefType::kBoolean;
 #endif  // BUILDFLAG(IS_CHROMEOS)

   // Supervised Users.  This setting is queried in our Tast tests (b/241943380).
--- a/chrome/browser/ui/webui/settings/settings_ui.cc
+++ b/chrome/browser/ui/webui/settings/settings_ui.cc
@@ -58,6 +58,7 @@
 #include "chrome/browser/ui/webui/settings/about_handler.h"
 #include "chrome/browser/ui/webui/settings/accessibility_main_handler.h"
 #include "chrome/browser/ui/webui/settings/appearance_handler.h"
+#include "chrome/browser/ui/webui/settings/brave_import_data_handler.h"
 #include "chrome/browser/ui/webui/settings/browser_lifetime_handler.h"
 #include "chrome/browser/ui/webui/settings/downloads_handler.h"
 #include "chrome/browser/ui/webui/settings/font_handler.h"
@@ -203,6 +204,7 @@ void SettingsUI::RegisterProfilePrefs(
   registry->RegisterBooleanPref(prefs::kImportDialogHistory, true);
   registry->RegisterBooleanPref(prefs::kImportDialogSavedPasswords, true);
   registry->RegisterBooleanPref(prefs::kImportDialogSearchEngine, true);
+  registry->RegisterBooleanPref(prefs::kImportDialogExtensions, true);
 }

 SettingsUI::SettingsUI(content::WebUI* web_ui)
@@ -232,7 +234,7 @@ SettingsUI::SettingsUI(content::WebUI* w
   AddSettingsPageUIHandler(std::make_unique<DownloadsHandler>(profile));
   AddSettingsPageUIHandler(std::make_unique<ExtensionControlHandler>());
   AddSettingsPageUIHandler(std::make_unique<FontHandler>(profile));
-  AddSettingsPageUIHandler(std::make_unique<ImportDataHandler>());
+  AddSettingsPageUIHandler(std::make_unique<BraveImportDataHandler>());
   AddSettingsPageUIHandler(std::make_unique<HatsHandler>());

 #if BUILDFLAG(IS_WIN)
--- a/chrome/browser/ui/webui/settings/settings_localized_strings_provider.cc
+++ b/chrome/browser/ui/webui/settings/settings_localized_strings_provider.cc
@@ -999,6 +999,8 @@ void AddImportDataStrings(content::WebUI
       {"importHistory", IDS_SETTINGS_IMPORT_HISTORY_CHECKBOX},
       {"importFavorites", IDS_SETTINGS_IMPORT_FAVORITES_CHECKBOX},
       {"importPasswords", IDS_SETTINGS_IMPORT_PASSWORDS_CHECKBOX},
+      // abusing some strings here so _we_ don't have to localize them
+      {"importExtensions", IDS_EXTENSIONS_TOOLBAR_TITLE},
       {"importSearch", IDS_SETTINGS_IMPORT_SEARCH_ENGINES_CHECKBOX},
       {"importAutofillFormData",
        IDS_SETTINGS_IMPORT_AUTOFILL_FORM_DATA_CHECKBOX},
--- a/chrome/browser/resources/settings/people_page/import_data_dialog.html
+++ b/chrome/browser/resources/settings/people_page/import_data_dialog.html
@@ -84,6 +84,11 @@
                 pref="{{prefs.import_dialog_autofill_form_data}}"
                 label="$i18n{importAutofillFormData}" no-set-pref>
             </settings-checkbox>
+            <settings-checkbox id="importDialogExtensions"
+              hidden="[[!selected_.extensions]]"
+              pref="{{prefs.import_dialog_extensions}}"
+              label="$i18n{importExtensions}" no-set-pref>
+            </settings-checkbox>
           </div>
         </div>
       </div>
--- a/chrome/browser/ui/BUILD.gn
+++ b/chrome/browser/ui/BUILD.gn
@@ -1252,6 +1252,10 @@ static_library("ui") {
       "webui/settings/accessibility_main_handler.h",
       "webui/settings/appearance_handler.cc",
       "webui/settings/appearance_handler.h",
+      "webui/settings/brave_import_data_handler.cc",
+      "webui/settings/brave_import_data_handler.h",
+      "webui/settings/brave_importer_observer.cc",
+      "webui/settings/brave_importer_observer.h",
       "webui/settings/browser_lifetime_handler.cc",
       "webui/settings/browser_lifetime_handler.h",
       "webui/settings/captions_handler.cc",
@@ -1408,6 +1412,13 @@ static_library("ui") {
       ]
     }

+    if (is_mac) {
+      sources += [
+        "webui/settings/brave_full_disk_access_confirm_dialog_delegate.h",
+        "webui/settings/brave_full_disk_access_confirm_dialog_delegate_mac.mm",
+      ]
+    }
+
     # Non-android deps for "ui" target.
     deps += [
       ":browser_tab_strip",
--- a/chrome/browser/ui/webui/settings/import_data_handler.h
+++ b/chrome/browser/ui/webui/settings/import_data_handler.h
@@ -36,9 +36,9 @@ class ImportDataHandler : public Setting
   void RegisterMessages() override;
   void OnJavascriptAllowed() override {}
   void OnJavascriptDisallowed() override;
-
+  friend class BraveImportDataHandler;
  private:
-  void StartImport(const user_data_importer::SourceProfile& source_profile,
+  virtual void StartImport(const user_data_importer::SourceProfile& source_profile,
                    uint16_t imported_items);

   // Handler for the "importData" message. First argument is the selected
--- a/chrome/browser/importer/BUILD.gn
+++ b/chrome/browser/importer/BUILD.gn
@@ -6,6 +6,10 @@ assert(is_win || is_mac || is_linux || i

 source_set("importer") {
   sources = [
+    "brave_external_process_importer_client.h",
+    "brave_external_process_importer_host.h",
+    "brave_in_process_importer_bridge.h",
+    "extensions_import_helpers.h",
     "external_process_importer_client.h",
     "external_process_importer_host.h",
     "firefox_profile_lock.h",
@@ -37,6 +41,10 @@ source_set("impl") {
   public_deps = [ "//chrome/browser:browser_public_dependencies" ]

   sources = [
+    "brave_external_process_importer_client.cc",
+    "brave_external_process_importer_host.cc",
+    "brave_in_process_importer_bridge.cc",
+    "extensions_import_helpers.cc",
     "external_process_importer_client.cc",
     "external_process_importer_host.cc",
     "firefox_profile_lock.cc",
--- a/chrome/browser/importer/external_process_importer_host.h
+++ b/chrome/browser/importer/external_process_importer_host.h
@@ -79,8 +79,13 @@ class ExternalProcessImporterHost
   void NotifyImportStarted();
   void NotifyImportItemStarted(user_data_importer::ImportItem item);
   void NotifyImportItemEnded(user_data_importer::ImportItem item);
-  void NotifyImportEnded();
+  void virtual NotifyImportEnded();

+  friend class BraveExternalProcessImporterHost;
+  void set_parent_view(gfx::NativeView parent_view) {
+    parent_view_ = parent_view;
+  }
+  gfx::NativeView parent_view_ = gfx::NativeView();
  private:
   // ExternalProcessImporterHost deletes itself in OnImportEnded().
   ~ExternalProcessImporterHost() override;
--- a/components/history/core/browser/history_types.h
+++ b/components/history/core/browser/history_types.h
@@ -55,6 +55,8 @@ enum VisitSource {
   SOURCE_SAFARI_IMPORTED = 5,
   SOURCE_ACTOR = 6,
   SOURCE_OS_MIGRATION_IMPORTED = 7,
+  SOURCE_CHROME_IMPORTED = 8,
+  SOURCE_BRAVE_IMPORTED = 9,
 };

 // Corresponds to the "id" column of the "visits" SQL table.
--- a/components/history/core/browser/visit_database.cc
+++ b/components/history/core/browser/visit_database.cc
@@ -120,6 +120,8 @@ VisitSource VisitSourceFromInt(int value
     case SOURCE_SAFARI_IMPORTED:
     case SOURCE_ACTOR:
     case SOURCE_OS_MIGRATION_IMPORTED:
+    case SOURCE_CHROME_IMPORTED:
+    case SOURCE_BRAVE_IMPORTED:
       return converted;
   }
   // In cases of database corruption, SOURCE_BROWSED is a safe default value.
--- a/chrome/browser/importer/in_process_importer_bridge.cc
+++ b/chrome/browser/importer/in_process_importer_bridge.cc
@@ -53,6 +53,8 @@ history::VisitSource ConvertImporterVisi
       return history::SOURCE_IE_IMPORTED;
     case user_data_importer::VISIT_SOURCE_SAFARI_IMPORTED:
       return history::SOURCE_SAFARI_IMPORTED;
+    case user_data_importer::VISIT_SOURCE_CHROME_IMPORTED:
+      return history::SOURCE_CHROME_IMPORTED;
   }
   NOTREACHED();
 }
--- a/chrome/utility/BUILD.gn
+++ b/chrome/utility/BUILD.gn
@@ -90,6 +90,12 @@ static_library("utility") {
     sources += [
       "importer/bookmarks_file_importer.cc",
       "importer/bookmarks_file_importer.h",
+      "importer/brave_external_process_importer_bridge.cc",
+      "importer/brave_external_process_importer_bridge.h",
+      "importer/brave_profile_import_impl.cc",
+      "importer/brave_profile_import_impl.h",
+      "importer/chrome_importer.cc",
+      "importer/chrome_importer.h",
       "importer/external_process_importer_bridge.cc",
       "importer/external_process_importer_bridge.h",
       "importer/importer.cc",
--- a/chrome/utility/services.cc
+++ b/chrome/utility/services.cc
@@ -56,7 +56,9 @@

 #if !BUILDFLAG(IS_ANDROID)
 #include "chrome/common/importer/profile_import.mojom.h"
+#include "chrome/common/importer/chrome_profile_import.mojom.h"
 #include "chrome/utility/importer/profile_import_impl.h"
+#include "chrome/utility/importer/brave_profile_import_impl.h"
 #include "components/mirroring/service/mirroring_service.h"
 #include "services/passage_embeddings/passage_embeddings_service.h"
 #include "services/proxy_resolver/proxy_resolver_factory_impl.h"  // nogncheck
@@ -138,6 +140,13 @@ static_assert(BUILDFLAG(ENABLE_PRINTING)

 namespace {

+#if !BUILDFLAG(IS_ANDROID)
+auto RunBraveProfileImporter(
+    mojo::PendingReceiver<chrome::mojom::ChromeProfileImport> receiver) {
+  return std::make_unique<BraveProfileImportImpl>(std::move(receiver));
+}
+#endif
+
 auto RunFilePatcher(mojo::PendingReceiver<patch::mojom::FilePatcher> receiver) {
   return std::make_unique<patch::FilePatcherImpl>(std::move(receiver));
 }
@@ -434,6 +443,7 @@ void RegisterMainThreadServices(mojo::Se
   services.Add(ContentBookmarkParser);

 #if !BUILDFLAG(IS_ANDROID)
+  services.Add(RunBraveProfileImporter);
   services.Add(RunProfileImporter);
   services.Add(RunMirroringService);
   services.Add(RunPassageEmbeddingsService);
--- a/chrome/utility/importer/external_process_importer_bridge.h
+++ b/chrome/utility/importer/external_process_importer_bridge.h
@@ -72,7 +72,7 @@ class ExternalProcessImporterBridge : pu

   std::u16string GetLocalizedString(int message_id) override;
   // End ImporterBridge implementation.
-
+  friend class BraveExternalProcessImporterBridge;
  private:
   ~ExternalProcessImporterBridge() override;

--- a/chrome/browser/importer/external_process_importer_host.cc
+++ b/chrome/browser/importer/external_process_importer_host.cc
@@ -8,6 +8,8 @@

 #include "base/functional/bind.h"
 #include "chrome/browser/bookmarks/bookmark_model_factory.h"
+#include "chrome/browser/importer/brave_external_process_importer_client.h"
+#include "chrome/browser/importer/brave_in_process_importer_bridge.h"
 #include "chrome/browser/importer/external_process_importer_client.h"
 #include "chrome/browser/importer/firefox_profile_lock.h"
 #include "chrome/browser/importer/importer_lock_dialog.h"
@@ -102,10 +104,10 @@ void ExternalProcessImporterHost::Launch
   // bridge lives in the external process (see ProfileImportThread).
   // The ExternalProcessImporterClient created in the next line owns the bridge,
   // and will delete it.
-  InProcessImporterBridge* bridge =
-      new InProcessImporterBridge(writer_.get(),
+  BraveInProcessImporterBridge* bridge =
+      new BraveInProcessImporterBridge(writer_.get(),
                                   weak_ptr_factory_.GetWeakPtr());
-  client_ = new ExternalProcessImporterClient(
+  client_ = new BraveExternalProcessImporterClient(
       weak_ptr_factory_.GetWeakPtr(), source_profile_, items_, bridge);
   client_->Start();
 }
--- a/chrome/browser/importer/in_process_importer_bridge.h
+++ b/chrome/browser/importer/in_process_importer_bridge.h
@@ -59,7 +59,7 @@ class InProcessImporterBridge : public I

   std::u16string GetLocalizedString(int message_id) override;
   // End ImporterBridge implementation.
-
+  friend class BraveInProcessImporterBridge;
  private:
   ~InProcessImporterBridge() override;

--- a/chrome/browser/importer/importer_uma.cc
+++ b/chrome/browser/importer/importer_uma.cc
@@ -35,6 +35,7 @@ enum ImporterTypeMetrics {

 void LogImporterUseToMetrics(const std::string& metric_postfix,
                              user_data_importer::ImporterType type) {
+  return;
   ImporterTypeMetrics metrics_type = IMPORTER_METRICS_UNKNOWN;
   switch (type) {
     case user_data_importer::TYPE_UNKNOWN:
@@ -59,6 +60,9 @@ void LogImporterUseToMetrics(const std::
     case user_data_importer::TYPE_BOOKMARKS_FILE:
       metrics_type = IMPORTER_METRICS_BOOKMARKS_FILE;
       break;
+    default:
+      metrics_type = IMPORTER_METRICS_UNKNOWN;
+      break;
   }

   // Note: This leaks memory, which is the expected behavior as the factory
--- a/chrome/browser/importer/external_process_importer_client.h
+++ b/chrome/browser/importer/external_process_importer_client.h
@@ -48,10 +48,10 @@ class ExternalProcessImporterClient
       const ExternalProcessImporterClient&) = delete;

   // Launches the task to start the external process.
-  void Start();
+  virtual void Start();

   // Called by the ExternalProcessImporterHost on import cancel.
-  void Cancel();
+  virtual void Cancel();

   // chrome::mojom::ProfileImportObserver:
   void OnImportStart() override;
@@ -82,6 +82,8 @@ class ExternalProcessImporterClient
       const std::vector<ImporterAutofillFormDataEntry>&
           autofill_form_data_entry_group) override;

+ friend class BraveExternalProcessImporterClient;
+
  protected:
   ~ExternalProcessImporterClient() override;

@@ -97,7 +99,7 @@ class ExternalProcessImporterClient
   // The Mojo connections need to be torn down on the same thread that created
   // them, but the destructor is not guaranteed to be run on that thread so we
   // tear down the connections explicitly.
-  void CloseMojoHandles();
+  virtual void CloseMojoHandles();

   // These variables store data being collected from the importer until the
   // entire group has been collected and is ready to be written to the profile.
--- a/chrome/app/generated_resources.grd
+++ b/chrome/app/generated_resources.grd
@@ -11279,6 +11279,15 @@ Check your passwords anytime in <ph name
             Microsoft Edge
           </message>
         </if>
+        <message name="IDS_IMPORTED_FROM_BOOKMARK_FOLDER" desc="Name for bookmark panel folder imported from another browser">
+          Imported from <ph name="BROWSER_NAME">$1<ex>Chrome</ex></ph>
+        </message>
+        <message name="IDS_EXTENSIONS_IMPORTER_LOCK_TITLE" desc="Dialog title for importer lock dialog">
+          Import profile still in use
+        </message>
+        <message name="IDS_EXTENSIONS_IMPORTER_LOCK_TEXT" desc="The message to be displayed in the importer-lock dialog">
+          To continue importing data, first close the browser you're importing from.
+        </message>
         <message name="IDS_IMPORT_FROM_FIREFOX" desc="browser combo box: Mozilla Firefox">
           Mozilla Firefox
         </message>
--- a/chrome/browser/importer/importer_lock_dialog.h
+++ b/chrome/browser/importer/importer_lock_dialog.h
@@ -21,6 +21,11 @@ void ShowImportLockDialog(gfx::NativeWin
                           base::OnceCallback<void(bool)> callback,
                           int importer_lock_title_id = IDS_IMPORTER_LOCK_TITLE,
                           int importer_lock_text_id = IDS_IMPORTER_LOCK_TEXT);
+void ShowImportLockDialog(gfx::NativeView parent_view,
+                          gfx::NativeWindow parent,
+                          base::OnceCallback<void(bool)> callback,
+                          int importer_lock_title_id = IDS_IMPORTER_LOCK_TITLE,
+                          int importer_lock_text_id = IDS_IMPORTER_LOCK_TEXT);

 }  // namespace importer

--- a/chrome/browser/ui/views/importer/import_lock_dialog_view.cc
+++ b/chrome/browser/ui/views/importer/import_lock_dialog_view.cc
@@ -27,8 +27,36 @@ void ShowImportLockDialog(gfx::NativeWin
                              importer_lock_title_id, importer_lock_text_id);
 }

+void ShowImportLockDialog(gfx::NativeView parent_view,
+                          gfx::NativeWindow parent,
+                          base::OnceCallback<void(bool)> callback,
+                          int importer_lock_title_id,
+                          int importer_lock_text_id) {
+  ImportLockDialogView::Show(parent_view, parent, std::move(callback),
+                             importer_lock_title_id, importer_lock_text_id);
+}
+
 }  // namespace importer

+
+// static
+void ImportLockDialogView::Show(gfx::NativeView parent_view,
+                                gfx::NativeWindow parent,
+                                base::OnceCallback<void(bool)> callback,
+                                int importer_lock_title_id,
+                                int importer_lock_text_id) {
+  views::DialogDelegate::CreateDialogWidget(
+      new ImportLockDialogView(std::move(callback), importer_lock_title_id,
+                               importer_lock_text_id),
+      parent, parent_view)
+      ->Show();
+  base::RecordAction(UserMetricsAction("ImportLockDialogView_Shown"));
+}
+
+ui::mojom::ModalType ImportLockDialogView::GetModalType() const {
+  return ui::mojom::ModalType::kChild;
+}
+
 // static
 void ImportLockDialogView::Show(gfx::NativeWindow parent,
                                 base::OnceCallback<void(bool)> callback,
--- a/chrome/browser/ui/views/importer/import_lock_dialog_view.h
+++ b/chrome/browser/ui/views/importer/import_lock_dialog_view.h
@@ -23,6 +23,12 @@ class ImportLockDialogView : public view
                    base::OnceCallback<void(bool)> callback,
                    int importer_lock_title_id = IDS_IMPORTER_LOCK_TITLE,
                    int importer_lock_text_id = IDS_IMPORTER_LOCK_TEXT);
+  static void Show(gfx::NativeView parent_view,
+                   gfx::NativeWindow parent,
+                   base::OnceCallback<void(bool)> callback,
+                   int importer_lock_title_id = IDS_IMPORTER_LOCK_TITLE,
+                   int importer_lock_text_id = IDS_IMPORTER_LOCK_TEXT);
+  ui::mojom::ModalType GetModalType() const override;

  private:
   ImportLockDialogView(base::OnceCallback<void(bool)> callback,



================================================
FILE: patches/brave/fix-component-content-settings-store.patch
================================================
This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this file,
You can obtain one at https://mozilla.org/MPL/2.0/.

Copyright (c) 2025, The Brave Authors
Copyright (c) 2025, The Helium Authors

Alternatively, the contents of this file may be used under the terms
of the GNU General Public License Version 3, as described below:

Copyright (C) 2025 The Helium Authors

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.

--- a/extensions/browser/extension_registrar.cc
+++ b/extensions/browser/extension_registrar.cc
@@ -18,6 +18,7 @@
 #include "content/public/browser/browser_context.h"
 #include "content/public/browser/browser_thread.h"
 #include "content/public/browser/devtools_agent_host.h"
+#include "extensions/browser/api/content_settings/content_settings_service.h"
 #include "extensions/browser/blocklist_extension_prefs.h"
 #include "extensions/browser/delayed_install_manager.h"
 #include "extensions/browser/disable_reason.h"
@@ -540,6 +541,22 @@ void ExtensionRegistrar::AddComponentExt
   }

   AddExtension(extension);
+
+  if (!IsExtensionEnabled(extension->id()))
+    return;
+
+  // ContentSettingsStore::RegisterExtension is only called for default
+  // components on the first run with a fresh profile. All restarts of the
+  // browser after that do not call it. This causes ContentSettingsStore's
+  // `entries_` to never insert the component ID and then
+  // ContentSettingsStore::GetValueMap always returns nullptr. I don't think
+  // Chromium is affected by this simply because they don't use content settings
+  // from default component extensions.
+  extension_prefs_->OnExtensionInstalled(
+      extension, /*disable_reasons=*/{}, syncer::StringOrdinal(),
+      extensions::kInstallFlagNone, std::string(), {} /* ruleset_checksums */);
+  extensions::ContentSettingsService::Get(browser_context_)
+      ->OnExtensionPrefsLoaded(extension->id(), extension_prefs_);
 }

 void ExtensionRegistrar::RemoveComponentExtension(



================================================
FILE: patches/brave/tab-cycling-mru-impl.patch
================================================
Based on Brave's MRU tab cycling implementation, adapted for Helium.

This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this file,
You can obtain one at https://mozilla.org/MPL/2.0/.

Copyright (c) 2025, The Brave Authors
Copyright (c) 2025, The Helium Authors

Alternatively, the contents of this file may be used under the terms
of the GNU General Public License Version 3, as described below:

Copyright (C) 2025 The Helium Authors

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see <http://www.gnu.org/licenses/>.

--- a/chrome/browser/ui/tabs/tab_strip_model.cc
+++ b/chrome/browser/ui/tabs/tab_strip_model.cc
@@ -54,6 +54,7 @@
 #include "chrome/browser/ui/browser_commands.h"
 #include "chrome/browser/ui/browser_finder.h"
 #include "chrome/browser/ui/browser_window.h"
+#include "chrome/browser/ui/views/frame/browser_view.h"
 #include "chrome/browser/ui/commerce/ui_utils.h"
 #include "chrome/browser/ui/send_tab_to_self/send_tab_to_self_bubble.h"
 #include "chrome/browser/ui/tabs/features.h"
@@ -3703,6 +3704,44 @@ TabStripSelectionChange TabStripModel::S
   return selection;
 }

+void TabStripModel::SelectMRUTab(TabRelativeDirection direction,
+                                 TabStripUserGestureDetails detail) {
+  if (mru_cycle_list_.empty()) {
+    Browser* browser = chrome::FindBrowserWithTab(GetWebContentsAt(0));
+    if (!browser) {
+      return;
+    }
+
+    for (int i = 0; i < count(); ++i) {
+      mru_cycle_list_.push_back(i);
+    }
+
+    std::sort(mru_cycle_list_.begin(), mru_cycle_list_.end(),
+              [this](int a, int b) {
+                return GetWebContentsAt(a)->GetLastActiveTimeTicks() >
+                       GetWebContentsAt(b)->GetLastActiveTimeTicks();
+              });
+
+    if (BrowserView* browser_view = browser->window()->AsBrowserView()) {
+      browser_view->StartTabCycling();
+    }
+  }
+
+  if (direction == TabRelativeDirection::kNext) {
+    std::rotate(mru_cycle_list_.begin(), mru_cycle_list_.begin() + 1,
+                mru_cycle_list_.end());
+  } else {
+    std::rotate(mru_cycle_list_.rbegin(), mru_cycle_list_.rbegin() + 1,
+                mru_cycle_list_.rend());
+  }
+
+  ActivateTabAt(mru_cycle_list_[0], detail);
+}
+
+void TabStripModel::StopMRUCycling() {
+  mru_cycle_list_.clear();
+}
+
 void TabStripModel::SelectRelativeTab(TabRelativeDirection direction,
                                       TabStripUserGestureDetails detail) {
   // This may happen during automated testing or if a user somehow buffers
--- a/chrome/browser/ui/tabs/tab_strip_model.h
+++ b/chrome/browser/ui/tabs/tab_strip_model.h
@@ -611,6 +611,10 @@ class TabStripModel {
       TabStripUserGestureDetails detail = TabStripUserGestureDetails(
           TabStripUserGestureDetails::GestureType::kOther));

+  // Stops cycling through tabs in MRU order when Ctrl is released.
+  // Used in BrowserView::StopTabCycling().
+  void StopMRUCycling();
+
   // Moves the active in the specified direction. Respects group boundaries.
   void MoveTabNext();
   void MoveTabPrevious();
@@ -1139,6 +1143,11 @@ class TabStripModel {
     kPrevious,
   };

+  // Selects either the most recently used tab
+  // or the least recently used tab.
+  void SelectMRUTab(TabRelativeDirection direction,
+                    TabStripUserGestureDetails detail);
+
   // Selects either the next tab (kNext), or the previous tab (kPrevious).
   void SelectRelativeTab(TabRelativeDirection direction,
                          TabStripUserGestureDetails detail);
@@ -1393,6 +1402,9 @@ class TabStripModel {
   // Tracks whether a modal UI is showing.
   bool showing_modal_ui_ = false;

+  // List of tabs for MRU cycling
+  std::vector<int> mru_cycle_list_;
+
   base::WeakPtrFactory<TabStripModel> weak_factory_{this};
 };

--- a/chrome/browser/ui/views/frame/browser_view.cc
+++ b/chrome/browser/ui/views/frame/browser_view.cc
@@ -291,7 +291,10 @@
 #include "ui/compositor/paint_recorder.h"
 #include "ui/content_accelerators/accelerator_util.h"
 #include "ui/display/screen.h"
+#include "ui/events/event.h"
+#include "ui/events/event_handler.h"
 #include "ui/events/event_utils.h"
+#include "ui/events/keycodes/keyboard_codes.h"
 #include "ui/gfx/animation/animation_runner.h"
 #include "ui/gfx/canvas.h"
 #include "ui/gfx/color_utils.h"
@@ -309,6 +312,7 @@
 #include "ui/views/controls/button/menu_button.h"
 #include "ui/views/controls/textfield/textfield.h"
 #include "ui/views/controls/webview/webview.h"
+#include "ui/views/event_monitor.h"
 #include "ui/views/interaction/element_tracker_views.h"
 #include "ui/views/layout/fill_layout.h"
 #include "ui/views/view.h"
@@ -809,6 +813,83 @@ class BrowserView::ExclusiveAccessContex
   base::WeakPtrFactory<ExclusiveAccessContextImpl> weak_ptr_factory_{this};
 };

+// Handles events during MRU tab cycling to start/stop tab cycling.
+class TabCyclingEventHandler : public ui::EventObserver,
+                               public views::WidgetObserver {
+ public:
+  explicit TabCyclingEventHandler(BrowserView* browser_view)
+      : browser_view_(browser_view) {
+    Start();
+  }
+
+  ~TabCyclingEventHandler() override { Stop(); }
+
+  TabCyclingEventHandler(const TabCyclingEventHandler&) = delete;
+  TabCyclingEventHandler& operator=(const TabCyclingEventHandler&) = delete;
+
+ private:
+  // ui::EventObserver overrides:
+  void OnEvent(const ui::Event& event) override {
+    if (event.type() == ui::EventType::kKeyReleased &&
+        event.AsKeyEvent()->key_code() == ui::VKEY_CONTROL) {
+      // Ctrl key was released, stop the tab cycling.
+      Stop();
+      return;
+    }
+
+    if (event.type() == ui::EventType::kMousePressed) {
+      Stop();
+    }
+  }
+
+  // views::WidgetObserver overrides:
+  void OnWidgetActivationChanged(views::Widget* widget, bool active) override {
+    // We should stop cycling if other application gets active state.
+    if (!active) {
+      Stop();
+    }
+  }
+
+  // Handle browser widget closing while tab cycling is in-progress.
+  void OnWidgetClosing(views::Widget* widget) override { Stop(); }
+
+  void Start() {
+    // Add the event handler.
+    auto* widget = browser_view_->GetWidget();
+    if (widget->GetNativeWindow()) {
+      monitor_ = views::EventMonitor::CreateWindowMonitor(
+          this, widget->GetNativeWindow(),
+          {ui::EventType::kMousePressed, ui::EventType::kKeyReleased});
+    }
+    widget->AddObserver(this);
+  }
+
+  void Stop() {
+    if (!monitor_) {
+      // Already stopped.
+      return;
+    }
+
+    // Remove event handler.
+    auto* widget = browser_view_->GetWidget();
+    monitor_.reset();
+    widget->RemoveObserver(this);
+    browser_view_->StopTabCycling();
+  }
+
+  raw_ptr<BrowserView> browser_view_;
+  std::unique_ptr<views::EventMonitor> monitor_;
+};
+
+void BrowserView::StartTabCycling() {
+  tab_cycling_event_handler_ = std::make_unique<TabCyclingEventHandler>(this);
+}
+
+void BrowserView::StopTabCycling() {
+  tab_cycling_event_handler_.reset();
+  browser()->tab_strip_model()->StopMRUCycling();
+}
+
 class BrowserView::AccessibilityModeObserver : public ui::AXModeObserver {
  public:
   explicit AccessibilityModeObserver(BrowserView* browser_view)
--- a/chrome/browser/ui/views/frame/browser_view.h
+++ b/chrome/browser/ui/views/frame/browser_view.h
@@ -80,6 +80,7 @@ class LocationBarView;
 class MultiContentsView;
 class ScrimView;
 class SidePanel;
+class TabCyclingEventHandler;
 class TabDragDelegate;
 class TabSearchBubbleHost;
 class TabStrip;
@@ -555,6 +556,10 @@ class BrowserView : public BrowserWindow
   bool IsBorderlessModeEnabled() const override;
   void ShowChromeLabs() override;
   BrowserView* AsBrowserView() override;
+
+  void StartTabCycling();
+  void StopTabCycling();
+
   SharingDialog* ShowSharingDialog(content::WebContents* contents,
                                    SharingDialogData data) override;
   void ShowUpdateChromeDialog() override;
@@ -860,6 +865,7 @@ class BrowserView : public BrowserWindow
   friend class BrowserViewLayoutDelegateImpl;
   friend class BrowserViewLayoutDelegateImplOld;
   friend class BrowserViewLayoutDelegateImplBrowsertest;
+  friend class TabCyclingEventHandler;
   friend class TopControlsSlideControllerTest;
   FRIEND_TEST_ALL_PREFIXES(BrowserViewTest, BrowserView);
   FRIEND_TEST_ALL_PREFIXES(BrowserViewTest, AccessibleWindowTitle);
@@ -1387,6 +1393,8 @@ class BrowserView : public BrowserWindow

   base::CallbackListSubscription vertical_tab_subscription_;

+  std::unique_ptr<TabCyclingEventHandler> tab_cycling_event_handler_;
+
   mutable base::WeakPtrFactory<BrowserView> weak_ptr_factory_{this};
 };




================================================
FILE: patches/bromite/disable-fetching-field-trials.patch
================================================
# NOTE: Modified to remove usage of compiler #if macros
From: csagan5 <32685696+csagan5@users.noreply.github.com>
Date: Sun, 8 Jul 2018 18:16:34 +0200
Subject: Disable fetching of all field trials

---
 .../browser/flags/ChromeFeatureList.java      | 19 ++++---------------
 .../variations/service/variations_service.cc  | 12 +-----------
 2 files changed, 5 insertions(+), 26 deletions(-)

--- a/chrome/browser/flags/android/java/src/org/chromium/chrome/browser/flags/ChromeFeatureList.java
+++ b/chrome/browser/flags/android/java/src/org/chromium/chrome/browser/flags/ChromeFeatureList.java
@@ -61,7 +61,7 @@ public abstract class ChromeFeatureList
      * |kFeaturesExposedToJava| in chrome/browser/flags/android/chrome_feature_list.cc
      */
     public static String getFieldTrialParamByFeature(String featureName, String paramName) {
-        return ChromeFeatureMap.getInstance().getFieldTrialParamByFeature(featureName, paramName);
+        return "";
     }

     /**
@@ -73,8 +73,7 @@ public abstract class ChromeFeatureList
      */
     public static boolean getFieldTrialParamByFeatureAsBoolean(
             String featureName, String paramName, boolean defaultValue) {
-        return ChromeFeatureMap.getInstance()
-                .getFieldTrialParamByFeatureAsBoolean(featureName, paramName, defaultValue);
+        return defaultValue;
     }

     /**
@@ -86,8 +85,7 @@ public abstract class ChromeFeatureList
      */
     public static int getFieldTrialParamByFeatureAsInt(
             String featureName, String paramName, int defaultValue) {
-        return ChromeFeatureMap.getInstance()
-                .getFieldTrialParamByFeatureAsInt(featureName, paramName, defaultValue);
+        return defaultValue;
     }

     /**
@@ -99,8 +97,7 @@ public abstract class ChromeFeatureList
      */
     public static double getFieldTrialParamByFeatureAsDouble(
             String featureName, String paramName, double defaultValue) {
-        return ChromeFeatureMap.getInstance()
-                .getFieldTrialParamByFeatureAsDouble(featureName, paramName, defaultValue);
+        return defaultValue;
     }

     /**
--- a/components/variations/service/variations_service.cc
+++ b/components/variations/service/variations_service.cc
@@ -223,22 +223,7 @@ bool GetInstanceManipulations(const net:
 // Variations seed fetching is only enabled in official Chrome builds, if a URL
 // is specified on the command line, and for testing.
 bool IsFetchingEnabled() {
-#if BUILDFLAG(GOOGLE_CHROME_BRANDING)
-  if (base::CommandLine::ForCurrentProcess()->HasSwitch(
-          switches::kDisableVariationsSeedFetch)) {
     return false;
-  }
-#else
-  if (!base::CommandLine::ForCurrentProcess()->HasSwitch(
-          switches::kVariationsServerURL) &&
-      !g_should_fetch_for_testing) {
-    DVLOG(1)
-        << "Not performing repeated fetching in unofficial build without --"
-        << switches::kVariationsServerURL << " specified.";
-    return false;
-  }
-#endif  // BUILDFLAG(GOOGLE_CHROME_BRANDING)
-  return true;
 }

 // Returns the already downloaded first run seed, and clear the seed from the



================================================
FILE: patches/bromite/fingerprinting-flags-client-rects-and-measuretext.patch
================================================
# Adds two flags:
# 1. --fingerprinting-client-rects-noise to enable fingerprinting deception for Range::getClientRects and Element::getBoundingClientRect
# 2. --fingerprinting-canvas-measuretext-noise to enable fingerprinting deception for Canvas::measureText
# Tweaks based on https://github.com/bromite/bromite/blob/b1bc96bbd9ec549cf496e87f487a0ac35c83df0a/patches/BRM052_getClientRects-getBoundingClientRect-measureText-add-fingerprinting-mitigation.patch
# Originally based on https://github.com/ungoogled-software/ungoogled-chromium/pull/377/commits/4151259b3248f0fc5c42fa262a1d1dd43c39fb60
# chrome://flag setting added by ungoogled-chromium developers
#
# Unlike the latest Bromite patch, it was chosen to not regenerate the noise value each time the value is read to prevent potential efficiency issues with the load on the RNG.

--- a/chrome/browser/BUILD.gn
+++ b/chrome/browser/BUILD.gn
@@ -2596,6 +2596,7 @@ static_library("browser") {
     "//third_party/libyuv",
     "//third_party/metrics_proto",
     "//third_party/re2",
+    "//components/ungoogled:ungoogled_switches",
     "//third_party/webrtc_overrides:webrtc_component",
     "//third_party/widevine/cdm:buildflags",
     "//third_party/widevine/cdm:headers",
--- a/chrome/browser/about_flags.cc
+++ b/chrome/browser/about_flags.cc
@@ -191,6 +191,7 @@
 #include "components/translate/core/common/translate_util.h"
 #include "components/trusted_vault/features.h"
 #include "components/ui_devtools/switches.h"
+#include "components/ungoogled/ungoogled_switches.h"
 #include "components/variations/variations_switches.h"
 #include "components/version_info/channel.h"
 #include "components/version_info/version_info.h"
--- a/chrome/browser/bromite_flag_entries.h
+++ b/chrome/browser/bromite_flag_entries.h
@@ -4,4 +4,12 @@

 #ifndef CHROME_BROWSER_BROMITE_FLAG_ENTRIES_H_
 #define CHROME_BROWSER_BROMITE_FLAG_ENTRIES_H_
+    {"fingerprinting-client-rects-noise",
+     "Enable get*ClientRects() fingerprint deception",
+     "Scale the output values of Range::getClientRects() and Element::getBoundingClientRect() with a randomly selected factor in the range -0.0003% to 0.0003%, which are recomputed on every document initialization. ungoogled-chromium flag, Bromite feature.",
+     kOsAll, SINGLE_VALUE_TYPE(switches::kFingerprintingClientRectsNoise)},
+    {"fingerprinting-canvas-measuretext-noise",
+     "Enable Canvas::measureText() fingerprint deception",
+     "Scale the output values of Canvas::measureText() with a randomly selected factor in the range -0.0003% to 0.0003%, which are recomputed on every document initialization. ungoogled-chromium flag, Bromite feature.",
+     kOsAll, SINGLE_VALUE_TYPE(switches::kFingerprintingCanvasMeasureTextNoise)},
 #endif  // CHROME_BROWSER_BROMITE_FLAG_ENTRIES_H_
--- a/content/browser/BUILD.gn
+++ b/content/browser/BUILD.gn
@@ -299,6 +299,7 @@ source_set("browser") {
     "//third_party/re2",
     "//third_party/snappy",
     "//third_party/sqlite",
+    "//components/ungoogled:ungoogled_switches",
     "//third_party/webrtc_overrides:webrtc_component",
     "//third_party/zlib",
     "//tools/v8_context_snapshot:buildflags",
--- a/content/browser/renderer_host/render_process_host_impl.cc
+++ b/content/browser/renderer_host/render_process_host_impl.cc
@@ -84,6 +84,7 @@
 #include "components/services/storage/public/cpp/quota_error_or.h"
 #include "components/services/storage/public/mojom/cache_storage_control.mojom.h"
 #include "components/tracing/common/tracing_switches.h"
+#include "components/ungoogled/ungoogled_switches.h"
 #include "components/viz/common/switches.h"
 #include "components/viz/host/gpu_client.h"
 #include "components/viz/host/host_frame_sink_manager.h"
@@ -3698,6 +3699,8 @@ void RenderProcessHostImpl::PropagateBro
       switches::kEnableWebGLImageChromium,
       switches::kEnableWebGPUDeveloperFeatures,
       switches::kFileUrlPathAlias,
+      switches::kFingerprintingClientRectsNoise,
+      switches::kFingerprintingCanvasMeasureTextNoise,
       switches::kForceDeviceScaleFactor,
       switches::kForceDisplayColorProfile,
       switches::kForceHighContrast,
--- a/content/child/BUILD.gn
+++ b/content/child/BUILD.gn
@@ -109,6 +109,7 @@ target(link_target_type, "child") {
     "//third_party/blink/public/common:buildflags",
     "//third_party/blink/public/strings",
     "//third_party/ced",
+    "//components/ungoogled:ungoogled_switches",
     "//third_party/zlib/google:compression_utils",
     "//ui/base",
     "//ui/events/blink",
--- a/content/child/runtime_features.cc
+++ b/content/child/runtime_features.cc
@@ -42,6 +42,7 @@
 #include "third_party/blink/public/common/loader/referrer_utils.h"
 #include "third_party/blink/public/common/switches.h"
 #include "third_party/blink/public/platform/web_runtime_features.h"
+#include "components/ungoogled/ungoogled_switches.h"
 #include "ui/accessibility/accessibility_features.h"
 #include "ui/base/ui_base_features.h"
 #include "ui/events/blink/blink_features.h"
@@ -485,6 +486,10 @@ void SetRuntimeFeaturesFromCommandLine(c
        true},
       {wrf::EnableWebAudioBypassOutputBufferingOptOut,
        blink::switches::kWebAudioBypassOutputBufferingOptOut, true},
+      {wrf::EnableFingerprintingClientRectsNoise,
+       switches::kFingerprintingClientRectsNoise, true},
+      {wrf::EnableFingerprintingCanvasMeasureTextNoise,
+       switches::kFingerprintingCanvasMeasureTextNoise, true},
   };

   for (const auto& mapping : switchToFeatureMapping) {
--- a/third_party/blink/public/platform/web_runtime_features.h
+++ b/third_party/blink/public/platform/web_runtime_features.h
@@ -71,6 +71,9 @@ class BLINK_PLATFORM_EXPORT WebRuntimeFe

   static void EnableLocalNetworkAccessWebRTC(bool);

+  static void EnableFingerprintingClientRectsNoise(bool);
+  static void EnableFingerprintingCanvasMeasureTextNoise(bool);
+
   WebRuntimeFeatures() = delete;
 };

--- a/third_party/blink/renderer/core/dom/document.cc
+++ b/third_party/blink/renderer/core/dom/document.cc
@@ -41,6 +41,7 @@
 #include "base/i18n/time_formatting.h"
 #include "base/metrics/histogram_functions.h"
 #include "base/notreached.h"
+#include "base/rand_util.h"
 #include "base/task/single_thread_task_runner.h"
 #include "base/time/time.h"
 #include "base/trace_event/trace_event.h"
@@ -1089,6 +1090,11 @@ Document::Document(const DocumentInit& i
   TRACE_EVENT_WITH_FLOW0("blink", "Document::Document", TRACE_ID_LOCAL(this),
                          TRACE_EVENT_FLAG_FLOW_OUT);
   DCHECK(agent_);
+  if (RuntimeEnabledFeatures::FingerprintingClientRectsNoiseEnabled()) {
+    // Precompute -0.0003% to 0.0003% noise factor for get*ClientRect*() fingerprinting
+    noise_factor_x_ = 1 + (base::RandDouble() - 0.5) * 0.000003;
+    noise_factor_y_ = 1 + (base::RandDouble() - 0.5) * 0.000003;
+  }
   if (base::FeatureList::IsEnabled(features::kDelayAsyncScriptExecution) &&
       features::kDelayAsyncScriptExecutionDelayByDefaultParam.Get()) {
     script_runner_delayer_->Activate();
@@ -1226,6 +1232,14 @@ const Position Document::PositionAdjuste
   return Position::BeforeNode(*shadow_host);
 }

+double Document::GetNoiseFactorX() {
+  return noise_factor_x_;
+}
+
+double Document::GetNoiseFactorY() {
+  return noise_factor_y_;
+}
+
 SelectorQueryCache& Document::GetSelectorQueryCache() {
   if (!selector_query_cache_)
     selector_query_cache_ = MakeGarbageCollected<SelectorQueryCache>();
--- a/third_party/blink/renderer/core/dom/document.h
+++ b/third_party/blink/renderer/core/dom/document.h
@@ -574,6 +574,10 @@ class CORE_EXPORT Document : public Cont
     has_xml_declaration_ = has_xml_declaration ? 1 : 0;
   }

+  // Values for get*ClientRect fingerprint deception
+  double GetNoiseFactorX();
+  double GetNoiseFactorY();
+
   V8VisibilityState visibilityState() const;
   String visibilityStateAsString() const;
   bool IsPageVisible() const;
@@ -2810,6 +2814,9 @@ class CORE_EXPORT Document : public Cont

   base::ElapsedTimer start_time_;

+  double noise_factor_x_ = 1;
+  double noise_factor_y_ = 1;
+
   // The script runner is used to run scripts of the following scheduling types:
   // - ScriptSchedulingType::kAsync
   // - ScriptSchedulingType::kInOrder
--- a/third_party/blink/renderer/core/dom/element.cc
+++ b/third_party/blink/renderer/core/dom/element.cc
@@ -3195,6 +3195,9 @@ Vector<gfx::RectF> Element::GetClientRec
   }
   Vector<gfx::RectF> result;
   for (auto& quad : quads) {
+    if (RuntimeEnabledFeatures::FingerprintingClientRectsNoiseEnabled()) {
+      quad.Scale(GetDocument().GetNoiseFactorX(), GetDocument().GetNoiseFactorY());
+    }
     result.emplace_back(quad.BoundingBox());
   }
   return result;
@@ -3224,6 +3227,9 @@ gfx::RectF Element::GetBoundingClientRec
   DCHECK(element_layout_object);
   GetDocument().AdjustRectForScrollAndAbsoluteZoom(result,
                                                    *element_layout_object);
+  if (RuntimeEnabledFeatures::FingerprintingClientRectsNoiseEnabled()) {
+    result.Scale(GetDocument().GetNoiseFactorX(), GetDocument().GetNoiseFactorY());
+  }
   return result;
 }

--- a/third_party/blink/renderer/core/dom/range.cc
+++ b/third_party/blink/renderer/core/dom/range.cc
@@ -1655,6 +1655,12 @@ DOMRectList* Range::getClientRects() con
   Vector<gfx::QuadF> quads;
   GetBorderAndTextQuads(quads);

+  if (RuntimeEnabledFeatures::FingerprintingClientRectsNoiseEnabled()) {
+    for (gfx::QuadF& quad : quads) {
+      quad.Scale(owner_document_->GetNoiseFactorX(), owner_document_->GetNoiseFactorY());
+    }
+  }
+
   return MakeGarbageCollected<DOMRectList>(quads);
 }

@@ -1662,7 +1668,11 @@ DOMRect* Range::getBoundingClientRect()
   // TODO(crbug.com/1499981): This should be removed once synchronized scrolling
   // impact is understood.
   SyncScrollAttemptHeuristic::DidAccessScrollOffset();
-  return DOMRect::FromRectF(BoundingRect());
+  auto rect = BoundingRect();
+  if (RuntimeEnabledFeatures::FingerprintingClientRectsNoiseEnabled()) {
+    rect.Scale(owner_document_->GetNoiseFactorX(), owner_document_->GetNoiseFactorY());
+  }
+  return DOMRect::FromRectF(rect);
 }

 // TODO(editing-dev): We should make
--- a/third_party/blink/renderer/core/html/canvas/text_metrics.cc
+++ b/third_party/blink/renderer/core/html/canvas/text_metrics.cc
@@ -89,6 +89,24 @@ TextMetrics::TextMetrics(const Font* fon
   Update(font, direction, baseline, align, text, text_painter);
 }

+void TextMetrics::Shuffle(const double factor) {
+  // x-direction
+  width_ *= factor;
+  actual_bounding_box_left_ *= factor;
+  actual_bounding_box_right_ *= factor;
+
+  // y-direction
+  font_bounding_box_ascent_ *= factor;
+  font_bounding_box_descent_ *= factor;
+  actual_bounding_box_ascent_ *= factor;
+  actual_bounding_box_descent_ *= factor;
+  em_height_ascent_ *= factor;
+  em_height_descent_ *= factor;
+  baselines_->setAlphabetic(baselines_->alphabetic() * factor);
+  baselines_->setHanging(baselines_->hanging() * factor);
+  baselines_->setIdeographic(baselines_->ideographic() * factor);
+}
+
 void TextMetrics::Update(const Font* font,
                          const TextDirection& direction,
                          const V8CanvasTextBaseline::Enum baseline,
--- a/third_party/blink/renderer/core/html/canvas/text_metrics.h
+++ b/third_party/blink/renderer/core/html/canvas/text_metrics.h
@@ -109,6 +109,8 @@ class CORE_EXPORT TextMetrics final : pu
     float x_position_;
   };

+  void Shuffle(const double factor);
+
  private:
   void Update(const Font*,
               const TextDirection& direction,
--- a/third_party/blink/renderer/modules/canvas/canvas2d/base_rendering_context_2d.cc
+++ b/third_party/blink/renderer/modules/canvas/canvas2d/base_rendering_context_2d.cc
@@ -107,6 +107,9 @@
 // https://github.com/include-what-you-use/include-what-you-use/issues/1122
 // IWYU pragma: no_include "base/numerics/clamped_math.h"

+#include "third_party/blink/renderer/core/offscreencanvas/offscreen_canvas.h"
+#include "third_party/blink/renderer/core/frame/local_dom_window.h"
+
 namespace blink {

 class MemoryManagedPaintCanvas;
@@ -1233,9 +1236,22 @@ TextMetrics* BaseRenderingContext2D::mea
   TextDirection direction =
       ToTextDirection(state.GetDirection(), host, computed_style);

-  return MakeGarbageCollected<TextMetrics>(
+  TextMetrics* text_metrics = MakeGarbageCollected<TextMetrics>(
       font, direction, state.GetTextBaseline().AsEnum(),
       state.GetTextAlign().AsEnum(), text, host->GetPlainTextPainter());
+
+  // Scale text metrics if enabled
+  if (RuntimeEnabledFeatures::FingerprintingCanvasMeasureTextNoiseEnabled()) {
+    if (HostAsOffscreenCanvas()) {
+      if (auto* window = DynamicTo<LocalDOMWindow>(GetTopExecutionContext())) {
+        if (window->GetFrame() && window->GetFrame()->GetDocument())
+          text_metrics->Shuffle(window->GetFrame()->GetDocument()->GetNoiseFactorX());
+      }
+    } else if (canvas) {
+      text_metrics->Shuffle(canvas->GetDocument().GetNoiseFactorX());
+    }
+  }
+  return text_metrics;
 }

 String BaseRenderingContext2D::lang() const {
--- a/third_party/blink/renderer/platform/BUILD.gn
+++ b/third_party/blink/renderer/platform/BUILD.gn
@@ -1811,6 +1811,7 @@ component("platform") {
     "//components/paint_preview/common",
     "//components/search_engines:search_engine_utils",
     "//components/translate/core/language_detection",
+    "//components/ungoogled:ungoogled_switches",
     "//components/viz/client",
     "//components/viz/common",
     "//components/webrtc:net_address_utils",
--- a/third_party/blink/renderer/platform/exported/web_runtime_features.cc
+++ b/third_party/blink/renderer/platform/exported/web_runtime_features.cc
@@ -73,4 +73,12 @@ void WebRuntimeFeatures::EnableLocalNetw
   RuntimeEnabledFeatures::SetLocalNetworkAccessWebRTCEnabled(enable);
 }

+void WebRuntimeFeatures::EnableFingerprintingClientRectsNoise(bool enable) {
+  RuntimeEnabledFeatures::SetFingerprintingClientRectsNoiseEnabled(enable);
+}
+
+void WebRuntimeFeatures::EnableFingerprintingCanvasMeasureTextNoise(bool enable) {
+  RuntimeEnabledFeatures::SetFingerprintingCanvasMeasureTextNoiseEnabled(enable);
+}
+
 }  // namespace blink
--- a/third_party/blink/renderer/platform/graphics/image_data_buffer.cc
+++ b/third_party/blink/renderer/platform/graphics/image_data_buffer.cc
@@ -35,6 +35,7 @@
 #include "base/compiler_specific.h"
 #include "base/memory/ptr_util.h"
 #include "third_party/blink/renderer/platform/image-encoders/image_encoder_utils.h"
+#include "third_party/blink/renderer/platform/runtime_enabled_features.h"
 #include "third_party/blink/renderer/platform/wtf/text/base64.h"
 #include "third_party/blink/renderer/platform/wtf/text/strcat.h"
 #include "third_party/skia/include/core/SkImage.h"
--- a/third_party/blink/renderer/platform/runtime_enabled_features.json5
+++ b/third_party/blink/renderer/platform/runtime_enabled_features.json5
@@ -2441,6 +2441,12 @@
       status: "stable",
     },
     {
+      name: "FingerprintingClientRectsNoise",
+    },
+    {
+      name: "FingerprintingCanvasMeasureTextNoise",
+    },
+    {
       name: "Fledge",
       status: "stable",
       base_feature: "none",



================================================
FILE: patches/bromite/flag-fingerprinting-canvas-image-data-noise.patch
================================================
# NOTE: Changes made:
# * Added flag --fingerprinting-canvas-image-data-noise to enable/disable
#   Canvas image data fingerprinting deception
# * Removed WebGLDebugRendererInfo disabling in favor of an alternative
#   implementation in ungoogled-chromium/disable-webgl-renderer-info.patch
# * Tweak subchannel noise generation to require fewer random number generation
From: csagan5 <32685696+csagan5@users.noreply.github.com>
Date: Sat, 24 Mar 2018 05:18:03 +0100
Subject: Canvas: fingerprinting mitigations for image data and webGL

Disable webGL renderer info and modify the color data returned by ToBlob,
ToDataURL and getImageData so that it will contain randomly manipulated
pixels (maximum 10) that slightly change the color of the R,G,B components
without a visible effect.

Credits to Slaviro (https://github.com/Slaviro) for coming up with a better
approach to change color components.
---
 .../platform/graphics/image_data_buffer.cc         |   5 +
 .../platform/graphics/static_bitmap_image.cc       | 154 +++++++++++++++++++++
 .../platform/graphics/static_bitmap_image.h        |   2 +
 4 files changed, 163 insertions(+), 2 deletions(-)

--- a/chrome/browser/bromite_flag_entries.h
+++ b/chrome/browser/bromite_flag_entries.h
@@ -16,4 +16,8 @@
      flag_descriptions::kMaxConnectionsPerHostName,
      flag_descriptions::kMaxConnectionsPerHostDescription,
      kOsAll, MULTI_VALUE_TYPE(kMaxConnectionsPerHostChoices)},
+    {"fingerprinting-canvas-image-data-noise",
+     "Enable Canvas image data fingerprint deception",
+     "Slightly modifies at most 10 pixels in Canvas image data extracted via JS APIs. ungoogled-chromium flag, Bromite feature.",
+     kOsAll, SINGLE_VALUE_TYPE(switches::kFingerprintingCanvasImageDataNoise)},
 #endif  // CHROME_BROWSER_BROMITE_FLAG_ENTRIES_H_
--- a/content/browser/renderer_host/render_process_host_impl.cc
+++ b/content/browser/renderer_host/render_process_host_impl.cc
@@ -3701,6 +3701,7 @@ void RenderProcessHostImpl::PropagateBro
       switches::kFileUrlPathAlias,
       switches::kFingerprintingClientRectsNoise,
       switches::kFingerprintingCanvasMeasureTextNoise,
+      switches::kFingerprintingCanvasImageDataNoise,
       switches::kForceDeviceScaleFactor,
       switches::kForceDisplayColorProfile,
       switches::kForceHighContrast,
--- a/content/child/runtime_features.cc
+++ b/content/child/runtime_features.cc
@@ -490,6 +490,8 @@ void SetRuntimeFeaturesFromCommandLine(c
        switches::kFingerprintingClientRectsNoise, true},
       {wrf::EnableFingerprintingCanvasMeasureTextNoise,
        switches::kFingerprintingCanvasMeasureTextNoise, true},
+      {wrf::EnableFingerprintingCanvasImageDataNoise,
+       switches::kFingerprintingCanvasImageDataNoise, true},
   };

   for (const auto& mapping : switchToFeatureMapping) {
--- a/third_party/blink/public/platform/web_runtime_features.h
+++ b/third_party/blink/public/platform/web_runtime_features.h
@@ -73,6 +73,7 @@ class BLINK_PLATFORM_EXPORT WebRuntimeFe

   static void EnableFingerprintingClientRectsNoise(bool);
   static void EnableFingerprintingCanvasMeasureTextNoise(bool);
+  static void EnableFingerprintingCanvasImageDataNoise(bool);

   WebRuntimeFeatures() = delete;
 };
--- a/third_party/blink/renderer/modules/canvas/canvas2d/base_rendering_context_2d.cc
+++ b/third_party/blink/renderer/modules/canvas/canvas2d/base_rendering_context_2d.cc
@@ -557,6 +557,9 @@ ImageData* BaseRenderingContext2D::getIm
           snapshot->PaintImageForCurrentFrame().GetSkImageInfo().bounds();
       DCHECK(!bounds.intersect(SkIRect::MakeXYWH(sx, sy, sw, sh)));
     }
+    if (read_pixels_successful && RuntimeEnabledFeatures::FingerprintingCanvasImageDataNoiseEnabled()) {
+      StaticBitmapImage::ShuffleSubchannelColorData(image_data_pixmap.addr(), image_data_pixmap.info(), sx, sy);
+    }
   }

   return image_data;
--- a/third_party/blink/renderer/platform/BUILD.gn
+++ b/third_party/blink/renderer/platform/BUILD.gn
@@ -1753,7 +1753,9 @@ component("platform") {
     "//third_party/blink/renderer:non_test_config",
   ]

-  include_dirs = []
+  include_dirs = [
+    "//third_party/skia/include/private", # For shuffler in graphics/static_bitmap_image.cc
+  ]

   allow_circular_includes_from = [
     "//third_party/blink/renderer/platform/blob",
--- a/third_party/blink/renderer/platform/exported/web_runtime_features.cc
+++ b/third_party/blink/renderer/platform/exported/web_runtime_features.cc
@@ -81,4 +81,8 @@ void WebRuntimeFeatures::EnableFingerpri
   RuntimeEnabledFeatures::SetFingerprintingCanvasMeasureTextNoiseEnabled(enable);
 }

+void WebRuntimeFeatures::EnableFingerprintingCanvasImageDataNoise(bool enable) {
+  RuntimeEnabledFeatures::SetFingerprintingCanvasImageDataNoiseEnabled(enable);
+}
+
 }  // namespace blink
--- a/third_party/blink/renderer/platform/graphics/static_bitmap_image.cc
+++ b/third_party/blink/renderer/platform/graphics/static_bitmap_image.cc
@@ -4,6 +4,8 @@

 #include "third_party/blink/renderer/platform/graphics/static_bitmap_image.h"

+#include "base/rand_util.h"
+#include "base/logging.h"
 #include "base/numerics/checked_math.h"
 #include "gpu/command_buffer/client/gles2_interface.h"
 #include "third_party/blink/renderer/platform/graphics/accelerated_static_bitmap_image.h"
@@ -11,11 +13,13 @@
 #include "third_party/blink/renderer/platform/graphics/image_observer.h"
 #include "third_party/blink/renderer/platform/graphics/paint/paint_image.h"
 #include "third_party/blink/renderer/platform/graphics/unaccelerated_static_bitmap_image.h"
+#include "third_party/blink/renderer/platform/runtime_enabled_features.h"
 #include "third_party/blink/renderer/platform/transforms/affine_transform.h"
 #include "third_party/skia/include/core/SkCanvas.h"
 #include "third_party/skia/include/core/SkImage.h"
 #include "third_party/skia/include/core/SkPaint.h"
 #include "third_party/skia/include/core/SkSurface.h"
+#include "third_party/skia/src/core/SkColorData.h"
 #include "ui/gfx/geometry/skia_conversions.h"
 #include "v8/include/v8.h"

@@ -114,4 +118,154 @@ void StaticBitmapImage::DrawHelper(cc::P
                         ToSkiaRectConstraint(draw_options.clamping_mode));
 }

+// set the component to maximum-delta if it is >= maximum, or add to existing color component (color + delta)
+#define shuffleComponent(color, max, delta) ( (color) >= (max) ? ((max)-(delta)) : ((color)+(delta)) )
+
+#define writable_addr(T, p, stride, x, y) (T*)((const char *)p + y * stride + x * sizeof(T))
+
+void StaticBitmapImage::ShuffleSubchannelColorData(const void *addr, const SkImageInfo& info, int srcX, int srcY) {
+  auto w = info.width() - srcX, h = info.height() - srcY;
+
+  // skip tiny images; info.width()/height() can also be 0
+  if ((w < 8) || (h < 8)) {
+    return;
+  }
+
+  // generate the first random number here
+  double shuffleX = base::RandDouble();
+
+  // cap maximum pixels to change
+  auto pixels = (w + h) / 128;
+  if (pixels > 10) {
+    pixels = 10;
+  } else if (pixels < 2) {
+    pixels = 2;
+  }
+
+  auto colorType = info.colorType();
+  auto fRowBytes = info.minRowBytes(); // stride
+
+  DLOG(INFO) << "BRM: ShuffleSubchannelColorData() w=" << w << " h=" << h << " colorType=" << colorType << " fRowBytes=" << fRowBytes;
+
+  // second random number (for y/height)
+  double shuffleY = base::RandDouble();
+
+  // calculate random coordinates using bisection
+  auto currentW = w, currentH = h;
+  for(;pixels >= 0; pixels--) {
+    int x = currentW * shuffleX, y = currentH * shuffleY;
+
+    // calculate randomisation amounts for each RGB component
+    uint8_t shuffleR = base::RandInt(0, 4);
+    uint8_t shuffleG = (shuffleR + x) % 4;
+    uint8_t shuffleB = (shuffleG + y) % 4;
+
+    // manipulate pixel data to slightly change the R, G, B components
+    switch (colorType) {
+      case kAlpha_8_SkColorType:
+      {
+         auto *pixel = writable_addr(uint8_t, addr, fRowBytes, x, y);
+         auto r = SkColorGetR(*pixel), g = SkColorGetG(*pixel), b = SkColorGetB(*pixel), a = SkColorGetA(*pixel);
+
+         r = shuffleComponent(r, UINT8_MAX-1, shuffleR);
+         g = shuffleComponent(g, UINT8_MAX-1, shuffleG);
+         b = shuffleComponent(b, UINT8_MAX-1, shuffleB);
+         // alpha is left unchanged
+
+         *pixel = SkColorSetARGB(a, r, g, b);
+      }
+      break;
+      case kGray_8_SkColorType:
+      {
+         auto *pixel = writable_addr(uint8_t, addr, fRowBytes, x, y);
+         *pixel = shuffleComponent(*pixel, UINT8_MAX-1, shuffleB);
+      }
+      break;
+      case kRGB_565_SkColorType:
+      {
+         auto *pixel = writable_addr(uint16_t, addr, fRowBytes, x, y);
+         unsigned    r = SkPacked16ToR32(*pixel);
+         unsigned    g = SkPacked16ToG32(*pixel);
+         unsigned    b = SkPacked16ToB32(*pixel);
+
+         r = shuffleComponent(r, 31, shuffleR);
+         g = shuffleComponent(g, 63, shuffleG);
+         b = shuffleComponent(b, 31, shuffleB);
+
+         unsigned r16 = (r & SK_R16_MASK) << SK_R16_SHIFT;
+         unsigned g16 = (g & SK_G16_MASK) << SK_G16_SHIFT;
+         unsigned b16 = (b & SK_B16_MASK) << SK_B16_SHIFT;
+
+         *pixel = r16 | g16 | b16;
+      }
+      break;
+      case kARGB_4444_SkColorType:
+      {
+         auto *pixel = writable_addr(uint16_t, addr, fRowBytes, x, y);
+         auto a = SkGetPackedA4444(*pixel), r = SkGetPackedR4444(*pixel), g = SkGetPackedG4444(*pixel), b = SkGetPackedB4444(*pixel);
+
+         r = shuffleComponent(r, 15, shuffleR);
+         g = shuffleComponent(g, 15, shuffleG);
+         b = shuffleComponent(b, 15, shuffleB);
+         // alpha is left unchanged
+
+         unsigned a4 = (a & 0xF) << SK_A4444_SHIFT;
+         unsigned r4 = (r & 0xF) << SK_R4444_SHIFT;
+         unsigned g4 = (g & 0xF) << SK_G4444_SHIFT;
+         unsigned b4 = (b & 0xF) << SK_B4444_SHIFT;
+
+         *pixel = r4 | b4 | g4 | a4;
+      }
+      break;
+      case kRGBA_8888_SkColorType:
+      {
+         auto *pixel = writable_addr(uint32_t, addr, fRowBytes, x, y);
+         auto a = SkGetPackedA32(*pixel), r = SkGetPackedR32(*pixel), g = SkGetPackedG32(*pixel), b = SkGetPackedB32(*pixel);
+
+         r = shuffleComponent(r, UINT8_MAX-1, shuffleR);
+         g = shuffleComponent(g, UINT8_MAX-1, shuffleG);
+         b = shuffleComponent(b, UINT8_MAX-1, shuffleB);
+         // alpha is left unchanged
+
+         *pixel = (a << SK_A32_SHIFT) | (r << SK_R32_SHIFT) |
+                  (g << SK_G32_SHIFT) | (b << SK_B32_SHIFT);
+      }
+      break;
+      case kBGRA_8888_SkColorType:
+      {
+         auto *pixel = writable_addr(uint32_t, addr, fRowBytes, x, y);
+         auto a = SkGetPackedA32(*pixel), b = SkGetPackedR32(*pixel), g = SkGetPackedG32(*pixel), r = SkGetPackedB32(*pixel);
+
+         r = shuffleComponent(r, UINT8_MAX-1, shuffleR);
+         g = shuffleComponent(g, UINT8_MAX-1, shuffleG);
+         b = shuffleComponent(b, UINT8_MAX-1, shuffleB);
+         // alpha is left unchanged
+
+         *pixel = (a << SK_BGRA_A32_SHIFT) | (r << SK_BGRA_R32_SHIFT) |
+                  (g << SK_BGRA_G32_SHIFT) | (b << SK_BGRA_B32_SHIFT);
+      }
+      break;
+      default:
+         // the remaining formats are not expected to be used in Chromium
+         LOG(WARNING) << "BRM: ShuffleSubchannelColorData(): Ignoring pixel format";
+         return;
+    }
+
+    // keep bisecting or reset current width/height as needed
+    if (x == 0) {
+       currentW = w;
+    } else {
+       currentW = x;
+    }
+    if (y == 0) {
+       currentH = h;
+    } else {
+       currentH = y;
+    }
+  }
+}
+
+#undef writable_addr
+#undef shuffleComponent
+
 }  // namespace blink
--- a/third_party/blink/renderer/platform/graphics/static_bitmap_image.h
+++ b/third_party/blink/renderer/platform/graphics/static_bitmap_image.h
@@ -38,6 +38,8 @@ class PLATFORM_EXPORT StaticBitmapImage

   StaticBitmapImage(ImageOrientation orientation) : orientation_(orientation) {}

+  static void ShuffleSubchannelColorData(const void *addr, const SkImageInfo& info, int srcX, int srcY);
+
   bool IsStaticBitmapImage() const override { return true; }

   // Methods overridden by all sub-classes
--- a/third_party/blink/renderer/platform/image-encoders/image_encoder.cc
+++ b/third_party/blink/renderer/platform/image-encoders/image_encoder.cc
@@ -13,6 +13,8 @@
 #include <stdio.h>  // Needed by jpeglib.h

 #include "jpeglib.h"  // for JPEG_MAX_DIMENSION
+#include "third_party/blink/renderer/platform/graphics/static_bitmap_image.h"
+#include "third_party/blink/renderer/platform/runtime_enabled_features.h"
 #include "third_party/libwebp/src/src/webp/encode.h"  // for WEBP_MAX_DIMENSION

 namespace blink {
@@ -44,6 +46,10 @@ bool ImageEncoder::Encode(Vector<unsigne
                           const SkPixmap& src,
                           ImageEncodingMimeType mime_type,
                           double quality) {
+  if (RuntimeEnabledFeatures::FingerprintingCanvasImageDataNoiseEnabled()) {
+    // shuffle subchannel color data within the pixmap
+    StaticBitmapImage::ShuffleSubchannelColorData(src.writable_addr(), src.info(), 0, 0);
+  }
   switch (mime_type) {
     case kMimeTypeJpeg: {
       SkJpegEncoder::Options options;
--- a/third_party/blink/renderer/platform/runtime_enabled_features.json5
+++ b/third_party/blink/renderer/platform/runtime_enabled_features.json5
@@ -2447,6 +2447,9 @@
       name: "FingerprintingCanvasMeasureTextNoise",
     },
     {
+      name: "FingerprintingCanvasImageDataNoise",
+    },
+    {
       name: "Fledge",
       status: "stable",
       base_feature: "none",



================================================
FILE: patches/bromite/flag-max-connections-per-host.patch
================================================
From: csagan5 <32685696+csagan5@users.noreply.github.com>
Date: Sun, 8 Jul 2018 22:42:04 +0200
Subject: Add flag to configure maximum connections per host

With the introduction of this flag it is possible to increase the maximum
allowed connections per host; this can however be detrimental to devices
with limited CPU/memory resources and it is disabled by default.
---
 chrome/browser/about_flags.cc                            |  8 ++++++++
 chrome/browser/flag_descriptions.cc                      |  4 ++++
 chrome/browser/flag_descriptions.h                       |  3 +++
 .../common/network_features.cc                           |  3 +++
 .../common/network_features.h                            |  4 ++++
 .../common/network_switch_list.h                         |  4 ++++
 net/socket/client_socket_pool_manager.cc                 | 16 ++++++++++++++++
 7 files changed, 42 insertions(+)

--- a/chrome/browser/BUILD.gn
+++ b/chrome/browser/BUILD.gn
@@ -2269,6 +2269,7 @@ static_library("browser") {
     "//components/net_log",
     "//components/network_hints/common:mojo_bindings",
     "//components/network_session_configurator/browser",
+    "//components/network_session_configurator/common",
     "//components/network_time",
     "//components/network_time/time_tracker",
     "//components/no_state_prefetch/browser",
--- a/chrome/browser/bromite_flag_choices.h
+++ b/chrome/browser/bromite_flag_choices.h
@@ -4,4 +4,8 @@

 #ifndef CHROME_BROWSER_BROMITE_FLAG_CHOICES_H_
 #define CHROME_BROWSER_BROMITE_FLAG_CHOICES_H_
+const FeatureEntry::Choice kMaxConnectionsPerHostChoices[] = {
+    {features::kMaxConnectionsPerHostChoiceDefault, "", ""},
+    {features::kMaxConnectionsPerHostChoice15, switches::kMaxConnectionsPerHost, "15"},
+};
 #endif  // CHROME_BROWSER_BROMITE_FLAG_CHOICES_H_
--- a/chrome/browser/bromite_flag_entries.h
+++ b/chrome/browser/bromite_flag_entries.h
@@ -12,4 +12,8 @@
      "Enable Canvas::measureText() fingerprint deception",
      "Scale the output values of Canvas::measureText() with a randomly selected factor in the range -0.0003% to 0.0003%, which are recomputed on every document initialization. ungoogled-chromium flag, Bromite feature.",
      kOsAll, SINGLE_VALUE_TYPE(switches::kFingerprintingCanvasMeasureTextNoise)},
+    {"max-connections-per-host",
+     flag_descriptions::kMaxConnectionsPerHostName,
+     flag_descriptions::kMaxConnectionsPerHostDescription,
+     kOsAll, MULTI_VALUE_TYPE(kMaxConnectionsPerHostChoices)},
 #endif  // CHROME_BROWSER_BROMITE_FLAG_ENTRIES_H_
--- a/chrome/browser/browser_process_impl.cc
+++ b/chrome/browser/browser_process_impl.cc
@@ -22,6 +22,7 @@
 #include "base/functional/callback.h"
 #include "base/functional/callback_helpers.h"
 #include "base/location.h"
+#include "base/logging.h"
 #include "base/memory/ptr_util.h"
 #include "base/metrics/histogram_functions.h"
 #include "base/metrics/histogram_macros.h"
@@ -29,6 +30,7 @@
 #include "base/notreached.h"
 #include "base/path_service.h"
 #include "base/run_loop.h"
+#include "base/strings/string_number_conversions.h"
 #include "base/synchronization/waitable_event.h"
 #include "base/task/sequenced_task_runner.h"
 #include "base/task/single_thread_task_runner.h"
@@ -115,6 +117,7 @@
 #include "components/metrics/metrics_service.h"
 #include "components/metrics_services_manager/metrics_services_manager.h"
 #include "components/metrics_services_manager/metrics_services_manager_client.h"
+#include "components/network_session_configurator/common/network_switches.h"
 #include "components/network_time/network_time_tracker.h"
 #include "components/os_crypt/async/browser/os_crypt_async.h"
 #include "components/permissions/permissions_client.h"
@@ -149,6 +152,7 @@
 #include "extensions/common/constants.h"
 #include "media/media_buildflags.h"
 #include "mojo/public/cpp/bindings/pending_receiver.h"
+#include "net/socket/client_socket_pool_manager.h"
 #include "printing/buildflags/buildflags.h"
 #include "services/network/public/cpp/features.h"
 #include "services/network/public/cpp/network_switches.h"
@@ -432,6 +436,18 @@ void BrowserProcessImpl::Init() {
   pref_change_registrar_.Add(metrics::prefs::kMetricsReportingEnabled,
                              base::BindRepeating(&ApplyMetricsReportingPolicy));

+  int max_connections_per_host = 0;
+  auto switch_value = base::CommandLine::ForCurrentProcess()->GetSwitchValueASCII(
+      switches::kMaxConnectionsPerHost);
+  if (!switch_value.empty() && !base::StringToInt(switch_value, &max_connections_per_host)) {
+    LOG(DFATAL) << "--" << switches::kMaxConnectionsPerHost
+      << " expected integer; got (\"" << switch_value << "\" instead)";
+  }
+  if (max_connections_per_host != 0) {
+    net::ClientSocketPoolManager::set_max_sockets_per_group(
+        net::HttpNetworkSession::NORMAL_SOCKET_POOL, max_connections_per_host);
+  }
+
   DCHECK(!webrtc_event_log_manager_);
   webrtc_event_log_manager_ = WebRtcEventLogManager::CreateSingletonInstance();

--- a/chrome/browser/flag_descriptions.h
+++ b/chrome/browser/flag_descriptions.h
@@ -2753,6 +2753,10 @@ inline constexpr char kLogJsConsoleMessa
     "Enable logging JS console messages in system logs, please note that they "
     "may contain PII.";

+inline constexpr char kMaxConnectionsPerHostName[] = "Maximum connections per host";
+inline constexpr char kMaxConnectionsPerHostDescription[] =
+     "Customize maximum allowed connections per host. ungoogled-chromium flag, Bromite feature.";
+
 inline constexpr char kMediaRouterCastAllowAllIPsName[] =
     "Connect to Cast devices on all IP addresses";
 inline constexpr char kMediaRouterCastAllowAllIPsDescription[] =
--- a/components/network_session_configurator/common/network_features.cc
+++ b/components/network_session_configurator/common/network_features.cc
@@ -8,4 +8,7 @@

 namespace features {

+const char kMaxConnectionsPerHostChoiceDefault[] = "6",
+                 kMaxConnectionsPerHostChoice15[] = "15";
+
 }  // namespace features
--- a/components/network_session_configurator/common/network_features.h
+++ b/components/network_session_configurator/common/network_features.h
@@ -10,6 +10,10 @@

 namespace features {

+NETWORK_SESSION_CONFIGURATOR_EXPORT extern const char kMaxConnectionsPerHostChoiceDefault[],
+                 kMaxConnectionsPerHostChoice6[],
+                 kMaxConnectionsPerHostChoice15[];
+
 }  // namespace features

 #endif  // COMPONENTS_NETWORK_SESSION_CONFIGURATOR_COMMON_NETWORK_FEATURES_H_
--- a/components/network_session_configurator/common/network_switch_list.h
+++ b/components/network_session_configurator/common/network_switch_list.h
@@ -19,6 +19,10 @@ NETWORK_SWITCH(kEnableUserAlternateProto
 // Enables the QUIC protocol.  This is a temporary testing flag.
 NETWORK_SWITCH(kEnableQuic, "enable-quic")

+// Allows specifying a higher number of maximum connections per host
+// (15 instead of 6, mirroring the value Mozilla uses).
+NETWORK_SWITCH(kMaxConnectionsPerHost, "max-connections-per-host")
+
 // Ignores certificate-related errors.
 NETWORK_SWITCH(kIgnoreCertificateErrors, "ignore-certificate-errors")




================================================
FILE: patches/debian/disable-google-api-warning.patch
================================================
description: disable the google api key warning when those aren't found
author: Michael Gilbert <mgilbert@debian.org>

--- a/chrome/browser/ui/startup/infobar_utils.cc
+++ b/chrome/browser/ui/startup/infobar_utils.cc
@@ -188,10 +188,6 @@ void AddInfoBarsIfNecessary(BrowserWindo
   infobars::ContentInfoBarManager* infobar_manager =
       infobars::ContentInfoBarManager::FromWebContents(web_contents);

-  if (!google_apis::HasAPIKeyConfigured()) {
-    GoogleApiKeysInfoBarDelegate::Create(infobar_manager);
-  }
-
   if (ObsoleteSystem::IsObsoleteNowOrSoon()) {
     PrefService* local_state = g_browser_process->local_state();
     if (!local_state ||



================================================
FILE: patches/helium/core/add-component-l10n-support.patch
================================================
--- a/extensions/common/extension_l10n_util.h
+++ b/extensions/common/extension_l10n_util.h
@@ -81,7 +81,8 @@ bool LocalizeManifest(const extensions::
 bool LocalizeExtension(const base::FilePath& extension_path,
                        base::Value::Dict* manifest,
                        GzippedMessagesPermission gzip_permission,
-                       std::string* error);
+                       std::string* error,
+                       bool is_component = false);

 // Adds locale_name to the extension if it's in chrome_locales, and
 // if messages file is present (we don't check content of messages file here).
@@ -129,6 +130,11 @@ extensions::MessageBundle* LoadMessageCa
     GzippedMessagesPermission gzip_permission,
     std::string* error);

+extensions::MessageBundle* LoadComponentMessageCatalogs(
+    const base::FilePath& extension_root,
+    const std::string& default_locale,
+    std::string* error);
+
 // Loads message catalogs for all locales to check for validity. Used for
 // validating unpacked extensions.
 bool ValidateExtensionLocales(const base::FilePath& extension_path,
--- a/extensions/common/extension_l10n_util.cc
+++ b/extensions/common/extension_l10n_util.cc
@@ -18,14 +18,18 @@
 #include "base/files/file_enumerator.h"
 #include "base/files/file_util.h"
 #include "base/json/json_file_value_serializer.h"
+#include "base/json/json_string_value_serializer.h"
 #include "base/json/json_reader.h"
 #include "base/logging.h"
+#include "base/memory/ref_counted_memory.h"
 #include "base/no_destructor.h"
 #include "base/strings/strcat.h"
 #include "base/strings/string_util.h"
 #include "base/strings/stringprintf.h"
 #include "base/strings/utf_string_conversions.h"
 #include "base/values.h"
+#include "extensions/browser/component_extension_resource_manager.h"
+#include "extensions/browser/extensions_browser_client.h"
 #include "extensions/common/constants.h"
 #include "extensions/common/error_utils.h"
 #include "extensions/common/extension.h"
@@ -38,6 +42,7 @@
 #include "third_party/icu/source/common/unicode/uloc.h"
 #include "third_party/zlib/google/compression_utils.h"
 #include "ui/base/l10n/l10n_util.h"
+#include "ui/base/resource/resource_bundle.h"

 namespace errors = extensions::manifest_errors;
 namespace keys = extensions::manifest_keys;
@@ -114,6 +119,19 @@ std::optional<base::Value::Dict> LoadMes
   return dictionary;
 }

+std::optional<base::Value::Dict> LoadMessageFile(
+    int resource_id, std::string* error) {
+  const ui::ResourceBundle& rb = ui::ResourceBundle::GetSharedInstance();
+  JSONStringValueDeserializer messages_deserializer(
+      base::as_string_view(*rb.LoadDataResourceBytes(resource_id)));
+
+  if (auto value = messages_deserializer.Deserialize(nullptr, error); value) {
+    return std::move(*value).TakeDict();
+  }
+
+  return std::nullopt;
+}
+
 // Localizes manifest value of string type for a given key.
 bool LocalizeManifestValue(const std::string& key,
                            const extensions::MessageBundle& messages,
@@ -361,13 +379,16 @@ bool LocalizeManifest(const extensions::
 bool LocalizeExtension(const base::FilePath& extension_path,
                        base::Value::Dict* manifest,
                        GzippedMessagesPermission gzip_permission,
-                       std::string* error) {
+                       std::string* error,
+                       bool is_component) {
   DCHECK(manifest);

   std::string default_locale = GetDefaultLocaleFromManifest(*manifest, error);

   std::unique_ptr<extensions::MessageBundle> message_bundle(
-      extensions::file_util::LoadMessageBundle(extension_path, default_locale,
+      is_component ? extensions::file_util::LoadComponentMessageBundle(extension_path,
+                                                                default_locale, error)
+      : extensions::file_util::LoadMessageBundle(extension_path, default_locale,
                                                gzip_permission, error));

   if (!message_bundle && !error->empty())
@@ -505,6 +526,42 @@ extensions::MessageBundle* LoadMessageCa
   return extensions::MessageBundle::Create(catalogs, error);
 }

+extensions::MessageBundle* LoadComponentMessageCatalogs(
+    const base::FilePath& extension_root,
+    const std::string& default_locale,
+    std::string* error) {
+  std::vector<std::string> all_fallback_locales;
+  base::FilePath locale_path(extensions::kLocaleFolder);
+
+  auto* manager =
+      extensions::ExtensionsBrowserClient::Get()->GetComponentExtensionResourceManager();
+
+  GetAllFallbackLocales(default_locale, &all_fallback_locales);
+
+  extensions::MessageBundle::CatalogVector catalogs;
+  for (const auto& fallback_locale : all_fallback_locales) {
+    base::FilePath this_locale_path =
+      locale_path.AppendASCII(fallback_locale)
+                 .Append(extensions::kMessagesFilename);
+    int resource_id = 0;
+
+    if (!manager->IsComponentExtensionResource(
+          extension_root, this_locale_path, &resource_id)) {
+      continue;
+    }
+
+    std::optional<base::Value::Dict> catalog = LoadMessageFile(resource_id, error);
+    if (!catalog.has_value()) {
+      return nullptr;
+    }
+
+    catalogs.push_back(std::move(*catalog));
+  }
+
+  return extensions::MessageBundle::Create(
+           catalogs, error);
+}
+
 bool ValidateExtensionLocales(const base::FilePath& extension_path,
                               const base::Value::Dict& manifest,
                               std::string* error) {
--- a/extensions/browser/l10n_file_util.h
+++ b/extensions/browser/l10n_file_util.h
@@ -47,7 +47,8 @@ LoadMessageBundleSubstitutionMapFromPath
     const std::vector<base::FilePath>& paths,
     const ExtensionId& extension_id,
     const std::string& default_locale,
-    extension_l10n_util::GzippedMessagesPermission gzip_permission);
+    extension_l10n_util::GzippedMessagesPermission gzip_permission,
+    bool is_component = false);

 }  // namespace extensions::l10n_file_util

--- a/extensions/browser/l10n_file_util.cc
+++ b/extensions/browser/l10n_file_util.cc
@@ -38,7 +38,8 @@ LoadMessageBundleSubstitutionMapFromPath
     const std::vector<base::FilePath>& paths,
     const ExtensionId& extension_id,
     const std::string& default_locale,
-    extension_l10n_util::GzippedMessagesPermission gzip_permission) {
+    extension_l10n_util::GzippedMessagesPermission gzip_permission,
+    bool is_component) {
   std::unique_ptr<MessageBundle::SubstitutionMap> return_value =
       LoadNonLocalizedMessageBundleSubstitutionMap(extension_id);

@@ -49,8 +50,13 @@ LoadMessageBundleSubstitutionMapFromPath

   std::string error;
   for (const base::FilePath& path : paths) {
-    std::unique_ptr<MessageBundle> bundle(file_util::LoadMessageBundle(
-        path, default_locale, gzip_permission, &error));
+    std::unique_ptr<MessageBundle> bundle(
+        is_component
+        ? file_util::LoadComponentMessageBundle(
+            path, default_locale, &error)
+        : file_util::LoadMessageBundle(
+            path, default_locale, gzip_permission, &error));
+
     if (bundle) {
       for (const auto& iter : *bundle->dictionary()) {
         // |insert| only adds new entries, and does not replace entries in
--- a/extensions/common/file_util.h
+++ b/extensions/common/file_util.h
@@ -162,6 +162,11 @@ MessageBundle* LoadMessageBundle(
     extension_l10n_util::GzippedMessagesPermission gzip_permission,
     std::string* error);

+MessageBundle* LoadComponentMessageBundle(
+      const base::FilePath& extension_root,
+      const std::string& default_locale,
+      std::string* error);
+
 // Helper functions for getting paths for files used in content verification.
 base::FilePath GetVerifiedContentsPath(const base::FilePath& extension_path);
 base::FilePath GetComputedHashesPath(const base::FilePath& extension_path);
--- a/extensions/common/file_util.cc
+++ b/extensions/common/file_util.cc
@@ -597,6 +597,25 @@ MessageBundle* LoadMessageBundle(
   return message_bundle;
 }

+MessageBundle* LoadComponentMessageBundle(
+      const base::FilePath& extension_root,
+      const std::string& default_locale,
+      std::string* error) {
+  error->clear();
+
+  std::set<std::string> chrome_locales;
+  extension_l10n_util::GetAllLocales(&chrome_locales);
+
+  if (default_locale.empty() || !base::Contains(chrome_locales, default_locale)) {
+    *error = l10n_util::GetStringUTF8(
+        IDS_EXTENSION_LOCALES_NO_DEFAULT_LOCALE_SPECIFIED);
+    return nullptr;
+  }
+
+  return extension_l10n_util::LoadComponentMessageCatalogs(
+      extension_root, default_locale, error);
+}
+
 base::FilePath GetVerifiedContentsPath(const base::FilePath& extension_path) {
   return extension_path.Append(kMetadataFolder)
       .Append(kVerifiedContentsFilename);
--- a/extensions/browser/renderer_startup_helper.cc
+++ b/extensions/browser/renderer_startup_helper.cc
@@ -688,6 +688,18 @@ void RendererStartupHelper::GetMessageBu
     paths_to_load.push_back(imported_extension->path());
   }

+  bool is_component =
+    extension->location() == extensions::mojom::ManifestLocation::kComponent;
+
+  if (is_component) {
+    auto dictionary_map = l10n_file_util::LoadMessageBundleSubstitutionMapFromPaths(
+                            paths_to_load, extension_id, default_locale,
+                            extension_l10n_util::GzippedMessagesPermission::kAllowForTrustedSource,
+                            is_component);
+    std::move(callback).Run(ToFlatMap(*dictionary_map));
+    return;
+  }
+
   // This blocks tab loading. Priority is inherited from the calling context.
   base::ThreadPool::PostTaskAndReplyWithResult(
       FROM_HERE, {base::MayBlock()},



================================================
FILE: patches/helium/core/add-component-managed-schema-support.patch
================================================
--- a/chrome/browser/extensions/api/storage/managed_value_store_cache.cc
+++ b/chrome/browser/extensions/api/storage/managed_value_store_cache.cc
@@ -97,9 +97,11 @@ class ManagedValueStoreCache::ExtensionT

   // Loads the schemas of the |extensions| and passes a ComponentMap to
   // Register().
+  void LoadSchemasOnUIThread(ExtensionSet extensions);
   static void LoadSchemasOnFileTaskRunner(ExtensionSet extensions,
                                           base::WeakPtr<ExtensionTracker> self);
-  void Register(const policy::ComponentMap* components);
+  void Register(const policy::ComponentMap* components,
+                ExtensionSet extensions);

   raw_ptr<Profile> profile_;
   policy::PolicyDomain policy_domain_;
@@ -178,6 +180,22 @@ bool ManagedValueStoreCache::ExtensionTr
   return extension->manifest()->FindPath(manifest_keys::kStorageManagedSchema);
 }

+void ManagedValueStoreCache::ExtensionTracker::LoadSchemasOnUIThread(ExtensionSet extensions) {
+  auto components = std::make_unique<policy::ComponentMap>();
+
+  for (const auto& extension : extensions) {
+    if (!Manifest::IsComponentLocation(extension->location())) {
+      continue;
+    }
+
+    (*components)[extension->id()] =
+        StorageSchemaManifestHandler::GetComponentSchema(extension.get())
+            .value_or(policy::Schema());
+  }
+
+  schema_registry_->RegisterComponents(policy_domain_, *components);
+}
+
 // static
 void ManagedValueStoreCache::ExtensionTracker::LoadSchemasOnFileTaskRunner(
     ExtensionSet extensions,
@@ -202,14 +220,21 @@ void ManagedValueStoreCache::ExtensionTr

   content::GetUIThreadTaskRunner({})->PostTask(
       FROM_HERE, base::BindOnce(&ExtensionTracker::Register, self,
-                                base::Owned(components.release())));
+                                base::Owned(components.release()),
+                                std::move(extensions)));
 }

 void ManagedValueStoreCache::ExtensionTracker::Register(
-    const policy::ComponentMap* components) {
+    const policy::ComponentMap* components,
+    ExtensionSet extensions) {
   DCHECK_CURRENTLY_ON(BrowserThread::UI);
   schema_registry_->RegisterComponents(policy_domain_, *components);

+  // Our uBlock Origin component has a policy schema, but is
+  // not anywhere on the actual filesystem - so we need to pull
+  // it out on the UI thread from resources.
+  LoadSchemasOnUIThread(std::move(extensions));
+
   // The first SetExtensionsDomainsReady() call is performed after the
   // ExtensionSystem is ready, even if there are no managed extensions. It will
   // trigger a loading of the initial policy for any managed extensions, and
--- a/chrome/common/extensions/api/storage/storage_schema_manifest_handler.cc
+++ b/chrome/common/extensions/api/storage/storage_schema_manifest_handler.cc
@@ -15,6 +15,8 @@
 #include "base/types/expected.h"
 #include "base/types/expected_macros.h"
 #include "components/policy/core/common/schema.h"
+#include "extensions/browser/extensions_browser_client.h"
+#include "extensions/browser/component_extension_resource_manager.h"
 #include "extensions/common/extension.h"
 #include "extensions/common/install_warning.h"
 #include "extensions/common/manifest.h"
@@ -23,6 +25,7 @@
 #include "extensions/common/permissions/api_permission.h"
 #include "extensions/common/permissions/api_permission_set.h"
 #include "extensions/common/permissions/permissions_info.h"
+#include "ui/base/resource/resource_bundle.h"

 using extensions::manifest_keys::kStorageManagedSchema;

@@ -34,6 +37,33 @@ StorageSchemaManifestHandler::~StorageSc

 // static
 base::expected<policy::Schema, std::string>
+StorageSchemaManifestHandler::GetComponentSchema(const Extension* extension) {
+  auto* manager =
+      extensions::ExtensionsBrowserClient::Get()->GetComponentExtensionResourceManager();
+  const ui::ResourceBundle& rb = ui::ResourceBundle::GetSharedInstance();
+
+  int resource_id;
+  std::string path;
+  if (const std::string* temp =
+          extension->manifest()->FindStringPath(kStorageManagedSchema)) {
+    path = *temp;
+  } else {
+      return base::unexpected(base::StringPrintf(
+        "%s does not have a schema path", extension->id()));
+  }
+
+  if (!manager->IsComponentExtensionResource(
+        extension->path(), base::FilePath::FromUTF8Unsafe(path), &resource_id)) {
+    return base::unexpected(base::StringPrintf(
+        "%s/%s is not a component extension resource",
+        base::UTF16ToUTF8(extension->path().LossyDisplayName()), path));
+  }
+
+  return policy::Schema::Parse(rb.LoadDataResourceString(resource_id));
+}
+
+// static
+base::expected<policy::Schema, std::string>
 StorageSchemaManifestHandler::GetSchema(const Extension* extension) {
   std::string path;
   if (const std::string* temp =
--- a/chrome/common/extensions/api/storage/storage_schema_manifest_handler.h
+++ b/chrome/common/extensions/api/storage/storage_schema_manifest_handler.h
@@ -29,6 +29,8 @@ class StorageSchemaManifestHandler : pub
   // If the schema is invalid then the Schema returned is invalid too, and
   // the failure reason is stored in |error|.
   // This function does file I/O and must be called on a thread that allows I/O.
+  static base::expected<policy::Schema, std::string> GetComponentSchema(
+      const Extension* extension);
   static base::expected<policy::Schema, std::string> GetSchema(
       const Extension* extension);

--- a/chrome/common/extensions/BUILD.gn
+++ b/chrome/common/extensions/BUILD.gn
@@ -82,6 +82,7 @@ source_set("extensions") {
     "//components/url_formatter",
     "//components/version_info",
     "//extensions:extensions_resources",
+    "//extensions/browser",
     "//extensions/common",
     "//extensions/common:common_constants",
     "//extensions/common:core_api_provider",
@@ -89,6 +90,7 @@ source_set("extensions") {
     "//extensions/strings",
     "//ui/gfx/geometry",
     "//ui/message_center/public/cpp",
+    "//ui/base",
     "//url",
   ]




================================================
FILE: patches/helium/core/add-default-browser-reject-button.patch
================================================
--- a/chrome/common/pref_names.h
+++ b/chrome/common/pref_names.h
@@ -1407,6 +1407,11 @@ inline constexpr char kExtensionCommands
 inline constexpr char kPluginsAlwaysOpenPdfExternally[] =
     "plugins.always_open_pdf_externally";

+// Boolean indicating that the user has rejected setting
+// the browser as default for an indefinite amount of time.
+inline constexpr char kHeliumDefaultBrowserRejected[] =
+    "helium.browser.default_browser_infobar_rejected";
+
 // Int64 containing the internal value of the time at which the default browser
 // infobar was last dismissed by the user.
 inline constexpr char kDefaultBrowserLastDeclined[] =
--- a/chrome/browser/ui/browser_ui_prefs.cc
+++ b/chrome/browser/ui/browser_ui_prefs.cc
@@ -80,6 +80,8 @@ void RegisterBrowserPrefs(PrefRegistrySi
   registry->RegisterIntegerPref(prefs::kDefaultBrowserDeclinedCount, 0);
   registry->RegisterTimePref(prefs::kDefaultBrowserFirstShownTime,
                              base::Time());
+  registry->RegisterBooleanPref(prefs::kHeliumDefaultBrowserRejected, false);
+
 #if BUILDFLAG(IS_WIN) || BUILDFLAG(IS_MAC)
   registry->RegisterTimePref(prefs::kPdfInfoBarLastShown, base::Time());
   registry->RegisterIntegerPref(prefs::kPdfInfoBarTimesShown, 0);
--- a/chrome/browser/ui/startup/infobar_utils.cc
+++ b/chrome/browser/ui/startup/infobar_utils.cc
@@ -211,6 +211,11 @@ void AddInfoBarsIfNecessary(BrowserWindo
     return;
   }

+  PrefService* local_state = g_browser_process->local_state();
+  if (local_state && local_state->GetBoolean(prefs::kHeliumDefaultBrowserRejected)) {
+    return;
+  }
+
   base::OnceCallback<void(bool)> default_browser_prompt_shown_callback =
       base::DoNothing();
 #if BUILDFLAG(IS_MAC) || BUILDFLAG(IS_WIN)
--- a/components/infobars/core/confirm_infobar_delegate.h
+++ b/components/infobars/core/confirm_infobar_delegate.h
@@ -84,6 +84,8 @@ class ConfirmInfoBarDelegate : public in
   // on the infobar.
   virtual int GetLinkSpacingWhenPositionedBeforeButton() const;

+  virtual bool OkButtonShouldAlwaysLead() const;
+
 #if BUILDFLAG(IS_IOS)
   // Returns whether or not a tint should be applied to the icon background.
   // Defaults to true.
--- a/components/infobars/core/confirm_infobar_delegate.cc
+++ b/components/infobars/core/confirm_infobar_delegate.cc
@@ -71,6 +71,10 @@ int ConfirmInfoBarDelegate::GetLinkSpaci
   return 0;
 }

+bool ConfirmInfoBarDelegate::OkButtonShouldAlwaysLead() const {
+  return false;
+}
+
 #if BUILDFLAG(IS_IOS)
 bool ConfirmInfoBarDelegate::UseIconBackgroundTint() const {
   return true;
--- a/chrome/browser/ui/startup/default_browser_prompt/default_browser_infobar_delegate.cc
+++ b/chrome/browser/ui/startup/default_browser_prompt/default_browser_infobar_delegate.cc
@@ -112,13 +112,15 @@ std::u16string DefaultBrowserInfoBarDele
 }

 int DefaultBrowserInfoBarDelegate::GetButtons() const {
-  return BUTTON_OK;
+  return BUTTON_OK | BUTTON_CANCEL;
 }

 std::u16string DefaultBrowserInfoBarDelegate::GetButtonLabel(
     InfoBarButton button) const {
-  DCHECK_EQ(BUTTON_OK, button);
-  return l10n_util::GetStringUTF16(IDS_DEFAULT_BROWSER_INFOBAR_OK_BUTTON_LABEL);
+  DCHECK(button == BUTTON_OK || button == BUTTON_CANCEL);
+  return l10n_util::GetStringUTF16(
+    button == BUTTON_OK ? IDS_DEFAULT_BROWSER_INFOBAR_OK_BUTTON_LABEL
+                        : IDS_CARET_BROWSING_DO_NOT_ASK);
 }

 bool DefaultBrowserInfoBarDelegate::Accept() {
@@ -156,6 +158,22 @@ bool DefaultBrowserInfoBarDelegate::Acce
   return ConfirmInfoBarDelegate::Accept();
 }

+bool DefaultBrowserInfoBarDelegate::Cancel() {
+  PrefService* local_state = g_browser_process->local_state();
+  if (!local_state) {
+    return true;
+  }
+
+  local_state->SetBoolean(prefs::kHeliumDefaultBrowserRejected, true);
+  ConfirmInfoBarDelegate::InfoBarDismissed();
+
+  return ConfirmInfoBarDelegate::Cancel();
+}
+
 bool DefaultBrowserInfoBarDelegate::ShouldHideInFullscreen() const {
   return true;
 }
+
+bool DefaultBrowserInfoBarDelegate::OkButtonShouldAlwaysLead() const {
+  return true;
+}
--- a/chrome/browser/ui/startup/default_browser_prompt/default_browser_infobar_delegate.h
+++ b/chrome/browser/ui/startup/default_browser_prompt/default_browser_infobar_delegate.h
@@ -61,7 +61,9 @@ class DefaultBrowserInfoBarDelegate : pu
   int GetButtons() const override;
   std::u16string GetButtonLabel(InfoBarButton button) const override;
   bool Accept() override;
+  bool Cancel() override;
   bool ShouldHideInFullscreen() const override;
+  bool OkButtonShouldAlwaysLead() const override;

   // The WebContents's corresponding profile.
   raw_ptr<Profile> profile_;
--- a/chrome/browser/ui/views/infobars/confirm_infobar.cc
+++ b/chrome/browser/ui/views/infobars/confirm_infobar.cc
@@ -137,7 +137,9 @@ void ConfirmInfoBar::Layout(PassKey) {
   }

   if constexpr (!views::PlatformStyle::kIsOkButtonLeading) {
-    std::ranges::reverse(order_of_buttons);
+    if (!GetDelegate()->OkButtonShouldAlwaysLead()) {
+      std::ranges::reverse(order_of_buttons);
+    }
   }

   for (views::MdTextButton* button : order_of_buttons) {



================================================
FILE: patches/helium/core/add-disable-ech-flag.patch
================================================
--- a/chrome/browser/helium_flag_choices.h
+++ b/chrome/browser/helium_flag_choices.h
@@ -26,6 +26,8 @@ namespace helium {
     {kChannelBeta, kChannelCommandLine, kChannelBeta},
   };

+  constexpr const char kDisableEchCommandLine[] = "disable-ech";
+
 }  // namespace helium

 #endif  /* CHROME_BROWSER_HELIUM_FLAG_CHOICES_H_ */
--- a/chrome/browser/helium_flag_entries.h
+++ b/chrome/browser/helium_flag_entries.h
@@ -11,4 +11,9 @@
      "Maximum frame rate for Energy Saver",
      "Configures the frame rate the browser is throttled to when Energy Saver is enabled. Helium flag.",
      kOsDesktop, MULTI_VALUE_TYPE(helium::kEnergySaverFrameRateChoices)},
+    {helium::kDisableEchCommandLine,
+     "Disable ECH (Encrypted Client Hello)",
+     "Disables TLS Encrypted Client Hello. Not recommended unless you live in an area with heavy Internet"
+     " censorship and ECH prevents websites from loading. Helium flag.",
+     kOsAll, SINGLE_VALUE_TYPE(helium::kDisableEchCommandLine)},
 #endif  /* CHROME_BROWSER_HELIUM_FLAG_ENTRIES_H_ */
--- a/chrome/browser/ssl/ssl_config_service_manager.cc
+++ b/chrome/browser/ssl/ssl_config_service_manager.cc
@@ -10,6 +10,7 @@
 #include <string_view>
 #include <vector>

+#include "base/command_line.h"
 #include "base/containers/to_vector.h"
 #include "base/feature_list.h"
 #include "base/functional/bind.h"
@@ -265,6 +266,10 @@ network::mojom::SSLConfigPtr SSLConfigSe

   config->ech_enabled = ech_enabled_.GetValue();

+  if (base::CommandLine::ForCurrentProcess()->HasSwitch("disable-ech")) {
+    config->ech_enabled = false;
+  }
+
   if (post_quantum_enabled_.IsManaged()) {
     config->post_quantum_key_agreement_enabled =
         post_quantum_enabled_.GetValue();



================================================
FILE: patches/helium/core/add-helium-versioning.patch
================================================
--- a/build/apple/tweak_info_plist.py
+++ b/build/apple/tweak_info_plist.py
@@ -116,7 +116,7 @@ def _AddVersionKeys(plist, version_forma
     VERSION_FILE = os.path.join(TOP, 'chrome/VERSION')
     (stdout, retval) = _GetOutput([
         VERSION_TOOL, '-f', VERSION_FILE, '-t',
-        '@MAJOR@.@MINOR@.@BUILD@.@PATCH@'
+        '@HELIUM_MAJOR@.@HELIUM_MINOR@.@HELIUM_PATCH@.@HELIUM_PLATFORM@'
     ])

     # If the command finished with a non-zero return code, then report the
@@ -378,7 +378,7 @@ def Main(argv):
         # http://lists.apple.com/archives/carbon-dev/2006/Jun/msg00139.html
         # BUILD will always be an increasing value, so BUILD_PATH gives us
         # something unique that meetings what LS wants.
-        'CFBundleVersion': '@BUILD@.@PATCH@',
+        'CFBundleVersion': '@MAJOR@.@MINOR@.@BUILD@.@PATCH@',
     }
   else:
     version_format_for_key = {
--- a/base/version_info/version_info_values.h.version
+++ b/base/version_info/version_info_values.h.version
@@ -7,6 +7,7 @@

 #define PRODUCT_NAME "@PRODUCT_FULLNAME@"
 #define PRODUCT_VERSION "@MAJOR@.@MINOR@.@BUILD@.@PATCH@"
+#define HELIUM_PRODUCT_VERSION "@HELIUM_MAJOR@.@HELIUM_MINOR@.@HELIUM_PATCH@.@HELIUM_PLATFORM@"
 #define LAST_CHANGE "@LASTCHANGE@"
 #define IS_OFFICIAL_BUILD @OFFICIAL_BUILD@

--- a/base/version_info/version_info.h
+++ b/base/version_info/version_info.h
@@ -25,6 +25,10 @@ constexpr std::string_view GetProductNam
   return PRODUCT_NAME;
 }

+constexpr std::string_view GetHeliumVersionNumber() {
+  return HELIUM_PRODUCT_VERSION;
+}
+
 // Returns the version number, e.g. "6.0.490.1".
 constexpr std::string_view GetVersionNumber() {
   return PRODUCT_VERSION;
--- a/chrome/browser/ui/webui/version/version_ui.cc
+++ b/chrome/browser/ui/webui/version/version_ui.cc
@@ -222,6 +222,8 @@ void VersionUI::AddVersionDetailStrings(
                                   VersionProcessorVariation());

   // Data strings.
+  html_source->AddString(version_ui::kHeliumVersion,
+                         version_info::GetHeliumVersionNumber());
   html_source->AddString(version_ui::kVersion,
                          version_info::GetVersionNumber());
   html_source->AddString(version_ui::kVersionSuffix,
@@ -309,12 +311,14 @@ void VersionUI::AddVersionDetailStrings(
 std::u16string VersionUI::GetAnnotatedVersionStringForUi() {
   return l10n_util::GetStringFUTF16(
       IDS_SETTINGS_ABOUT_PAGE_BROWSER_VERSION,
+      {base::UTF8ToUTF16(version_info::GetHeliumVersionNumber()),
       base::UTF8ToUTF16(version_info::GetVersionNumber()),
       base::UTF8ToUTF16(GetVersionInformationalSuffix()),
       l10n_util::GetStringUTF16(version_info::IsOfficialBuild()
                                     ? IDS_VERSION_UI_OFFICIAL
                                     : IDS_VERSION_UI_UNOFFICIAL),
       base::UTF8ToUTF16(GetProductModifier()),
-      l10n_util::GetStringUTF16(VersionUI::VersionProcessorVariation()));
+      l10n_util::GetStringUTF16(VersionUI::VersionProcessorVariation()),
+      u"Chromium"}, nullptr);
 }
 #endif  // !BUILDFLAG(IS_ANDROID)
--- a/components/webui/version/version_ui_constants.cc
+++ b/components/webui/version/version_ui_constants.cc
@@ -86,6 +86,7 @@ const char kVariationsName[] = "variatio
 const char kVariationsSeed[] = "variations_seed";
 const char kVariationsSeedName[] = "variations_seed_name";
 const char kVersion[] = "version";
+const char kHeliumVersion[] = "helium_version";
 const char kVersionSuffix[] = "version_suffix";
 const char kVersionModifier[] = "version_modifier";
 const char kVersionProcessorVariation[] = "version_processor_variation";
--- a/components/webui/version/version_ui_constants.h
+++ b/components/webui/version/version_ui_constants.h
@@ -90,6 +90,7 @@ extern const char kVariationsName[];
 extern const char kVariationsSeed[];
 extern const char kVariationsSeedName[];
 extern const char kVersion[];
+extern const char kHeliumVersion[];
 extern const char kVersionSuffix[];
 extern const char kVersionModifier[];
 extern const char kVersionProcessorVariation[];
--- a/chrome/app/settings_strings.grdp
+++ b/chrome/app/settings_strings.grdp
@@ -42,7 +42,7 @@

   <!-- About Page -->
   <message name="IDS_SETTINGS_ABOUT_PAGE_BROWSER_VERSION" desc="The text label describing the version of the browser, example: Version 57.0.2937.0-r123456 (Developer Build) unknown (64-bit). The suffix of the version (eg. '-r123456') exists only in limited cases.)">
-    Version <ph name="PRODUCT_VERSION">$1<ex>15.0.865.0</ex></ph><ph name="PRODUCT_VERSION_SUFFIX">$2<ex>-r123456</ex></ph>  (<ph name="PRODUCT_CHANNEL">$3<ex>Developer Build</ex></ph>) <ph name="PRODUCT_MODIFIER">$4</ph> <ph name="PRODUCT_VERSION_BITS">$5</ph>
+    Version <ph name="HELIUM_PRODUCT_VERSION">$1<ex>0.0.0.0</ex></ph> (<ph name="PRODUCT_CHANNEL">$4<ex>Developer Build</ex></ph>, <ph name="CHROMIUM_NAME">$7</ph> <ph name="PRODUCT_VERSION">$2<ex>15.0.865.0</ex></ph><ph name="PRODUCT_VERSION_SUFFIX">$3<ex>-r123456</ex></ph>) <ph name="PRODUCT_MODIFIER">$5</ph> <ph name="PRODUCT_VERSION_BITS">$6</ph>
   </message>
   <message name="IDS_SETTINGS_ABOUT_PAGE_LEARN_MORE_UPDATE_ERRORS" desc="The accessibility label for a 'Learn more' link next to an error message about how an update has failed.">
     Learn more about fixing update errors
--- a/components/webui/version/resources/about_version.html
+++ b/components/webui/version/resources/about_version.html
@@ -54,11 +54,21 @@ about:version template page
       <table id="inner" cellpadding="0" cellspacing="0" border="0">
         <tr><td class="label">$i18n{application_label}</td>
           <td class="version" id="version">
+            <span id="copy-content-helium">
+              <span>$i18n{helium_version}</span>
+              (<span>$i18n{official}</span>)
+              <span>$i18n{version_processor_variation}</span>
+            </span>
+            <button id="copy-to-clipboard-helium" aria-label="$i18n{copy_label}">
+              <div id="copy-to-clipboard-icon"></div>
+            </button>
+          </td>
+        </tr>
+        <tr><td class="label">Chromium</td>
+          <td class="version" id="version">
             <span id="copy-content">
               <span>$i18n{version}$i18n{version_suffix}</span>
-              (<span>$i18n{official}</span>)
               <span>$i18n{version_modifier}</span>
-              <span>$i18n{version_processor_variation}</span>
   <if expr="is_win">
               <span>$i18n{update_cohort_name}</span>
   </if>
--- a/components/webui/version/resources/about_version.ts
+++ b/components/webui/version/resources/about_version.ts
@@ -134,6 +134,12 @@ async function copyVersionToClipboard()
   announceCopy('copy_notice');
 }

+async function copyHeliumVersionToClipboard() {
+  await navigator.clipboard.writeText(
+      getRequiredElement('copy-content-helium').innerText);
+  announceCopy('copy_notice');
+}
+
 async function copyVariationsToClipboard() {
   const cmdLine =
       getRequiredElement('variations-cmd').dataset['value'] as string;
@@ -196,6 +202,9 @@ function initialize() {
   getRequiredElement('copy-to-clipboard')
       .addEventListener('click', copyVersionToClipboard);

+  getRequiredElement('copy-to-clipboard-helium')
+      .addEventListener('click', copyHeliumVersionToClipboard);
+
   getRequiredElement('copy-variations-to-clipboard')
       .addEventListener('click', copyVariationsToClipboard);
 }
--- a/components/webui/version/resources/about_version.css
+++ b/components/webui/version/resources/about_version.css
@@ -91,6 +91,7 @@ body {
   vertical-align: bottom;
 }

+#copy-to-clipboard-helium,
 #copy-to-clipboard,
 #copy-variations-to-clipboard {
   background-color: var(--background-color);
--- a/chrome/app/chrome_main_delegate.cc
+++ b/chrome/app/chrome_main_delegate.cc
@@ -367,15 +367,15 @@ bool HandleCreditsSwitch(const base::Com
 bool HandleVersionSwitches(const base::CommandLine& command_line) {
 #if !BUILDFLAG(IS_MAC)
   if (command_line.HasSwitch(switches::kProductVersion)) {
-    printf("%s\n", version_info::GetVersionNumber().data());
+    printf("%s\n", version_info::GetHeliumVersionNumber().data());
     return true;
   }
 #endif

   if (command_line.HasSwitch(switches::kVersion)) {
-    printf("%s %s %s\n", version_info::GetProductName().data(),
-           version_info::GetVersionNumber().data(),
-           chrome::GetChannelName(chrome::WithExtendedStable(true)).c_str());
+    printf("%s %s (Chromium %s)\n", version_info::GetProductName().data(),
+           version_info::GetHeliumVersionNumber().data(),
+           version_info::GetVersionNumber().data());
     return true;
   }




================================================
FILE: patches/helium/core/add-low-power-framerate-flag.patch
================================================
--- a/chrome/browser/helium_flag_choices.h
+++ b/chrome/browser/helium_flag_choices.h
@@ -11,6 +11,15 @@
 namespace helium {
   using namespace ::helium;

+  constexpr const char kEnergySaverFrameRateCommandLine[] = "energy-saver-fps-limit";
+  constexpr const FeatureEntry::Choice kEnergySaverFrameRateChoices[] = {
+    {flags_ui::kGenericExperimentChoiceAutomatic, "", ""},
+    {"30", kEnergySaverFrameRateCommandLine, "30"},
+    {"60", kEnergySaverFrameRateCommandLine, "60"},
+    {"120", kEnergySaverFrameRateCommandLine, "120"},
+    {"Disabled", kEnergySaverFrameRateCommandLine, "9001"},
+  };
+
 }  // namespace helium

 #endif  /* CHROME_BROWSER_HELIUM_FLAG_CHOICES_H_ */
--- a/chrome/browser/helium_flag_entries.h
+++ b/chrome/browser/helium_flag_entries.h
@@ -4,4 +4,8 @@

 #ifndef CHROME_BROWSER_HELIUM_FLAG_ENTRIES_H_
 #define CHROME_BROWSER_HELIUM_FLAG_ENTRIES_H_
+    {helium::kEnergySaverFrameRateCommandLine,
+     "Maximum frame rate for Energy Saver",
+     "Configures the frame rate the browser is throttled to when Energy Saver is enabled. Helium flag.",
+     kOsDesktop, MULTI_VALUE_TYPE(helium::kEnergySaverFrameRateChoices)},
 #endif  /* CHROME_BROWSER_HELIUM_FLAG_ENTRIES_H_ */
--- a/chrome/browser/performance_manager/user_tuning/battery_saver_mode_manager.cc
+++ b/chrome/browser/performance_manager/user_tuning/battery_saver_mode_manager.cc
@@ -20,6 +20,7 @@
 #include "base/power_monitor/power_observer.h"
 #include "base/run_loop.h"
 #include "base/scoped_multi_source_observation.h"
+#include "base/strings/string_number_conversions.h"
 #include "base/values.h"
 #include "components/performance_manager/freezing/freezing_policy.h"
 #include "components/performance_manager/performance_manager_impl.h"
@@ -68,12 +69,28 @@ constexpr int kBatterySaverModeThreshold
 constexpr int kBatterySaverModeThresholdAdjustmentForDisplayLevel = 0;
 #endif  // BUILDFLAG(IS_CHROMEOS)

+int GetMaxRate() {
+  auto* command_line = base::CommandLine::ForCurrentProcess();
+  int fps;
+
+  if (command_line->HasSwitch("energy-saver-fps-limit") &&
+      base::StringToInt(command_line->GetSwitchValueASCII(
+        "energy-saver-fps-limit"), &fps) && fps > 0) {
+    return fps;
+  }
+
+  return 30;
+}
+
 class FrameThrottlingDelegateImpl
     : public performance_manager::user_tuning::BatterySaverModeManager::
           FrameThrottlingDelegate {
  public:
   void StartThrottlingAllFrameSinks() override {
-    content::StartThrottlingAllFrameSinks(base::Hertz(30));
+    static int max_rate = GetMaxRate();
+    if (max_rate < 9000) {
+      content::StartThrottlingAllFrameSinks(base::Hertz(max_rate));
+    }
   }

   void StopThrottlingAllFrameSinks() override {



================================================
FILE: patches/helium/core/add-middle-click-autoscroll-flag.patch
================================================
--- a/chrome/browser/helium_flag_choices.h
+++ b/chrome/browser/helium_flag_choices.h
@@ -29,6 +29,7 @@ namespace helium {
   constexpr const char kDisableEchCommandLine[] = "disable-ech";
   constexpr const char kCanvasNoiseCommandLine[] = "fingerprinting-canvas-noise";
   constexpr const char kAudioContextJitterCommandLine[] = "fingerprinting-audio-context-jitter";
+  constexpr const char kMiddleClickAutoscrollCommandLine[] = "middle-click-autoscroll";

 }  // namespace helium

--- a/chrome/browser/helium_flag_entries.h
+++ b/chrome/browser/helium_flag_entries.h
@@ -24,4 +24,8 @@
      "Audio Context fingerprint deception",
      "Adds small random jitter (0.01%) to audio data to prevent fingerprinting. Helium flag.",
      kOsAll, FEATURE_VALUE_TYPE(blink::features::kAudioContextJitter)},
+    {helium::kMiddleClickAutoscrollCommandLine,
+     "Middle Click Autoscroll",
+     "Enables autoscroll on middle click. Helium flag, Chromium feature.",
+     kOsDesktop, FEATURE_VALUE_TYPE(blink::features::kHeliumMiddleClickAutoscroll)},
 #endif  /* CHROME_BROWSER_HELIUM_FLAG_ENTRIES_H_ */
--- a/third_party/blink/public/common/features.h
+++ b/third_party/blink/public/common/features.h
@@ -23,6 +23,7 @@ namespace blink {
 namespace features {

 BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kAudioContextJitter);
+BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kHeliumMiddleClickAutoscroll);

 BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kDisableLinkDrag);
 BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kReducedSystemInfo);
--- a/third_party/blink/common/features.cc
+++ b/third_party/blink/common/features.cc
@@ -24,6 +24,15 @@ BASE_FEATURE(kAudioContextJitter,
              "AudioContextJitter",
              base::FEATURE_ENABLED_BY_DEFAULT);

+BASE_FEATURE(kHeliumMiddleClickAutoscroll,
+             "HeliumMiddleClickAutoscroll",
+#if BUILDFLAG(IS_WIN)
+             base::FEATURE_ENABLED_BY_DEFAULT
+#else
+             base::FEATURE_DISABLED_BY_DEFAULT
+#endif
+);
+
 BASE_FEATURE(kDisableLinkDrag, "DisableLinkDrag", base::FEATURE_DISABLED_BY_DEFAULT);
 BASE_FEATURE(kReducedSystemInfo, "ReducedSystemInfo", base::FEATURE_DISABLED_BY_DEFAULT);
 BASE_FEATURE(kRemoveClientHints, "RemoveClientHints", base::FEATURE_DISABLED_BY_DEFAULT);
--- a/third_party/blink/renderer/core/exported/web_view_impl.cc
+++ b/third_party/blink/renderer/core/exported/web_view_impl.cc
@@ -1903,9 +1903,9 @@ void WebView::ApplyWebPreferences(const
       prefs.default_maximum_page_scale_factor);
 #endif

-#if BUILDFLAG(IS_WIN)
-  RuntimeEnabledFeatures::SetMiddleClickAutoscrollEnabled(true);
-#endif
+  RuntimeEnabledFeatures::SetMiddleClickAutoscrollEnabled(
+    base::FeatureList::IsEnabled(features::kHeliumMiddleClickAutoscroll)
+  );

   RuntimeEnabledFeatures::SetTranslateServiceEnabled(
       prefs.translate_service_available);



================================================
FILE: patches/helium/core/add-native-bangs.patch
================================================
--- a/chrome/browser/search_engines/template_url_service_factory.cc
+++ b/chrome/browser/search_engines/template_url_service_factory.cc
@@ -28,6 +28,7 @@
 #include "components/search_engines/enterprise/enterprise_search_manager.h"
 #include "components/search_engines/search_engines_pref_names.h"
 #include "components/search_engines/template_url_service.h"
+#include "content/public/browser/storage_partition.h"
 #include "rlz/buildflags/buildflags.h"

 #if BUILDFLAG(IS_CHROMEOS)
@@ -65,6 +66,7 @@ std::unique_ptr<KeyedService> TemplateUR
   Profile* profile = Profile::FromBrowserContext(context);
   return std::make_unique<TemplateURLService>(
       CHECK_DEREF(profile->GetPrefs()),
+      context->GetDefaultStoragePartition()->GetURLLoaderFactoryForBrowserProcess(),
       CHECK_DEREF(
           search_engines::SearchEngineChoiceServiceFactory::GetForProfile(
               profile)),
--- a/components/search_engines/template_url_data_util.h
+++ b/components/search_engines/template_url_data_util.h
@@ -8,6 +8,7 @@
 #include <memory>

 #include "base/values.h"
+#include "components/search_engines/template_url_bang_manager.h"

 namespace TemplateURLPrepopulateData {
 struct PrepopulatedEngine;
@@ -40,4 +41,5 @@ std::unique_ptr<TemplateURLData> Templat
 std::unique_ptr<TemplateURLData> TemplateURLDataFromStarterPackEngine(
     const template_url_starter_pack_data::StarterPackEngine& engine);

+TemplateURLData TemplateURLDataFromBang(const Bangs::Bang& bang);
 #endif  // COMPONENTS_SEARCH_ENGINES_TEMPLATE_URL_DATA_UTIL_H_
--- a/components/search_engines/BUILD.gn
+++ b/components/search_engines/BUILD.gn
@@ -35,6 +35,8 @@ static_library("search_engines") {
     "search_terms_data.h",
     "template_url.cc",
     "template_url.h",
+    "template_url_bang_manager.cc",
+    "template_url_bang_manager.h",
     "template_url_data.cc",
     "template_url_data.h",
     "template_url_data_util.cc",
@@ -79,6 +81,7 @@ static_library("search_engines") {
     "//components/country_codes",
     "//components/crash/core/common:crash_key",
     "//components/database_utils",
+    "//components/helium_services",
     "//components/infobars/core",
     "//components/lens:features",
     "//components/lens:mime_type",
--- a/components/search_engines/template_url_data_util.cc
+++ b/components/search_engines/template_url_data_util.cc
@@ -15,6 +15,7 @@
 #include "components/search_engines/default_search_manager.h"
 #include "components/search_engines/template_url_data.h"
 #include "components/search_engines/template_url_starter_pack_data.h"
+#include "components/search_engines/template_url_bang_manager.h"
 #include "third_party/search_engines_data/resources/definitions/prepopulated_engines.h"
 #include "ui/base/l10n/l10n_util.h"
 #include "url/gurl.h"
@@ -512,3 +513,20 @@ std::unique_ptr<TemplateURLData> Templat

   return turl;
 }
+
+TemplateURLData TemplateURLDataFromBang(const Bangs::Bang& bang) {
+  TemplateURLData turl;
+  turl.SetShortName(base::UTF8ToUTF16(bang.name));
+  turl.SetKeyword(u"!" + base::UTF8ToUTF16(bang.bang));
+  turl.SetURL(bang.template_url);
+
+  GURL favicon_url = GURL(bang.template_url).GetWithEmptyPath();
+  favicon_url.path() = "/favicon.ico";
+  turl.favicon_url = std::move(favicon_url);
+  turl.bang_id = 1 + bang.id;
+
+  turl.safe_for_autoreplace = false;
+  turl.GenerateSyncGUID();
+  turl.is_active = TemplateURLData::ActiveStatus::kTrue;
+  return turl;
+}
--- a/components/search_engines/template_url_service.cc
+++ b/components/search_engines/template_url_service.cc
@@ -40,6 +40,8 @@
 #include "base/strings/utf_string_conversions.h"
 #include "build/build_config.h"
 #include "components/country_codes/country_codes.h"
+#include "components/helium_services/pref_names.h"
+#include "components/helium_services/helium_services_helpers.h"
 #include "components/google/core/common/google_util.h"
 #include "components/omnibox/common/omnibox_feature_configs.h"
 #include "components/omnibox/common/omnibox_features.h"
@@ -58,7 +60,9 @@
 #include "components/search_engines/search_engines_switches.h"
 #include "components/search_engines/search_terms_data.h"
 #include "components/search_engines/template_url.h"
+#include "components/search_engines/template_url_bang_manager.h"
 #include "components/search_engines/template_url_data.h"
+#include "components/search_engines/template_url_data_util.h"
 #include "components/search_engines/template_url_prepopulate_data.h"
 #include "components/search_engines/template_url_prepopulate_data_resolver.h"
 #include "components/search_engines/template_url_service_client.h"
@@ -73,6 +77,7 @@
 #include "components/sync/protocol/search_engine_specifics.pb.h"
 #include "components/url_formatter/url_fixer.h"
 #include "net/base/registry_controlled_domains/registry_controlled_domain.h"
+#include "services/network/public/cpp/shared_url_loader_factory.h"
 #include "url/gurl.h"
 #include "url/origin.h"
 #include "url/third_party/mozilla/url_parse.h"
@@ -581,6 +586,7 @@ class TemplateURLService::PreLoadingProv
 // TemplateURLService ---------------------------------------------------------
 TemplateURLService::TemplateURLService(
     PrefService& prefs,
+    scoped_refptr<network::SharedURLLoaderFactory> url_loader_factory,
     search_engines::SearchEngineChoiceService& search_engine_choice_service,
     TemplateURLPrepopulateData::Resolver& prepopulate_data_resolver,
     std::unique_ptr<SearchTermsData> search_terms_data,
@@ -593,6 +599,8 @@ TemplateURLService::TemplateURLService(
       prepopulate_data_resolver_(prepopulate_data_resolver),
       search_terms_data_(std::move(search_terms_data)),
       web_data_service_(web_data_service),
+      url_loader_factory_(std::move(url_loader_factory)),
+      bang_manager_(Bangs::BangManager::GetInstance()),
       client_(std::move(client)),
       dsp_change_callback_(dsp_change_callback),
       pre_loading_providers_(std::make_unique<PreLoadingProviders>()),
@@ -609,11 +617,13 @@ TemplateURLService::TemplateURLService(

 TemplateURLService::TemplateURLService(
     PrefService& prefs,
+    scoped_refptr<network::SharedURLLoaderFactory> url_loader_factory,
     search_engines::SearchEngineChoiceService& search_engine_choice_service,
     TemplateURLPrepopulateData::Resolver& prepopulate_data_resolver,
     base::span<const TemplateURLService::Initializer> initializers)
     : TemplateURLService(
           prefs,
+          url_loader_factory,
           search_engine_choice_service,
           prepopulate_data_resolver,
           /*search_terms_data=*/std::make_unique<SearchTermsData>(),
@@ -694,6 +704,10 @@ bool TemplateURLService::ShowInActivesLi
 }

 bool TemplateURLService::HiddenFromLists(const TemplateURL* t_url) const {
+  if (t_url->bang_id()) {
+    return true;
+  }
+
   switch (t_url->policy_origin()) {
     case TemplateURLData::PolicyOrigin::kDefaultSearchProvider:
       return false;
@@ -1527,11 +1541,37 @@ void TemplateURLService::Load() {

   if (web_data_service_) {
     load_handle_ = web_data_service_->GetKeywords(this);
+    LoadBangs();
   } else {
     ChangeToLoadedState();
   }
 }

+void TemplateURLService::LoadBangs() {
+  VLOG(2) << "LoadBangs() called";
+  bang_manager_->LoadBangs(url_loader_factory_, prefs_.get(),
+    base::BindOnce(&


we can take some notes on how this other browser helium did it:
Directory structure:
 imputnet-helium/
     README.md
     chromium_version.txt
     domain_regex.list
     downloads.ini
     extras.ini
     flags.gn
     LICENSE
     LICENSE.ungoogled_chromium
     revision.txt
     shell.nix
     version.txt
     .cirrus.yml
     .cirrus_Dockerfile
     .cirrus_requirements.txt
     .style.yapf
     devutils/
        README.md
        __init__.py
        _lint_tests.py
        check_all_code.sh
        check_downloads_ini.py
        check_files_exist.py
        check_gn_flags.py
        check_patch_files.py
        clear-ublock-assets.js
        lint.py
        print_tag_version.sh
        pytest.ini
        run_devutils_pylint.py
        run_devutils_tests.sh
        run_devutils_yapf.sh
        run_other_pylint.py
        run_other_yapf.sh
        run_utils_pylint.py
        run_utils_tests.sh
        run_utils_yapf.sh
        set_quilt_vars.fish
        set_quilt_vars.sh
        update_lists.py
        update_platform_patches.py
        validate_config.py
        validate_patches.py
        .coveragerc
        tests/
           __init__.py
           test_check_patch_files.py
           test_validate_patches.py
        third_party/
            README.md
            __init__.py
            unidiff/
                __init__.py
                __version__.py
                constants.py
                errors.py
                patch.py
     patches/
        series
        brave/
           custom-importer.patch
           fix-component-content-settings-store.patch
           tab-cycling-mru-impl.patch
        bromite/
           disable-fetching-field-trials.patch
           fingerprinting-flags-client-rects-and-measuretext.patch
           flag-fingerprinting-canvas-image-data-noise.patch
           flag-max-connections-per-host.patch
        debian/
           disable-google-api-warning.patch
        helium/
           core/
              add-component-l10n-support.patch
              add-component-managed-schema-support.patch
              add-default-browser-reject-button.patch
              add-disable-ech-flag.patch
              add-helium-versioning.patch
              add-low-power-framerate-flag.patch
              add-middle-click-autoscroll-flag.patch
              add-native-bangs.patch
              add-update-channel-flag.patch
              add-updater-preference.patch
              add-zen-importer.patch
              browser-window-context-menu.patch
              change-chromium-branding.patch
              clean-context-menu.patch
              clean-omnibox-suggestions.patch
              component-updates.patch
              disable-ad-topics-and-etc.patch
              disable-bookmarks-bar.patch
              disable-fedcm-bubble.patch
              disable-history-clusters.patch
              disable-live-caption-completely.patch
              disable-ntp-footer.patch
              disable-outdated-build-detector.patch
              disable-touch-ui.patch
              disable-unsupported-importers.patch
              disable-update-toast.patch
              disable-user-education-nags.patch
              enable-parallel-downloading.patch
              enable-tab-hover-cards.patch
              enable-tab-search-toolbar-button.patch
              exclude-irrelevant-flags.patch
              fix-building-without-safebrowsing.patch
              fix-component-extension-reenablement.patch
              fix-instance-id-stuck.patch
              fix-tab-sync-unreached-error.patch
              flags-setup.patch
              increase-incognito-storage-quota.patch
              infinite-tab-freezing.patch
              keyboard-shortcuts.patch
              memory-saving-by-default.patch
              mitigate-fingerprinting-audio-context.patch
              mitigate-fingerprinting-canvas.patch
              onboarding-page.patch
              open-new-tabs-next-to-active-tab-option.patch
              override-chrome-protocol.patch
              prefer-https-by-default.patch
              proxy-extension-downloads.patch
              reduce-accept-language-headers.patch
              reenable-spellcheck-downloads.patch
              reenable-update-checks.patch
              remove-dead-toolbar-actions.patch
              replace-default-profile-name.patch
              scan-chrome-native-messaging-hosts.patch
              services-prefs.patch
              services-schema-nag.patch
              split-view.patch
              spoof-chrome-ua-brand.patch
              spoof-extension-downloader-platform.patch
              tab-cycling-mru.patch
              ublock-helium-services.patch
              ublock-install-as-component.patch
              ublock-migrate-prefs.patch
              ublock-reconfigure-defaults.patch
              ublock-setup-sources.patch
              unbreak-chromium-link.patch
              update-credits.patch
              update-default-browser-prefs.patch
              webrtc-default-handling-policy.patch
              search/
                  engine-defaults.patch
                  fix-search-engine-icons.patch
                  force-eu-search-features.patch
                  remove-description-snippet-deps.patch
                  restore-google.patch
           hop/
              disable-password-manager.patch
              setup.patch
           settings/
              about-page-tweaks.patch
              disable-safety-hub-page.patch
              enable-quad9-doh-option.patch
              fix-appearance-page.patch
              fix-page-names.patch
              fix-section-separators.patch
              fix-text-on-cookies-page.patch
              move-search-suggest.patch
              privacy-page-tweaks.patch
              reenable-update-status.patch
              remove-autofill.patch
              remove-dead-imports.patch
              remove-profile-page-sections.patch
              remove-results-help-link.patch
              remove-safety-hub-entry-points.patch
              remove-translate-section.patch
              reorder-settings-menu.patch
              settings-page-icons.patch
              setup-behavior-settings-page.patch
              update-search-suggest-text.patch
           ui/
               always-use-better-ntp.patch
               app-menu-button.patch
               app-menu-model.patch
               app-menu-style.patch
               bangs-ui.patch
               bookmark-button-bg-fix.patch
               bookmarks-bar-padding.patch
               center-window-on-launch.patch
               clean-incognito-guest-ntp.patch
               clean-new-tab-page.patch
               clean-up-installed-extension-bubble.patch
               disable-tab-group-editor-footer.patch
               enable-fluent-scrollbar.patch
               find-bar.patch
               fix-caption-button-bounds.patch
               fix-customize-side-panel.patch
               helium-color-scheme.patch
               helium-logo-icons.patch
               improve-flags-webui.patch
               improve-toast.patch
               layout-constants.patch
               layout-provider.patch
               licenses-in-credits.patch
               location-bar-intent-chip.patch
               location-bar.patch
               omnibox.patch
               pdf-viewer.patch
               profile-customization-cleanup.patch
               profile-picker-cleanup.patch
               pwa-toolbar.patch
               reduce-text-button-height.patch
               remove-autofill-link-to-password-manager.patch
               remove-dead-profile-actions.patch
               remove-dead-toolbar-actions.patch
               remove-devtools-annoyances.patch
               remove-reading-list-from-app-menu.patch
               remove-toolbar-corners.patch
               remove-zoom-action.patch
               restyle-ntp-tiles.patch
               selected-keyword-view.patch
               set-gray-as-default-theme.patch
               side-panel-webui.patch
               side-panel.patch
               smaller-window-grab-handle.patch
               square-interstitial-buttons.patch
               square-ntp-monograms.patch
               status-bubble.patch
               tab-strip-controls.patch
               tabs.patch
               thinner-infobar.patch
               toolbar-button-prefs.patch
               toolbar-window-frame-hit-test.patch
               toolbar.patch
               top-container.patch
               ublock-show-in-settings.patch
               update-cr-components.patch
               experiments/
                   compact-action-toolbar.patch
        inox-patchset/
           disable-autofill-download-manager.patch
           disable-battery-status-service.patch
           disable-rlz.patch
           disable-update-pings.patch
           fix-building-without-safebrowsing.patch
           modify-default-prefs.patch
        iridium-browser/
           all-add-trk-prefixes-to-possibly-evil-connections.patch
           browser-disable-profile-auto-import-on-first-run.patch
           safe-browsing-disable-reporting.patch
           updater-disable-auto-update.patch
        ungoogled-chromium/
           add-components-ungoogled.patch
           add-credits.patch
           add-flag-for-bookmark-bar-ntp.patch
           add-flag-for-close-confirmation.patch
           add-flag-for-custom-ntp.patch
           add-flag-for-disabling-link-drag.patch
           add-flag-for-grab-handle.patch
           add-flag-for-incognito-themes.patch
           add-flag-for-omnibox-autocomplete-filtering.patch
           add-flag-for-search-engine-collection.patch
           add-flag-for-tab-hover-cards.patch
           add-flag-to-change-http-accept-header.patch
           add-flag-to-clear-data-on-exit.patch
           add-flag-to-close-window-with-last-tab.patch
           add-flag-to-configure-extension-downloading.patch
           add-flag-to-convert-popups-to-tabs.patch
           add-flag-to-disable-beforeunload.patch
           add-flag-to-disable-local-history-expiration.patch
           add-flag-to-disable-tls-grease.patch
           add-flag-to-force-punycode-hostnames.patch
           add-flag-to-hide-crashed-bubble.patch
           add-flag-to-hide-extensions-menu.patch
           add-flag-to-hide-fullscreen-exit-ui.patch
           add-flag-to-hide-tab-close-buttons.patch
           add-flag-to-increase-incognito-storage-quota.patch
           add-flag-to-reduce-system-info.patch
           add-flag-to-remove-client-hints.patch
           add-flag-to-scroll-tabs.patch
           add-flag-to-show-avatar-button.patch
           add-flag-to-spoof-webgl-renderer-info.patch
           add-flags-for-existing-switches.patch
           add-flags-for-referrer-customization.patch
           add-ipv6-probing-option.patch
           add-suggestions-url-field.patch
           add-ungoogled-flag-headers.patch
           block-requests.patch
           block-trk-and-subdomains.patch
           disable-ai-search-shortcuts.patch
           disable-chromelabs.patch
           disable-crash-reporter.patch
           disable-dial-repeating-discovery.patch
           disable-domain-reliability.patch
           disable-downloads-page-referrer-url.patch
           disable-fonts-googleapis-references.patch
           disable-gaia.patch
           disable-gcm.patch
           disable-google-host-detection.patch
           disable-intranet-redirect-detector.patch
           disable-mei-preload.patch
           disable-network-time-tracker.patch
           disable-privacy-sandbox.patch
           disable-profile-avatar-downloading.patch
           disable-untraceable-urls.patch
           disable-webrtc-log-uploader.patch
           disable-webstore-urls.patch
           doh-changes.patch
           enable-certificate-transparency-and-add-flag.patch
           enable-menu-on-reload-button.patch
           enable-paste-and-go-new-tab-button.patch
           extensions-manifestv2.patch
           fix-building-without-mdns-and-service-discovery.patch
           fix-learn-doubleclick-hsts.patch
           move-js-optimizer-unfamiliar-sites.patch
           prepopulated-search-engines.patch
           remove-f1-shortcut.patch
           remove-pac-size-limit.patch
           remove-uneeded-ui.patch
           toggle-translation-via-switch.patch
        upstream-fixes/
            fix-crash-without-enterprise-cloud-content-analysis.patch
            fix-macos-widget-rect.patch
            fix-python-codecs-deprecation.patch
            missing-dependencies.patch
     resources/
        generate_resources.txt
        helium_resources.txt
        branding/
            product_logo.icon
            product_logo_color.icon
     utils/
        __init__.py
        _common.py
        _extraction.py
        clone.py
        depot_tools.patch
        domain_substitution.py
        downloads.py
        filescfg.py
        generate_resources.py
        helium_version.py
        make_domsub_script.py
        name_substitution.py
        patches.py
        prune_binaries.py
        pytest.ini
        replace_resources.py
        .coveragerc
        tests/
           __init__.py
           test_domain_substitution.py
           test_patches.py
        third_party/
            README.md
            __init__.py
            schema.py
     .github/
         PULL_REQUEST_TEMPLATE.md
         actions/
            bump-platform/
                action.yml
         ISSUE_TEMPLATE/
            bug-report.yml
            config.yml
            feature-request.yml
            misc.md
         workflows/
            cirrus.yml
            lint.yml
            release-and-tag.yml
            stale.yml
         .well-known/
             funding-manifest-urls
